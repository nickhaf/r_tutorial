[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome",
    "section": "",
    "text": "Welcome!12 This workshop will teach you the basics of R. It’s structure is meant to support different levels of R expertise and interests: already know the basics and want to learn how to plot? Want to freshen up your R skills and look at specific topics? Or are you new to programming with R and want to follow the course structure? This workshop provides different entry points. You can either follow the outline on the left side and work on all topics in the order they are presented in. Or, if you already have some R experience, you might want to read The Big Picture and/or the The Big Picture: Exercise first to identify topics you want to work on.\n\n\n\n\n\n\nUnfold if you want to learn more about optional content\n\n\n\n\n\nDon’t worry if you don’t finish the whole workshop in time, or the material seems a bit overwhelming. It is designed to provide additional information for self studying and looking up topics of interest. Optional input and exercises can be found in folded in sections like this one.\n\n\n\nThe main objective of this workshop is to get you started with using R for your own scientific work. To do that, we will repeat and try out the main concepts multiple times, so you get to work with them as much and as from many different perspectives as possible. Along the way, some advanced ideas will be introduced as well, which you can follow up on later in case you think they might be relevant for your own work.\nEach section is divided into a theory part and some exercises. If something is unclear, you can use the Ask a question button on the upper right corner.\n\n\n\n\n\n\nTip\n\n\n\nLearning how to program can be tough, and to get started it is important to write as much code as possible, and think about many different problems to get used to coding. So do the exercises!\n\n\n\n\n\n\n\n\nSoftware installation\n\n\n\nPlease install the necessary software before the workshop. Of course, feel free to ask questions if you run into problems along the way."
  },
  {
    "objectID": "index.html#about-this-workshop",
    "href": "index.html#about-this-workshop",
    "title": "Welcome",
    "section": "",
    "text": "Welcome!12 This workshop will teach you the basics of R. It’s structure is meant to support different levels of R expertise and interests: already know the basics and want to learn how to plot? Want to freshen up your R skills and look at specific topics? Or are you new to programming with R and want to follow the course structure? This workshop provides different entry points. You can either follow the outline on the left side and work on all topics in the order they are presented in. Or, if you already have some R experience, you might want to read The Big Picture and/or the The Big Picture: Exercise first to identify topics you want to work on.\n\n\n\n\n\n\nUnfold if you want to learn more about optional content\n\n\n\n\n\nDon’t worry if you don’t finish the whole workshop in time, or the material seems a bit overwhelming. It is designed to provide additional information for self studying and looking up topics of interest. Optional input and exercises can be found in folded in sections like this one.\n\n\n\nThe main objective of this workshop is to get you started with using R for your own scientific work. To do that, we will repeat and try out the main concepts multiple times, so you get to work with them as much and as from many different perspectives as possible. Along the way, some advanced ideas will be introduced as well, which you can follow up on later in case you think they might be relevant for your own work.\nEach section is divided into a theory part and some exercises. If something is unclear, you can use the Ask a question button on the upper right corner.\n\n\n\n\n\n\nTip\n\n\n\nLearning how to program can be tough, and to get started it is important to write as much code as possible, and think about many different problems to get used to coding. So do the exercises!\n\n\n\n\n\n\n\n\nSoftware installation\n\n\n\nPlease install the necessary software before the workshop. Of course, feel free to ask questions if you run into problems along the way."
  },
  {
    "objectID": "index.html#why-r",
    "href": "index.html#why-r",
    "title": "Welcome",
    "section": "Why R?",
    "text": "Why R?\n\nR is a popular programming language for data manipulation, statistical data analyses and plotting of data.\nIt is open source, and has a big community, which facilitates the development of additional software packages for multiple different applications, but also makes it easy to get help if you are stuck at a particular problem.\nThis is one of the reasons why R is great for doing statistical analyses - there are packages for almost every use case.\nIt has great tools for making beautiful plots.\nThis is not R specific, but because you can write programs for your specific use cases, it facilitates many workflow related tasks like automation, tracking changes with git, result preparation with markdown/latex and many more.\n\nThere are many more reasons to learn R, as it is a very flexible tool for almost every aspect of scientific work (after all, I have created this whole workshop from within RStudio), so let’s dive right into it!"
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "Welcome",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis workshop was designed by Nicklas Hafiz, PhD student and research fellow at the Institut für Qualitätsentwicklung im Bildungswesen (IQB).↩︎\nIt is licensed under the MIT License.↩︎"
  },
  {
    "objectID": "qmd/basics/basics.html",
    "href": "qmd/basics/basics.html",
    "title": "Basic operations",
    "section": "",
    "text": "Let’s take a quick look at the most important basic operations in R. You can also use a cheat sheet to keep an overview during the course.\n\n\nWe can use R as a calculator:\n\n(1 + 2) * 3^2\n2 - 3/log(8)\n\n\n\n\nWe can create objects in R by using the assignment operator &lt;-, which assigns a value to an object:\n\n## Assign the result of 1 + 1 to the object 'result':\nresult &lt;- 1 + 1\nresult\n\n[1] 2\n\n## Assign the result of the comparison to the object 'log_result':\nlog_result &lt;- 10 &gt; 1\nlog_result\n\n[1] TRUE\n\n\n\n\n\nWe can combine multiple elements to build a new one:\n\nnew_element &lt;- c(1, 10, 15)\n\nIn this case, this new element is a vector, which is a one dimensional collection of element. The c() stands for combine, or concatenate, and is the basic function for building a vector out of single elements.\n\n\n\nThe boolean variables in R are TRUE and FALSE. Comparison operators return either TRUE or FALSE:\n\n1 &lt; 2\n\n[1] TRUE\n\n# But:\n2 &lt; 1\n\n[1] FALSE\n\n\nThese are the comparison operators you will typically use:\n\n\n\n\n\nOperator\nDescription\n\n\n\n\n&lt;\nless than\n\n\n&gt;\ngreater than\n\n\n==\nequal to\n\n\n!=\nnot equal to\n\n\n&lt;=\nless or equal\n\n\n&gt;=\ngreater or equal\n\n\n%in%\npart of\n\n\n\n\n\nMainly we will use these logical operation to check which elements in a vector satisfy some requirements:\n\n# Build a vector of numbers ranging from 1 to 10\nvec_num &lt;- 1:10\n\n# Check which of these numbers are smaller than 5\nvec_num &lt; 5\n\n [1]  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE\n\n\nThis will become important later on, when we want to subset vectors and data frames to extract only those values that satisfy some requirements we defined.\n\n\n\nThe %in% operator is used to check for each element of its first argument if it is part of the second argument:\n\nc(\"Monica\", \"Rachel\", \"Barny\") %in% c(\"Monica\", \"Rachel\", \"Ross\", \"Joey\", \"Phoebe\", \"Chandler\")\n\n[1]  TRUE  TRUE FALSE\n\n\n\n\n\nWe can invert boolean values by using !:\n\n!TRUE\n\n[1] FALSE\n\n!(1 &gt; 100)\n\n[1] TRUE\n\n\n\n\n\nEverything that does something in R is a function. A function call has the form: functionname(argument1 = value, argument2 = value, ...). One basic example for a function is the function that can calculate the square root:\n\nsqrt(4)\n\n[1] 2\n\n\nWe can also assign the name of the function argument to our value. This is clearer, as we don’t rely on the order of the function arguments:\n\nrep(4, 10)\n\n [1] 4 4 4 4 4 4 4 4 4 4\n\n\nwill rep 4 10 times. If we swap the arguments, the 10 will be repeat 4 times:\n\nrep(10, 4)\n\n[1] 10 10 10 10\n\n\nBut if we specify which value belongs to which function argument, the order doesn’t matter:\n\nrep(times = 10, x = 4)\n\n [1] 4 4 4 4 4 4 4 4 4 4\n\n\nHow do we know which arguments a function has?:\n\n\n\nOne of the most important functions in R is the help-function ?:\n\n?rep\n\nwill open the documentation for the function with the description of its usage, details about the arguments … In the next chapter we will take a very quick look at R’s data types."
  },
  {
    "objectID": "qmd/basics/basics.html#basic-mathematical-operations",
    "href": "qmd/basics/basics.html#basic-mathematical-operations",
    "title": "Basic operations",
    "section": "",
    "text": "We can use R as a calculator:\n\n(1 + 2) * 3^2\n2 - 3/log(8)"
  },
  {
    "objectID": "qmd/basics/basics.html#assignment-operator",
    "href": "qmd/basics/basics.html#assignment-operator",
    "title": "Basic operations",
    "section": "",
    "text": "We can create objects in R by using the assignment operator &lt;-, which assigns a value to an object:\n\n## Assign the result of 1 + 1 to the object 'result':\nresult &lt;- 1 + 1\nresult\n\n[1] 2\n\n## Assign the result of the comparison to the object 'log_result':\nlog_result &lt;- 10 &gt; 1\nlog_result\n\n[1] TRUE"
  },
  {
    "objectID": "qmd/basics/basics.html#combination-of-elements",
    "href": "qmd/basics/basics.html#combination-of-elements",
    "title": "Basic operations",
    "section": "",
    "text": "We can combine multiple elements to build a new one:\n\nnew_element &lt;- c(1, 10, 15)\n\nIn this case, this new element is a vector, which is a one dimensional collection of element. The c() stands for combine, or concatenate, and is the basic function for building a vector out of single elements."
  },
  {
    "objectID": "qmd/basics/basics.html#comparisons-and-logical-operators",
    "href": "qmd/basics/basics.html#comparisons-and-logical-operators",
    "title": "Basic operations",
    "section": "",
    "text": "The boolean variables in R are TRUE and FALSE. Comparison operators return either TRUE or FALSE:\n\n1 &lt; 2\n\n[1] TRUE\n\n# But:\n2 &lt; 1\n\n[1] FALSE\n\n\nThese are the comparison operators you will typically use:\n\n\n\n\n\nOperator\nDescription\n\n\n\n\n&lt;\nless than\n\n\n&gt;\ngreater than\n\n\n==\nequal to\n\n\n!=\nnot equal to\n\n\n&lt;=\nless or equal\n\n\n&gt;=\ngreater or equal\n\n\n%in%\npart of\n\n\n\n\n\nMainly we will use these logical operation to check which elements in a vector satisfy some requirements:\n\n# Build a vector of numbers ranging from 1 to 10\nvec_num &lt;- 1:10\n\n# Check which of these numbers are smaller than 5\nvec_num &lt; 5\n\n [1]  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE\n\n\nThis will become important later on, when we want to subset vectors and data frames to extract only those values that satisfy some requirements we defined."
  },
  {
    "objectID": "qmd/basics/basics.html#in",
    "href": "qmd/basics/basics.html#in",
    "title": "Basic operations",
    "section": "",
    "text": "The %in% operator is used to check for each element of its first argument if it is part of the second argument:\n\nc(\"Monica\", \"Rachel\", \"Barny\") %in% c(\"Monica\", \"Rachel\", \"Ross\", \"Joey\", \"Phoebe\", \"Chandler\")\n\n[1]  TRUE  TRUE FALSE"
  },
  {
    "objectID": "qmd/basics/basics.html#section",
    "href": "qmd/basics/basics.html#section",
    "title": "Basic operations",
    "section": "",
    "text": "We can invert boolean values by using !:\n\n!TRUE\n\n[1] FALSE\n\n!(1 &gt; 100)\n\n[1] TRUE"
  },
  {
    "objectID": "qmd/basics/basics.html#functions",
    "href": "qmd/basics/basics.html#functions",
    "title": "Basic operations",
    "section": "",
    "text": "Everything that does something in R is a function. A function call has the form: functionname(argument1 = value, argument2 = value, ...). One basic example for a function is the function that can calculate the square root:\n\nsqrt(4)\n\n[1] 2\n\n\nWe can also assign the name of the function argument to our value. This is clearer, as we don’t rely on the order of the function arguments:\n\nrep(4, 10)\n\n [1] 4 4 4 4 4 4 4 4 4 4\n\n\nwill rep 4 10 times. If we swap the arguments, the 10 will be repeat 4 times:\n\nrep(10, 4)\n\n[1] 10 10 10 10\n\n\nBut if we specify which value belongs to which function argument, the order doesn’t matter:\n\nrep(times = 10, x = 4)\n\n [1] 4 4 4 4 4 4 4 4 4 4\n\n\nHow do we know which arguments a function has?:"
  },
  {
    "objectID": "qmd/basics/basics.html#help",
    "href": "qmd/basics/basics.html#help",
    "title": "Basic operations",
    "section": "",
    "text": "One of the most important functions in R is the help-function ?:\n\n?rep\n\nwill open the documentation for the function with the description of its usage, details about the arguments … In the next chapter we will take a very quick look at R’s data types."
  },
  {
    "objectID": "qmd/getting_started/data_sets.html",
    "href": "qmd/getting_started/data_sets.html",
    "title": "Data sets",
    "section": "",
    "text": "We will use two data sets during this workshop. One for the theory, and one for you to work on in the exercises."
  },
  {
    "objectID": "qmd/getting_started/data_sets.html#theory-olympic-athletes",
    "href": "qmd/getting_started/data_sets.html#theory-olympic-athletes",
    "title": "Data sets",
    "section": "Theory: Olympic athletes",
    "text": "Theory: Olympic athletes\n1\nFor the theory part of the workshop, we will mainly work with the athletes data set, downloaded from here. It contains the Olympic athletes from 1896 to 2016, along with some basic stats, their sport and country, and the medals they won. Our goal for the theory part of this workshop is to plot the number of medals by country in each sport, and learn R along the way!"
  },
  {
    "objectID": "qmd/getting_started/data_sets.html#exercises-fictional-characters",
    "href": "qmd/getting_started/data_sets.html#exercises-fictional-characters",
    "title": "Data sets",
    "section": "Exercises: Fictional characters",
    "text": "Exercises: Fictional characters\n2\nOver the course of this workshop, you can work on exercises to train the theoretical knowledge acquired in the chapters. Most of these exercises will use the characters data set, downloaded from here, which contains psychometric ratings for different fictional characters, rated by a large number of people on a personality scale developed by the author of the questionnaire.\nYou will load the data, prepare it for analyses and also plot it in the end."
  },
  {
    "objectID": "qmd/getting_started/data_sets.html#footnotes",
    "href": "qmd/getting_started/data_sets.html#footnotes",
    "title": "Data sets",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nImage by Ilse Orsen on Unsplash.↩︎\nImage by Ilse Orsen on Unsplash.↩︎"
  },
  {
    "objectID": "qmd/merging/merging.html",
    "href": "qmd/merging/merging.html",
    "title": "Merging data",
    "section": "",
    "text": "Previous code\n\n\n\n\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nathletes &lt;- readRDS(file = here::here(\"raw_data\", \"athletes.rds\"))"
  },
  {
    "objectID": "qmd/merging/merging.html#data-set",
    "href": "qmd/merging/merging.html#data-set",
    "title": "Merging data",
    "section": "Data set",
    "text": "Data set\nIn the end, we want to plot the number of gold medals the countries have won on a world map. To do that, we need a data set containing coordinates of the different countries. Luckily, ggplot2 (part of the tidyverse) provides a fitting data set. Let’s download it and load it into R:\n\nworld_coordinates &lt;- readRDS(file = here::here(\"raw_data\", \"world_coordinates.rds\"))\n\nAlso, let’s load our athletes data set, in case you didn’t already:\n\nathletes &lt;- readRDS(file = here::here(\"raw_data\", \"athletes.rds\"))"
  },
  {
    "objectID": "qmd/merging/merging.html#before-merging",
    "href": "qmd/merging/merging.html#before-merging",
    "title": "Merging data",
    "section": "Before merging",
    "text": "Before merging\nRight now, we have multiple rows for each country in both data sets. This will not be possible to merge easily, so we have to reduce our athletes data first. As you know, our goal is to plot the number of gold medals each country has won. So, we need to calculate how many gold medals each country has won over time. Let’s do that quickly, using some tidyverse functions. It is not especially important you understand and know everything that happens here, but we need it for the next chapters, so here it goes:\n\n\nmedal_counts &lt;- athletes %&gt;%\n  filter(Medal == \"Gold\") %&gt;%\n  group_by(Region) %&gt;%\n  count(Medal) \n\nmedal_counts\n\n# A tibble: 99 × 3\n# Groups:   Region [99]\n   Region     Medal     n\n   &lt;chr&gt;      &lt;chr&gt; &lt;int&gt;\n 1 Algeria    Gold      5\n 2 Argentina  Gold     91\n 3 Armenia    Gold      2\n 4 Australia  Gold    368\n 5 Austria    Gold    108\n 6 Azerbaijan Gold      7\n 7 Bahamas    Gold     14\n 8 Bahrain    Gold      1\n 9 Belarus    Gold     24\n10 Belgium    Gold     98\n# ℹ 89 more rows\n\n\n\nWhat happens here? We extract all rows containing gold medals, group them by region, so our next operation is performed region wise, and not for the whole data set. Then we count how many gold medals each region got."
  },
  {
    "objectID": "qmd/merging/merging.html#merging",
    "href": "qmd/merging/merging.html#merging",
    "title": "Merging data",
    "section": "Merging",
    "text": "Merging\nTo merge two data frames that include information that belongs together, we need a common column, on which we can combine them. In our case, this is the column containing the country. They are both named region, but one with an upper case R. This doesn’t pose a problem, as we can define which columns should be taken from which data frame for merging. Let’s take a quick look before to see if there are any countries named differently in both data sets (this simply combines commands we have already looked at in the Basic operations chapter:\n\nmedal_counts$Region[!(medal_counts$Region %in% world_coordinates$region)]\n\n[1] \"Individual Olympic Athletes\"\n\n\nLooks like all of the countries in our medal_countries data frame can be also found in our world_coordinates frame. Only athletes without a country will be lost when merging, but that’s ok for now, as we are interested in the country specific gold medal counts. So let’s merge:\n\nmedal_countries &lt;- merge(\n  x = medal_counts,\n  y = world_coordinates,\n  by.x = \"Region\",\n  by.y = \"region\",\n  all.x = FALSE,\n  all.y = TRUE\n)\n\nhead(medal_countries)\n\n       Region Medal  n     long      lat group order subregion\n1 Afghanistan  &lt;NA&gt; NA 74.89131 37.23164     2    12      &lt;NA&gt;\n2 Afghanistan  &lt;NA&gt; NA 74.84023 37.22505     2    13      &lt;NA&gt;\n3 Afghanistan  &lt;NA&gt; NA 74.76738 37.24917     2    14      &lt;NA&gt;\n4 Afghanistan  &lt;NA&gt; NA 74.73896 37.28564     2    15      &lt;NA&gt;\n5 Afghanistan  &lt;NA&gt; NA 74.72666 37.29072     2    16      &lt;NA&gt;\n6 Afghanistan  &lt;NA&gt; NA 74.66895 37.26670     2    17      &lt;NA&gt;\n\n\nNote that we also used the all.x and all.y arguments. In this example, we want to take all rows from the second data set, but only those from the first data set, that have a match in the second data set. This is necessary, because we want to plot all countries later on, but only those we have coordinates for, because they won’t show up on the map otherwise.\nUsing the tidyverse, we first have to rename our region column, as the column names need to be the same over both data sets that are merged. left_join() means that we will merge onto the first data set (world_coordinates in the code below), like we have done using the all.x and all.y arguments in the merge() function.\n\n\nmedal_countries &lt;- world_coordinates %&gt;%\n  rename(\"Region\" = region) %&gt;%\n  left_join(medal_counts)\n\nJoining with `by = join_by(Region)`\n\nhead(medal_countries)\n\n       long      lat group order Region subregion Medal  n\n1 -69.89912 12.45200     1     1  Aruba      &lt;NA&gt;  &lt;NA&gt; NA\n2 -69.89571 12.42300     1     2  Aruba      &lt;NA&gt;  &lt;NA&gt; NA\n3 -69.94219 12.43853     1     3  Aruba      &lt;NA&gt;  &lt;NA&gt; NA\n4 -70.00415 12.50049     1     4  Aruba      &lt;NA&gt;  &lt;NA&gt; NA\n5 -70.06612 12.54697     1     5  Aruba      &lt;NA&gt;  &lt;NA&gt; NA\n6 -70.05088 12.59707     1     6  Aruba      &lt;NA&gt;  &lt;NA&gt; NA\n\n\n\nGreat! Now the information that belongs together is stored together."
  },
  {
    "objectID": "qmd/format/format_exercise.html",
    "href": "qmd/format/format_exercise.html",
    "title": "Reshaping: Exercise",
    "section": "",
    "text": "Previous code\n\n\n\n\n\n\nlibrary(tidyverse)\n\n## Load the data\ncharacters &lt;- readRDS(file = here::here(\"raw_data\", \"characters.rds\"))\npsych_stats &lt;- read.csv(\n  file = here::here(\"raw_data\", \"psych_stats.csv\"),\n  sep = \";\"\n)\n\n## Take a look at the data sets\nstr(characters)\n\n'data.frame':   889 obs. of  7 variables:\n $ id        : chr  \"F2\" \"F1\" \"F5\" \"F4\" ...\n $ name      : chr  \"Monica Geller\" \"Rachel Green\" \"Chandler Bing\" \"Joey Tribbiani\" ...\n $ uni_id    : chr  \"F\" \"F\" \"F\" \"F\" ...\n $ uni_name  : chr  \"Friends\" \"Friends\" \"Friends\" \"Friends\" ...\n $ notability: num  79.7 76.7 74.4 74.3 72.6 51.6 86.5 84.2 82.6 65.6 ...\n $ link      : chr  \"https://openpsychometrics.org/tests/characters/stats/F/2\" \"https://openpsychometrics.org/tests/characters/stats/F/1\" \"https://openpsychometrics.org/tests/characters/stats/F/5\" \"https://openpsychometrics.org/tests/characters/stats/F/4\" ...\n $ image_link: chr  \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/2.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/1.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/5.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/4.jpg\" ...\n\nstr(psych_stats)\n\n'data.frame':   889 obs. of  365 variables:\n $ char_id                                     : chr  \"F2\" \"F1\" \"F5\" \"F4\" ...\n $ messy_neat                                  : num  95.7 30.2 45.3 13 20.9 ...\n $ disorganized_self.disciplined               : num  95.2 25.9 42.4 11 20.9 75.6 10.4 31.9 39.6 31.1 ...\n $ diligent_lazy                               : num  6.1 51.8 52.2 78.1 45.2 ...\n $ on.time_tardy                               : num  6.2 77.9 57.1 84.1 74 20.6 85.7 68.3 73.6 58.2 ...\n $ competitive_cooperative                     : num  6.4 28.9 42.8 44.2 55.3 ...\n $ scheduled_spontaneous                       : num  6.6 72.3 54.9 91.3 94.9 ...\n $ ADHD_OCD                                    : num  92.9 31.8 26.7 10.4 12.8 70.1 35.5 30.1 51.8 39.2 ...\n $ chaotic_orderly                             : num  92.2 27 38.2 12.6 11.2 68.8 6.8 20.6 23.4 28.8 ...\n $ motivated_unmotivated                       : num  7.8 31.8 52.3 45.6 24.7 31.5 80.9 30.5 40.8 50.7 ...\n $ bossy_meek                                  : num  7.9 30.6 64.8 60.8 40.1 ...\n $ persistent_quitter                          : num  7.9 35.8 43.9 33.8 21.3 ...\n $ overachiever_underachiever                  : num  8.2 43.8 55.8 68.8 51.3 23.2 67.7 36.7 44.1 44.4 ...\n $ muddy_washed                                : num  91 80.2 58.7 42.7 48.1 64.6 27.6 62.4 70.1 69.2 ...\n $ beautiful_ugly                              : num  9.2 5.3 26.2 11 11.4 ...\n $ slacker_workaholic                          : num  90.8 45.9 53.4 17.6 32 81.5 23.8 30.1 33.2 34.6 ...\n $ driven_unambitious                          : num  9.5 30.3 49.8 49.4 43.4 22.7 58.5 34.1 32 47.4 ...\n $ outlaw_sheriff                              : num  90.3 39.3 46.7 23.8 16.1 85.4 21.4 22.7 27.3 30.1 ...\n $ precise_vague                               : num  9.9 64.7 53.2 78 78.1 25.4 68.4 60.1 47.3 61.7 ...\n $ bad.cook_good.cook                          : num  90 11.1 28.2 31.2 29.4 35.9 27.3 46.2 43.8 52.8 ...\n $ manicured_scruffy                           : num  10.6 7.7 45.6 47.6 62.5 20.5 81.3 37.3 20.3 20.9 ...\n $ lenient_strict                              : num  89.3 34.2 28.8 11 15.4 76.7 15.2 24.2 38.9 21.5 ...\n $ relaxed_tense                               : num  89 58.8 66.4 10.4 16.9 88.9 69.9 64.2 54.5 64.8 ...\n $ demanding_unchallenging                     : num  11 23.9 58.3 66.3 57.1 28.5 35.9 37.8 16.8 60.3 ...\n $ drop.out_valedictorian                      : num  88.9 32.5 47 14.9 22.1 87.7 12.5 29.6 36.5 51.2 ...\n $ go.getter_slugabed                          : num  11.7 31.3 52.6 48.1 27.6 41.8 62.6 33.9 27.3 51.1 ...\n $ competent_incompetent                       : num  11.9 47.1 37.1 77.2 53.6 37.8 51.9 41.1 35.2 56.1 ...\n $ aloof_obsessed                              : num  88.1 62.3 52.3 35.1 33.2 80.8 75.1 54.9 70.7 61.9 ...\n $ flexible_rigid                              : num  87.8 41.8 45.9 17.3 13.9 83.7 45.9 27.4 55 32.1 ...\n $ active_slothful                             : num  12.2 33.1 61.1 56.7 31.4 48.8 73.9 19.8 29.2 35.5 ...\n $ loose_tight                                 : num  87.4 43.2 44.3 14 15.3 82.5 28.1 26 44.8 43.6 ...\n $ pointed_random                              : num  12.8 49.9 67.1 86.2 87.4 36.7 65.4 53.1 36.9 56.2 ...\n $ fresh_stinky                                : num  12.9 14.6 31.9 44.3 39.2 44.3 64.4 30.2 18.2 24.6 ...\n $ dominant_submissive                         : num  13.6 41.6 73.7 40.2 30.9 69.5 43.5 52.6 36.9 77.9 ...\n $ anxious_calm                                : num  13.7 28.8 20 66.1 58 11.9 12 32.1 37.1 29.8 ...\n $ clean_perverted                             : num  13.7 42.5 56.8 77.5 59.4 44 53.1 51.2 61.9 50.6 ...\n $ neutral_opinionated                         : num  86.3 74.6 67.2 43.4 76.6 84.2 67.3 77.9 82.5 43.9 ...\n $ always.down_picky                           : num  85.9 72.6 49.8 27.1 35.2 71.9 23.6 36.2 71.8 36.2 ...\n $ hurried_leisurely                           : num  14.6 55.1 55.9 85.9 81 22.1 48.6 45.6 49 39.3 ...\n $ attractive_repulsive                        : num  14.7 9.4 28.5 15.7 18.2 ...\n $ devoted_unfaithful                          : num  14.8 29.1 22.6 41.5 19.6 47.5 34.1 55.7 42.7 48.2 ...\n $ helpless_resourceful                        : num  85 41.4 56.6 37.9 70.6 52.4 41.4 51.5 36.2 29.8 ...\n $ deliberate_spontaneous                      : num  15.1 71.7 56.5 89.1 92.9 20.9 78.6 88.3 64 60.9 ...\n $ plays.hard_works.hard                       : num  84.7 41.3 46.5 13.7 26 81.2 28.2 30 19.9 26.4 ...\n $ imaginative_practical                       : num  84.7 37.9 54.6 17 5.4 ...\n $ frenzied_sleepy                             : num  15.5 29.9 34.7 55.6 30 31.1 59.4 25.2 19 46 ...\n $ queer_straight                              : num  84.3 84.1 65.4 84.3 45.4 77.9 10.2 4.8 73.4 64.1 ...\n $ assertive_passive                           : num  15.8 40.4 66.3 44.3 39.3 60.9 45.1 45.8 23.4 63.3 ...\n $ fast.talking_slow.talking                   : num  15.9 20.8 18.3 42.2 21.7 49.6 69.5 34.3 32.5 44.5 ...\n $ astonishing_methodical                      : num  83.8 28 49.9 19.2 17.4 83 31.2 27.4 36 32.7 ...\n $ hoarder_unprepared                          : num  16.2 70 63.5 82 54.9 35.5 60.3 64.5 48.3 67.8 ...\n $ consistent_variable                         : num  16.6 60.2 46.3 63.1 79.3 39.5 72 65.3 69.7 62.3 ...\n $ involved_remote                             : num  16.7 26.3 42.7 30.2 36.7 36.6 62.2 39.3 26.4 38.7 ...\n $ backdoor_official                           : num  83.3 51.9 47.4 24.4 20.4 76.4 29.1 29.3 53.5 36.7 ...\n $ captain_first.mate                          : num  16.7 52.7 73.5 74.2 57.9 68.4 55.9 51 19 73.6 ...\n $ refined_rugged                              : num  17.3 18.9 48.4 74.4 69.9 24.4 81.6 48 31.4 40.7 ...\n $ accommodating_stubborn                      : num  82.7 77.2 48.2 43.9 48.3 78.5 78.1 69 85.9 41.5 ...\n $ barbaric_civilized                          : num  82.6 76.5 66.6 32.9 39.9 77 33.4 44.4 36.7 55.5 ...\n $ alpha_beta                                  : num  17.7 37.9 73.9 33.6 41.9 78.2 44.3 37.4 17.5 66.6 ...\n $ loyal_traitorous                            : num  17.8 32.3 20 15.3 14.5 40.3 29.2 43.1 47.2 33.2 ...\n $ trash_treasure                              : num  82 80.1 82.2 78.4 83.2 47.8 64.5 62.2 68.2 78.4 ...\n $ fast_slow                                   : num  18.1 43.7 38.1 69 55.3 60.4 57.8 29.4 30 54.5 ...\n $ perceptive_unobservant                      : num  18.3 59.5 41.5 80 41.1 48.6 21.6 33.3 28 49 ...\n $ goof.off_studious                           : num  81.4 33.2 20.7 7.4 16.6 ...\n $ feminist_sexist                             : num  18.6 23.3 43.9 62 10.5 ...\n $ desperate_high.standards                    : num  81.1 69.2 30.7 36.8 56.7 29.2 33.7 32.5 61.7 25.8 ...\n $ impatient_patient                           : num  18.9 21.9 34 25.7 39.1 25.8 23.8 35.1 18 57.2 ...\n $ preppy_punk.rock                            : num  18.9 16.4 41.5 49.5 73.2 14.4 87.7 74.4 26.4 18.2 ...\n $ naive_paranoid                              : num  80.7 35.5 66.6 22 39.7 71.6 69.6 45.6 50.7 32.1 ...\n $ important_irrelevant                        : num  19.3 22.3 24.6 24.7 26.4 47.4 12.5 14.8 16.4 33.4 ...\n $ apprentice_master                           : num  80.6 42.3 44.9 36.3 61.5 60.8 48 48 73 31.5 ...\n $ healthy_sickly                              : num  19.6 17.8 39.1 26.9 22.6 37 88.9 65.7 56.7 45.5 ...\n $ morning.lark_night.owl                      : num  19.6 69.9 58.3 80.4 61.9 23.2 90.6 81.9 90.1 78.3 ...\n $ alert_oblivious                             : num  19.6 70.7 55.5 87.6 78.9 57.1 54.7 48.9 38.3 67.4 ...\n $ f....the.police_tattle.tale                 : num  80 57.5 56.7 34.4 13.7 ...\n $ experimental_reliable                       : num  79.7 37.8 62 35 22.2 61.7 28 26.5 30.4 39.8 ...\n $ loud_quiet                                  : num  20.4 20.8 25 10.6 15.3 39.5 71.9 42.7 13.2 55.2 ...\n $ high.IQ_low.IQ                              : num  20.5 56.7 28.8 82.6 50.6 19.3 30.9 26.1 47.7 55.6 ...\n $ oppressed_privileged                        : num  79.2 85.4 67.2 66.5 42.1 84.3 22.4 19.6 59.9 63.4 ...\n $ animalistic_human                           : num  79.2 75.6 73.7 43.8 42.1 69.3 70.4 55.9 64.4 73.2 ...\n $ still_twitchy                               : num  79.2 68.6 79.9 76.9 83.6 81.9 77.9 67.4 60.1 58.4 ...\n $ thick_thin                                  : num  78.8 79.6 52.8 35.2 69.2 60.6 73.3 81.4 66.1 48.8 ...\n $ repetitive_varied                           : num  21.3 44.5 40.9 43.4 74.1 18.4 40.1 68.4 47.3 42.1 ...\n $ rational_whimsical                          : num  21.7 72.3 54.4 86.8 93 27.4 67 78.7 69.6 70.9 ...\n $ egalitarian_racist                          : num  21.7 27.8 24.7 24.3 10.7 ...\n $ disreputable_prestigious                    : num  78.2 66.2 47 32.5 36.7 68.2 21.2 42.5 65.2 45.8 ...\n $ ignorant_knowledgeable                      : num  78.2 37.7 66.9 22.2 59.9 68.5 60.8 68.1 44.2 42.6 ...\n $ hard.work_natural.talent                    : num  21.9 47.5 41.8 69.8 71.2 29.2 55.8 67.5 65.8 57.3 ...\n $ androgynous_gendered                        : num  78.1 89.4 68.5 82.5 60.1 78.1 32.6 43.4 88.3 87.9 ...\n $ dispassionate_romantic                      : num  77.9 80.5 64.7 69.6 74.9 67.2 61.5 64.8 59.1 82.3 ...\n $ eloquent_unpolished                         : num  22.1 32.1 56.1 79.8 69 33.7 76.3 45.2 35 42.9 ...\n $ permanent_transient                         : num  22.2 56.1 39 59.6 71.1 31.9 68.5 79.7 57.2 70.6 ...\n $ intense_lighthearted                        : num  22.2 50.8 73.8 79.8 64.2 28.2 22.4 34.7 18.2 44.3 ...\n $ mischievous_well.behaved                    : num  77.8 34.2 30.6 15.8 20.3 71.4 13.3 19.4 17.6 38.2 ...\n $ adventurous_stick.in.the.mud                : num  77.7 37.4 59.7 14.4 8 ...\n $ obedient_rebellious                         : num  22.3 69.2 42.9 72.9 86.2 16.5 92.3 87.1 84.2 38.1 ...\n $ authoritarian_democratic                    : num  22.4 55.2 70 72.1 75.4 41.6 68 67.4 21.8 68.9 ...\n $ city.slicker_country.bumpkin                : num  22.7 9 22.4 18.4 42.6 18.8 26.5 20.2 16.8 24 ...\n $ traditional_unorthodox                      : num  22.8 52.8 54.9 67.2 90 23.1 85.7 90.2 74.5 62.6 ...\n  [list output truncated]"
  },
  {
    "objectID": "qmd/format/format_exercise.html#exercise-1",
    "href": "qmd/format/format_exercise.html#exercise-1",
    "title": "Reshaping: Exercise",
    "section": "Exercise 1",
    "text": "Exercise 1\nTake a look at the data frame psych_stats! Which format does it have?\n\nWide format\nLong format\nNone of the above\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nWide format\nLong format\nNone of the above\n\nEach unit of observation, in this case each character, only has one row."
  },
  {
    "objectID": "qmd/format/format_exercise.html#exercise-2",
    "href": "qmd/format/format_exercise.html#exercise-2",
    "title": "Reshaping: Exercise",
    "section": "Exercise 2",
    "text": "Exercise 2\nReshape it, so there are only three columns in the data set: char_id, question and rating.\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou can select multiple columns like this: column_1:column_10.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\npsych_stats &lt;- psych_stats %&gt;%\n  pivot_longer(cols = messy_neat:innocent_jaded, \n               names_to = \"question\", \n               values_to = \"rating\")\n\nhead(psych_stats)\n\n# A tibble: 6 × 3\n  char_id question                      rating\n  &lt;chr&gt;   &lt;chr&gt;                          &lt;dbl&gt;\n1 F2      messy_neat                     95.7 \n2 F2      disorganized_self.disciplined  95.2 \n3 F2      diligent_lazy                   6.10\n4 F2      on.time_tardy                   6.2 \n5 F2      competitive_cooperative         6.40\n6 F2      scheduled_spontaneous           6.60\n\n\nNow we have multiple rows for every character, but all question ratings are nicely aligned in one column."
  },
  {
    "objectID": "qmd/format/format_exercise.html#exercise-3",
    "href": "qmd/format/format_exercise.html#exercise-3",
    "title": "Reshaping: Exercise",
    "section": "Exercise 3",
    "text": "Exercise 3\nTry to reshape the data into long format.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\npsych_stats %&gt;%\n  pivot_wider(id_cols = char_id, \n               names_from = \"question\", \n               values_from = \"rating\")\n\n# A tibble: 889 × 365\n   char_id messy_neat disorganized_self.disciplined diligent_lazy on.time_tardy\n   &lt;chr&gt;        &lt;dbl&gt;                         &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt;\n 1 F2           95.7                           95.2          6.10           6.2\n 2 F1           30.2                           25.9         51.8           77.9\n 3 F5           45.3                           42.4         52.2           57.1\n 4 F4           13                             11           78.1           84.1\n 5 F3           20.9                           20.9         45.2           74  \n 6 F6           81                             75.6         20             20.6\n 7 EU1           9.60                          10.4         62.3           85.7\n 8 EU2          27.7                           31.9         23.7           68.3\n 9 EU6          40                             39.6         54.1           73.6\n10 EU3          43.9                           31.1         32.2           58.2\n# ℹ 879 more rows\n# ℹ 360 more variables: competitive_cooperative &lt;dbl&gt;,\n#   scheduled_spontaneous &lt;dbl&gt;, ADHD_OCD &lt;dbl&gt;, chaotic_orderly &lt;dbl&gt;,\n#   motivated_unmotivated &lt;dbl&gt;, bossy_meek &lt;dbl&gt;, persistent_quitter &lt;dbl&gt;,\n#   overachiever_underachiever &lt;dbl&gt;, muddy_washed &lt;dbl&gt;, beautiful_ugly &lt;dbl&gt;,\n#   slacker_workaholic &lt;dbl&gt;, driven_unambitious &lt;dbl&gt;, outlaw_sheriff &lt;dbl&gt;,\n#   precise_vague &lt;dbl&gt;, bad.cook_good.cook &lt;dbl&gt;, manicured_scruffy &lt;dbl&gt;, …\n\n\nThis is how we got it! But scratch that, that was just for the sake of the exercise. We want to use psych_stats in the long format from now on."
  },
  {
    "objectID": "qmd/peeking/peeking.html",
    "href": "qmd/peeking/peeking.html",
    "title": "Getting an overview",
    "section": "",
    "text": "Previous code\n\n\n\n\n\n\nathletes &lt;- readRDS(file = here::here(\"raw_data\", \"athletes.rds\"))\nBefore starting to do something with your data, it is always a good idea to get an overview. Our goal is to answer questions in the line of:\nTo answer these questions, we have different tools at our disposal:"
  },
  {
    "objectID": "qmd/peeking/peeking.html#view",
    "href": "qmd/peeking/peeking.html#view",
    "title": "Getting an overview",
    "section": "View()",
    "text": "View()\nView() will open the data set excel-style in a new window:\n\nView(athletes)\n\nIn this window we can sort and filter, which makes it a pretty useful tool."
  },
  {
    "objectID": "qmd/peeking/peeking.html#head",
    "href": "qmd/peeking/peeking.html#head",
    "title": "Getting an overview",
    "section": "head()",
    "text": "head()\nHead helps you to get an overview of the data frame, as it prints the first six rows into your console:\n\nhead(athletes)\n\n  NOC     ID                  Name Sex Age Height Weight        Team\n1 AFG 132181           Najam Yahya   M  NA     NA     NA Afghanistan\n2 AFG  87371 Ahmad Jahan Nuristani   M  NA     NA     NA Afghanistan\n3 AFG  44977     Mohammad Halilula   M  28    163     57 Afghanistan\n4 AFG    502     Ahmad Shah Abouwi   M  NA     NA     NA Afghanistan\n5 AFG 109153    Shakar Khan Shakar   M  24     NA     74 Afghanistan\n6 AFG  29626  Sultan Mohammad Dost   M  28    168     73 Afghanistan\n        Games Year Season      City     Sport\n1 1956 Summer 1956 Summer Melbourne    Hockey\n2 1948 Summer 1948 Summer    London    Hockey\n3 1980 Summer 1980 Summer    Moskva Wrestling\n4 1956 Summer 1956 Summer Melbourne    Hockey\n5 1964 Summer 1964 Summer     Tokyo Wrestling\n6 1960 Summer 1960 Summer      Roma Wrestling\n                                    Event Medal      Region\n1                     Hockey Men's Hockey  &lt;NA&gt; Afghanistan\n2                     Hockey Men's Hockey  &lt;NA&gt; Afghanistan\n3 Wrestling Men's Bantamweight, Freestyle  &lt;NA&gt; Afghanistan\n4                     Hockey Men's Hockey  &lt;NA&gt; Afghanistan\n5 Wrestling Men's Welterweight, Freestyle  &lt;NA&gt; Afghanistan\n6 Wrestling Men's Welterweight, Freestyle  &lt;NA&gt; Afghanistan"
  },
  {
    "objectID": "qmd/peeking/peeking.html#str",
    "href": "qmd/peeking/peeking.html#str",
    "title": "Getting an overview",
    "section": "str()",
    "text": "str()\nThis one is actually my favorite, as for bigger data sets it is often more feasible to only look at the structure and not the whole data set. It looks a bit different to what we are used to though:\n\nstr(athletes)\n\n'data.frame':   270767 obs. of  16 variables:\n $ NOC   : chr  \"AFG\" \"AFG\" \"AFG\" \"AFG\" ...\n $ ID    : int  132181 87371 44977 502 109153 29626 1076 121376 80210 87374 ...\n $ Name  : chr  \"Najam Yahya\" \"Ahmad Jahan Nuristani\" \"Mohammad Halilula\" \"Ahmad Shah Abouwi\" ...\n $ Sex   : chr  \"M\" \"M\" \"M\" \"M\" ...\n $ Age   : int  NA NA 28 NA 24 28 28 NA NA NA ...\n $ Height: int  NA NA 163 NA NA 168 NA NA NA NA ...\n $ Weight: num  NA NA 57 NA 74 73 NA NA 57 NA ...\n $ Team  : chr  \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ...\n $ Games : chr  \"1956 Summer\" \"1948 Summer\" \"1980 Summer\" \"1956 Summer\" ...\n $ Year  : int  1956 1948 1980 1956 1964 1960 1936 1956 1972 1956 ...\n $ Season: chr  \"Summer\" \"Summer\" \"Summer\" \"Summer\" ...\n $ City  : chr  \"Melbourne\" \"London\" \"Moskva\" \"Melbourne\" ...\n $ Sport : chr  \"Hockey\" \"Hockey\" \"Wrestling\" \"Hockey\" ...\n $ Event : chr  \"Hockey Men's Hockey\" \"Hockey Men's Hockey\" \"Wrestling Men's Bantamweight, Freestyle\" \"Hockey Men's Hockey\" ...\n $ Medal : chr  NA NA NA NA ...\n $ Region: chr  \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ...\n\n\nHere, the column names are printed on the left side, followed by the type of the column and then the first few values of each column. We can also see at the top that this object is a data frame with 270767 rows and 16 columns."
  },
  {
    "objectID": "qmd/peeking/peeking.html#summary",
    "href": "qmd/peeking/peeking.html#summary",
    "title": "Getting an overview",
    "section": "summary()",
    "text": "summary()\nFinally, to get a more thourough overview of our variables, we can use summary():\n\nsummary(athletes)\n\n     NOC                  ID             Name               Sex           \n Length:270767      Min.   :     1   Length:270767      Length:270767     \n Class :character   1st Qu.: 34630   Class :character   Class :character  \n Mode  :character   Median : 68187   Mode  :character   Mode  :character  \n                    Mean   : 68229                                        \n                    3rd Qu.:102066                                        \n                    Max.   :135571                                        \n                                                                          \n      Age            Height          Weight           Team          \n Min.   :10.00   Min.   :127.0   Min.   : 25.00   Length:270767     \n 1st Qu.:21.00   1st Qu.:168.0   1st Qu.: 60.00   Class :character  \n Median :24.00   Median :175.0   Median : 70.00   Mode  :character  \n Mean   :25.56   Mean   :175.3   Mean   : 70.71                     \n 3rd Qu.:28.00   3rd Qu.:183.0   3rd Qu.: 79.00                     \n Max.   :97.00   Max.   :226.0   Max.   :214.00                     \n NA's   :9462    NA's   :60083   NA's   :62785                      \n    Games                Year         Season              City          \n Length:270767      Min.   :1896   Length:270767      Length:270767     \n Class :character   1st Qu.:1960   Class :character   Class :character  \n Mode  :character   Median :1988   Mode  :character   Mode  :character  \n                    Mean   :1978                                        \n                    3rd Qu.:2002                                        \n                    Max.   :2016                                        \n                                                                        \n    Sport              Event              Medal              Region         \n Length:270767      Length:270767      Length:270767      Length:270767     \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n\n\nFor numeric columns we get their minimum and maximum, median and mean, as well as the first and third quantile. In case of missing values (NAs) their number is printed at the bottom (e.g., look at the Age column). We will look at how to deal with missings soon, but first we have to talk about subsetting data."
  },
  {
    "objectID": "qmd/data_structures/data_structures_exercise.html",
    "href": "qmd/data_structures/data_structures_exercise.html",
    "title": "Data Structures: Exercises",
    "section": "",
    "text": "Examine this object:\n\nobj\n\n[[1]]\n[1] 3 5 1\n\n[[2]]\n[1] \"a\"\n\n\n\nWhat kind of data structure is obj?\n\nData frame\nVector\nList\nMatrix\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nData frame\nVector\nList\nMatrix\n\n\n\n\n\nAnd what types of vectors are included?\n\nNumeric and character.\nCharacter and logical.\nOnly numeric.\nOnly character.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nNumeric and character.\nCharacter and logical.\nOnly numeric.\nOnly character."
  },
  {
    "objectID": "qmd/data_structures/data_structures_exercise.html#data-structures",
    "href": "qmd/data_structures/data_structures_exercise.html#data-structures",
    "title": "Data Structures: Exercises",
    "section": "",
    "text": "Examine this object:\n\nobj\n\n[[1]]\n[1] 3 5 1\n\n[[2]]\n[1] \"a\"\n\n\n\nWhat kind of data structure is obj?\n\nData frame\nVector\nList\nMatrix\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nData frame\nVector\nList\nMatrix\n\n\n\n\n\nAnd what types of vectors are included?\n\nNumeric and character.\nCharacter and logical.\nOnly numeric.\nOnly character.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nNumeric and character.\nCharacter and logical.\nOnly numeric.\nOnly character."
  },
  {
    "objectID": "qmd/packages/packages.html",
    "href": "qmd/packages/packages.html",
    "title": "Packages",
    "section": "",
    "text": "1\nPackages are extensions to the base R you get by default. Most times they provide many new functions, bundled around a specific use case. When working with R you will have to rely heavily on packages developed by others. There are many, many great packages out there facilitating your work with R and making possible many different analyses, visualizations and many more.\nWe can compare them somewhat to apps in an appstore:\n2 First, we have to install the package: install.packages(\"packagename\"). Most of the openly available packages lie on CRAN (Comprehensive R Archive Network). But you can also download packages form other sources, for example GitHub.\n3 Then, we have to load them in each session where we want to use them (like tapping on the app icon): library(packagename)."
  },
  {
    "objectID": "qmd/packages/packages.html#install-packages",
    "href": "qmd/packages/packages.html#install-packages",
    "title": "Packages",
    "section": "Install packages",
    "text": "Install packages\nBefore we can use packages we have to install them once. Most packages are hosted via the Comprehensive R Archive Network (CRAN), to install a package from there, we can use:\n\ninstall.packages(\"aRtsy\")\n\nBut often packages are only (or as well) provided via GitHub. To install a package from there, use:\n\ndevtools::install_github(\"cutterkom/generativeart\")"
  },
  {
    "objectID": "qmd/packages/packages.html#load-packages",
    "href": "qmd/packages/packages.html#load-packages",
    "title": "Packages",
    "section": "Load packages",
    "text": "Load packages\nAfter installing a package, we have to load it into our R session. Optimally we do this for all packages we are going to use at the top of our script, so dependencies are easy to spot.\n\nlibrary(aRtsy)\n\nNow we are free to use it, in this case to generate some artwork:\n\nset.seed(1)\ncanvas_collatz(colors = colorPalette(\"lava\"))"
  },
  {
    "objectID": "qmd/packages/packages.html#function-conflicts",
    "href": "qmd/packages/packages.html#function-conflicts",
    "title": "Packages",
    "section": "Function conflicts",
    "text": "Function conflicts\n\n\n\n\n\n\nExpand to learn about dealing with identical function names from different packages\n\n\n\n\n\nOf course it can happen that different packages include functions with the same name. For example, look at the warnings we get when installing and then loading the packages ggplot2 and psych:\n\ninstall.packages(\"ggplot2\")\ninstall.packages(\"psych\")\n\n\nlibrary(ggplot2)\nlibrary(psych)\n\n\nAttaching package: 'psych'\n\n\nThe following objects are masked from 'package:ggplot2':\n\n    %+%, alpha\n\n\nThere seems to be a function named alpha which is included in both packages (but not the same function, just the same name). The warning message notifies us that the object alpha from ggplot2 is masked, so if we call it, the alpha function from the psych package is used. To solve that quandary, we can use the :: operator. In front we write the package name, and behind it the name of the function we want to use from that package:\n\nggplot2::alpha()\npsych::alpha()"
  },
  {
    "objectID": "qmd/packages/packages.html#deliberate-package-management",
    "href": "qmd/packages/packages.html#deliberate-package-management",
    "title": "Packages",
    "section": "Deliberate package management",
    "text": "Deliberate package management\n\n\n\n\n\n\nExpand to learn about managing package versions\n\n\n\n\n\nFinally, a quick note on package management and reproducability of your code. R versions and package versions will change over time, in which case also the output of your code might change. Therefore, it is good practice to save the R version and package versions, so your code stays (kind of) reproducable for a longer period of time. The most straight forward thing to do is to just write down your R-version and the package versions at the top of your script. Call the versions you use with:\n\nsessionInfo()\n\nR version 4.3.1 (2023-06-16)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 22.04.3 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3 \nLAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.20.so;  LAPACK version 3.10.0\n\nlocale:\n [1] LC_CTYPE=C.UTF-8       LC_NUMERIC=C           LC_TIME=C.UTF-8       \n [4] LC_COLLATE=C.UTF-8     LC_MONETARY=C.UTF-8    LC_MESSAGES=C.UTF-8   \n [7] LC_PAPER=C.UTF-8       LC_NAME=C              LC_ADDRESS=C          \n[10] LC_TELEPHONE=C         LC_MEASUREMENT=C.UTF-8 LC_IDENTIFICATION=C   \n\ntime zone: UTC\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats     graphics  grDevices datasets  utils     methods   base     \n\nother attached packages:\n[1] psych_2.3.6   ggplot2_3.4.2\n\nloaded via a namespace (and not attached):\n [1] vctrs_0.6.3       nlme_3.1-162      cli_3.6.1         knitr_1.43       \n [5] rlang_1.1.1       xfun_0.39         generics_0.1.3    renv_1.0.0       \n [9] jsonlite_1.8.7    glue_1.6.2        colorspace_2.1-0  htmltools_0.5.5  \n[13] scales_1.2.1      fansi_1.0.4       rmarkdown_2.23    grid_4.3.1       \n[17] evaluate_0.21     munsell_0.5.0     tibble_3.2.1      fastmap_1.1.1    \n[21] yaml_2.3.7        lifecycle_1.0.3   compiler_4.3.1    dplyr_1.1.2      \n[25] pkgconfig_2.0.3   rstudioapi_0.15.0 lattice_0.21-8    digest_0.6.32    \n[29] R6_2.5.1          tidyselect_1.2.0  utf8_1.2.3        parallel_4.3.1   \n[33] mnormt_2.1.1      pillar_1.9.0      magrittr_2.0.3    withr_2.5.0      \n[37] tools_4.3.1       gtable_0.3.3     \n\n\nA more elegant approach to manage your packages is to use a dedicated package like renv, which will make it a lot easier to manage your package versions. But this is past the scope of this workshop, just keep in mind it might be something rewarding to look at, if you should start to programm more with R. Instead, let’s look at how to get data into R in the next chapter, so we can actually get to work with it."
  },
  {
    "objectID": "qmd/packages/packages.html#footnotes",
    "href": "qmd/packages/packages.html#footnotes",
    "title": "Packages",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nImage by Jan Antonin Kolar on [Unsplash]https://unsplash.com/de/fotos/lRoX0shwjUQ?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText).↩︎\nIcons from icons8.de.↩︎\nIcons from icons8.de.↩︎"
  },
  {
    "objectID": "qmd/functions/functions.html",
    "href": "qmd/functions/functions.html",
    "title": "Functions",
    "section": "",
    "text": "1"
  },
  {
    "objectID": "qmd/functions/functions.html#motivation",
    "href": "qmd/functions/functions.html#motivation",
    "title": "Functions",
    "section": "Motivation",
    "text": "Motivation\nLet’s assume we want to know the number of goldmedals a specific athlete has won, along with some additional data, all printed into the console.\nWell, we could do something like this: ::: tidy\n\nmedal_counts_athlete &lt;- athletes %&gt;%\n  # Extract all rows containing gold medal winners:\n  filter(Medal %in% c(\"Gold\")) %&gt;%\n  # Group them by name:\n  group_by(Name) %&gt;%\n  # Count the number of medals for each name:\n  count(Medal) \n\n# Extract all rows of Usain Bolt\nmedals_bolt &lt;- medal_counts_athlete %&gt;% \n  filter(Name == \"Usain St. Leo Bolt\")\n\n# Extract all rows of Usain bolt from the athletes data set\nstats_bolt &lt;- athletes %&gt;%\n  filter(Name == \"Usain St. Leo Bolt\") %&gt;%\n  ## sort the data frame by year:\n  arrange(Year)\n\n# Print a statement using the data we just have extracted: \nprint(\n  paste(\"Usain St. Leo Bolt participated in Olympic games in the year(s)\",\n        paste0(unique(stats_bolt$Year), collapse = \", \"), \n        \"and won\", \n        medals_bolt$n, \n        \"Goldmedal/s in total. The athletes sport was:\", \n        unique(stats_bolt$Sport), \n        \".\")\n  )\n\n[1] \"Usain St. Leo Bolt participated in Olympic games in the year(s) 2004, 2008, 2012, 2016 and won 8 Goldmedal/s in total. The athletes sport was: Athletics .\"\n\n\n:::\nPuuh, already not that quick, especially if this is meant as an easy way for users to extract the gold medal number for multiple persons. They would have to specify for both data frames the name and build togehter their print statement from scratch.\nLuckily, we can just write a function which is a way to organize multiple operations together, so they can easily get repeated. Let’s do that quickly, and then take a step back and look at the components of a function:\n\n\ncount_goldmedals &lt;- function(athlete_name) {\n  medal_counts_athlete &lt;- athletes %&gt;%\n    ## Extract all rows with gold medal winners:\n    filter(Medal == \"Gold\") %&gt;%\n    ## Group them by name\n    group_by(Name) %&gt;%\n    ## count the number of medals for each name:\n    count(Medal)\n\n  ## Extract the medal count row for the athlete name provided by the user using the athlete_name argument:\n  medals_name &lt;- medal_counts_athlete %&gt;%\n    filter(Name == athlete_name)\n\n  ## Extract the rows in the athlets data frame for the athlete name provided by the user using the athlete_name argument\n  stats_name &lt;- athletes %&gt;%\n    filter(Name == athlete_name) %&gt;%\n    ## Sort by year:\n    arrange(Year)\n\n  ## Build the statement:\n  statement &lt;- paste(\n    athlete_name,\n    \"participated in Olympic games in the year(s)\",\n    paste0(unique(stats_name$Year), collapse = \", \"),\n    \"and won\",\n    medals_name$n,\n    \"Goldmedal/s in total. The athletes sport was:\",\n    unique(stats_name$Sport),\n    \".\"\n  )\n\n  print(statement)\n\n  return(medals_name)\n}\n\ncount_goldmedals(athlete_name = \"Usain St. Leo Bolt\")\n\n[1] \"Usain St. Leo Bolt participated in Olympic games in the year(s) 2004, 2008, 2012, 2016 and won 8 Goldmedal/s in total. The athletes sport was: Athletics .\"\n\n\n# A tibble: 1 × 3\n# Groups:   Name [1]\n  Name               Medal     n\n  &lt;chr&gt;              &lt;chr&gt; &lt;int&gt;\n1 Usain St. Leo Bolt Gold      8\n\ncount_goldmedals(athlete_name = \"Simone Arianne Biles\")\n\n[1] \"Simone Arianne Biles participated in Olympic games in the year(s) 2016 and won 4 Goldmedal/s in total. The athletes sport was: Gymnastics .\"\n\n\n# A tibble: 1 × 3\n# Groups:   Name [1]\n  Name                 Medal     n\n  &lt;chr&gt;                &lt;chr&gt; &lt;int&gt;\n1 Simone Arianne Biles Gold      4\n\n\n\nPretty cool, right? We just write our code once, and can reuse it as often as we want to. So, let’s take a closer look at how to actually do that."
  },
  {
    "objectID": "qmd/functions/functions.html#how-to-write-a-function",
    "href": "qmd/functions/functions.html#how-to-write-a-function",
    "title": "Functions",
    "section": "How to write a function?",
    "text": "How to write a function?\nEverything that does something in R is a function. We have already used a lot of them, like print(), filter(), merge(). The great thing is: we can define our own functions pretty easily:\nfunction_name &lt;- function(argument_1, argument_2, ...){\n  do some operations\n  \n  return(result)\n}\nWe always have to give the function a concise name (often not that easy). Then we specify some arguments (which should also have concise names). In our introductory example that was just the athlete name. Inside the { } we define the operations, which can use the arguments so the users can specify some aspects of the functions behavior. In the end, it is good practice to return the result by using return(), so it is always clear what the function is giving back to the user. One minimal example with three arguments would be to sum three numbers. We can also provide a default option for the arguments, which the function will fall back on, if the user doesn’t specify anything:\n\nsum_num &lt;- function(x, y, z = 0){\n  result &lt;- x + y + z\n  return(result)\n}\n\nsum_num(x = 1, y = 1, z = 2)\n\n[1] 4\n\n## We don't have to use the arguments in order, IF we name them:\nsum_num(y = 2, z = 4, x = 1)\n\n[1] 7\n\n## We don't have to specify z, because the function can use a default:\nsum_num(x = 3, y = 1)\n\n[1] 4\n\n\n\n\n\n\n\n\nTip\n\n\n\nIt often makes sense to explicitly write the argument names into your function call. This makes your code clearer, and avoids a mix up."
  },
  {
    "objectID": "qmd/functions/functions.html#footnotes",
    "href": "qmd/functions/functions.html#footnotes",
    "title": "Functions",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nImage by Laura Ockel on Unsplash.↩︎"
  },
  {
    "objectID": "qmd/load_data/load_data.html",
    "href": "qmd/load_data/load_data.html",
    "title": "Loading data",
    "section": "",
    "text": "There are many different data types out there, most of which can also be loaded into R. Depending on the type, different commands are used. Sometimes, we will have to use additional packages to get access to that function, mainly readxl and haven.\n\n\n\n\n\n\n\n\n\nData.type\nImport\nExport\n\n\n\n\nR objects (.Rdata, .rda)\nload()\nsave()\n\n\nsingle R object (.rds)\nreadRDS()\nsaveRDS()\n\n\ntext-files (.txt)\nread.table()\nwrite.table()\n\n\n.csv-files (.csv)\nread.csv()\nwrite.csv()\n\n\nExcel-files (.xlsx)\nreadxl::read_excel()\nwritexl::write_xlsx()\n\n\nSPSS-files (.sav)\nhaven::read_sav()\nhaven::write_sav()\n\n\nSAS-files (.sas)\nhaven::read_sas()\nhaven::write_sas()\n\n\nStata-files (.stata)\nhaven::read_dta()\nhaven::write_dta()"
  },
  {
    "objectID": "qmd/load_data/load_data.html#data-types",
    "href": "qmd/load_data/load_data.html#data-types",
    "title": "Loading data",
    "section": "",
    "text": "There are many different data types out there, most of which can also be loaded into R. Depending on the type, different commands are used. Sometimes, we will have to use additional packages to get access to that function, mainly readxl and haven.\n\n\n\n\n\n\n\n\n\nData.type\nImport\nExport\n\n\n\n\nR objects (.Rdata, .rda)\nload()\nsave()\n\n\nsingle R object (.rds)\nreadRDS()\nsaveRDS()\n\n\ntext-files (.txt)\nread.table()\nwrite.table()\n\n\n.csv-files (.csv)\nread.csv()\nwrite.csv()\n\n\nExcel-files (.xlsx)\nreadxl::read_excel()\nwritexl::write_xlsx()\n\n\nSPSS-files (.sav)\nhaven::read_sav()\nhaven::write_sav()\n\n\nSAS-files (.sas)\nhaven::read_sas()\nhaven::write_sas()\n\n\nStata-files (.stata)\nhaven::read_dta()\nhaven::write_dta()"
  },
  {
    "objectID": "qmd/load_data/load_data.html#absolute-paths-vs.-relative-paths",
    "href": "qmd/load_data/load_data.html#absolute-paths-vs.-relative-paths",
    "title": "Loading data",
    "section": "Absolute paths vs. relative paths",
    "text": "Absolute paths vs. relative paths\nI can head to a specific file by using the full path (absolute path): \"C:\\Users\\hafiznij\\Documents\\GitHub\\r_tutorial\\raw_data\\winners.rda\". This approach has some disadvantages: it will only work on my notebook. If I want to continue my project on another device, I will have to change the path. The same goes for other people who want to work with my project. So, to keep these paths more reproducable, we should always use relative paths: \".\\raw_data\\winners.rda\". This will always work independently of the device I am working on, as long as I am in the correct working directory.\nThe working directory is the path R is currently working in. I can obtain it by typing:\n\ngetwd()\n\n[1] \"/home/runner/work/r_tutorial/r_tutorial/qmd/load_data\"\n\n\nLuckily, we have already created a RStudio projects, which sets the working directory automatically, so we don’t really have to deal with that.\nNow take a look at the working directory and the relative path I used for loading the winners.rda. Notice something? Correct, both paths combined equal the absolute path to the file. So by splitting it up, we obtain a more reproducible path, that works independent of where the current working directory is.\n\n\n\n\n\n\nThe here package\n\n\n\nAnother great way to deal with the path confusion is to use the here package. It can build the paths relative to the directory where your RStudio project is saved in. For example, \".\\raw_data\\winners.rda\" becomes here::here(\"raw_data\", \"winners.rda\"). This is not incredibly important right now, especially if you have all your files in the same folder. But it can become very valuable with increasing project complexity and file structure, so look into it if you want to get a head start! I also I have to use it sometimes during the tutorial because of I have organized my project, so don’t be confused! It is just another way to build file paths. Look here (:D) if you want to learn more about the package."
  },
  {
    "objectID": "qmd/load_data/load_data.html#example",
    "href": "qmd/load_data/load_data.html#example",
    "title": "Loading data",
    "section": "Example",
    "text": "Example\nLet’s load our Olympic athletes data set into R. By looking at it’s ending, we can see it is as .rds file, so it is R-specific, and can only be loaded into R. By taking a quick look into our table we can see we have to use the readRDS() function for loading .rds files.\n\nathletes &lt;- readRDS(file = here::here(\"raw_data\", \"athletes.rds\"))"
  },
  {
    "objectID": "qmd/missing/missing_exercise.html",
    "href": "qmd/missing/missing_exercise.html",
    "title": "Missing values: Exercises",
    "section": "",
    "text": "Previous code\n\n\n\n\n\n\nlibrary(tidyverse)\n\n## Load the data\ncharacters &lt;- readRDS(file = here::here(\"raw_data\", \"characters.rds\"))\npsych_stats &lt;- read.csv(\n  file = here::here(\"raw_data\", \"psych_stats.csv\"),\n  sep = \";\"\n)\n\n## Merge it\ncharacters_stats &lt;- merge(\n  x = characters,\n  y = psych_stats,\n  by.x = \"id\", \n  by.y = \"char_id\"\n)"
  },
  {
    "objectID": "qmd/missing/missing_exercise.html#exercise-1",
    "href": "qmd/missing/missing_exercise.html#exercise-1",
    "title": "Missing values: Exercises",
    "section": "Exercise 1",
    "text": "Exercise 1\n\nDoes the characters data set contain any NAs?\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse any() to see if a logical vector contains any TRUE values."
  },
  {
    "objectID": "qmd/missing/missing_exercise.html#solution",
    "href": "qmd/missing/missing_exercise.html#solution",
    "title": "Missing values: Exercises",
    "section": "Solution",
    "text": "Solution\n\nany(is.na(characters))\n\n[1] FALSE\n\n\nNo, there don’t seem to be any NAs in this data set, which would be great in real life. For this exercise it’s not great, so let’s introduce some NAs manually."
  },
  {
    "objectID": "qmd/missing/missing_exercise.html#solution-1",
    "href": "qmd/missing/missing_exercise.html#solution-1",
    "title": "Missing values: Exercises",
    "section": "Solution",
    "text": "Solution\n\ncharacters_na &lt;- characters\n\ncharacters_na[c(34, 103, 300), \"name\"] &lt;- NA\ncharacters_na[c(404, 670), \"uni_name\"] &lt;- NA"
  },
  {
    "objectID": "qmd/missing/missing_exercise.html#solution-2",
    "href": "qmd/missing/missing_exercise.html#solution-2",
    "title": "Missing values: Exercises",
    "section": "Solution",
    "text": "Solution\n\ncharacters_na &lt;- characters_na[!is.na(characters_na$name), ]\n\nOr:\n\n\nlibrary(tidyverse)\n\ncharacters_na &lt;- characters_na %&gt;%\n  drop_na(name)"
  },
  {
    "objectID": "qmd/workflow/workflow_exercise.html",
    "href": "qmd/workflow/workflow_exercise.html",
    "title": "Workflow: Exercises",
    "section": "",
    "text": "The following exercises will set up your working space for the rest of the workshop. All code you write will be saved in the script(s) you create here."
  },
  {
    "objectID": "qmd/workflow/workflow_exercise.html#exercise-1",
    "href": "qmd/workflow/workflow_exercise.html#exercise-1",
    "title": "Workflow: Exercises",
    "section": "Exercise 1",
    "text": "Exercise 1\n\nCreate a new folder for this workshop, where all your files will go.\nCreate a new RStudio project and open it.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nGo to File - New Project - Existing Directory and select the path of the folder you created in step 1.\n\n\n\n\nCreate a new R Script and save it.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nGo to File - New File - R Script. Save it into your folder.\n\n\n\n\n\n\n\n\n\nOrganizing your scripts\n\n\n\nHow you organize your scripts is up do you. I recommend to create seperate scripts for every use case. For this workshop, you could create one script for the exercises, and one script for the theory part, in case you want to try out some things by yourself.\n\n\n\n\n\n\n\n\nOrganizing your directory\n\n\n\nWithin your project folder, create a folder named R, where all your R Scripts will go. You can do the same for data, plots etc. later on. This will help you to structure your working directory and make it easier to find specific files.\n\n\nNow that you are ready to go, let’s get an overview of how working with data in R can look like."
  },
  {
    "objectID": "qmd/subsetting/subsetting_exercise.html",
    "href": "qmd/subsetting/subsetting_exercise.html",
    "title": "Subsetting data: Exercises",
    "section": "",
    "text": "Previous code\n\n\n\n\n\n\nlibrary(tidyverse)\n\n## Load the data\ncharacters &lt;- readRDS(file = here::here(\"raw_data\", \"characters.rds\"))\npsych_stats &lt;- read.csv(\n  file = here::here(\"raw_data\", \"psych_stats.csv\"),\n  sep = \";\"\n)\nstr(characters)\n\n'data.frame':   889 obs. of  7 variables:\n $ id        : chr  \"F2\" \"F1\" \"F5\" \"F4\" ...\n $ name      : chr  \"Monica Geller\" \"Rachel Green\" \"Chandler Bing\" \"Joey Tribbiani\" ...\n $ uni_id    : chr  \"F\" \"F\" \"F\" \"F\" ...\n $ uni_name  : chr  \"Friends\" \"Friends\" \"Friends\" \"Friends\" ...\n $ notability: num  79.7 76.7 74.4 74.3 72.6 51.6 86.5 84.2 82.6 65.6 ...\n $ link      : chr  \"https://openpsychometrics.org/tests/characters/stats/F/2\" \"https://openpsychometrics.org/tests/characters/stats/F/1\" \"https://openpsychometrics.org/tests/characters/stats/F/5\" \"https://openpsychometrics.org/tests/characters/stats/F/4\" ...\n $ image_link: chr  \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/2.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/1.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/5.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/4.jpg\" ...\nBecause subsetting data is such a basic skill, it will come up multiple times during this workshop. Here are some first exercises to get you started."
  },
  {
    "objectID": "qmd/subsetting/subsetting_exercise.html#exercise-1",
    "href": "qmd/subsetting/subsetting_exercise.html#exercise-1",
    "title": "Subsetting data: Exercises",
    "section": "Exercise 1",
    "text": "Exercise 1\nCorrect the following code, so only the first 10 rows and the last three columns are extracted:\n\ncharacters[4:6, 10]\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nWe have to target the rows we want to extract before the ,, the columns after.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ncharacters[1:10, 4:6]\n\n   uni_name notability\n1   Friends       79.7\n2   Friends       76.7\n3   Friends       74.4\n4   Friends       74.3\n5   Friends       72.6\n6   Friends       51.6\n7  Euphoria       86.5\n8  Euphoria       84.2\n9  Euphoria       82.6\n10 Euphoria       65.6\n                                                        link\n1   https://openpsychometrics.org/tests/characters/stats/F/2\n2   https://openpsychometrics.org/tests/characters/stats/F/1\n3   https://openpsychometrics.org/tests/characters/stats/F/5\n4   https://openpsychometrics.org/tests/characters/stats/F/4\n5   https://openpsychometrics.org/tests/characters/stats/F/3\n6   https://openpsychometrics.org/tests/characters/stats/F/6\n7  https://openpsychometrics.org/tests/characters/stats/EU/1\n8  https://openpsychometrics.org/tests/characters/stats/EU/2\n9  https://openpsychometrics.org/tests/characters/stats/EU/6\n10 https://openpsychometrics.org/tests/characters/stats/EU/3"
  },
  {
    "objectID": "qmd/subsetting/subsetting_exercise.html#exercise-2",
    "href": "qmd/subsetting/subsetting_exercise.html#exercise-2",
    "title": "Subsetting data: Exercises",
    "section": "Exercise 2",
    "text": "Exercise 2\n\nWhy does the following code not work? Correct it in your own script.\n\n\ncharacters[uni_name == \"Friends\", ]\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nYou need to extract the column from the data frame with $ before you can compare it to the string.\n\n\n\n\n\n\n\n\n\nCaution\n\n\n\n\n\n\ncharacters[characters$uni_name == \"Friends\", ]\n\n  id           name uni_id uni_name notability\n1 F2  Monica Geller      F  Friends       79.7\n2 F1   Rachel Green      F  Friends       76.7\n3 F5  Chandler Bing      F  Friends       74.4\n4 F4 Joey Tribbiani      F  Friends       74.3\n5 F3  Phoebe Buffay      F  Friends       72.6\n6 F6    Ross Geller      F  Friends       51.6\n                                                      link\n1 https://openpsychometrics.org/tests/characters/stats/F/2\n2 https://openpsychometrics.org/tests/characters/stats/F/1\n3 https://openpsychometrics.org/tests/characters/stats/F/5\n4 https://openpsychometrics.org/tests/characters/stats/F/4\n5 https://openpsychometrics.org/tests/characters/stats/F/3\n6 https://openpsychometrics.org/tests/characters/stats/F/6\n                                                                  image_link\n1 https://openpsychometrics.org/tests/characters/test-resources/pics/F/2.jpg\n2 https://openpsychometrics.org/tests/characters/test-resources/pics/F/1.jpg\n3 https://openpsychometrics.org/tests/characters/test-resources/pics/F/5.jpg\n4 https://openpsychometrics.org/tests/characters/test-resources/pics/F/4.jpg\n5 https://openpsychometrics.org/tests/characters/test-resources/pics/F/3.jpg\n6 https://openpsychometrics.org/tests/characters/test-resources/pics/F/6.jpg\n\n\n\n\n\n\nWhich characters will this code extract: characters[(characters$uni_name == \"Harry Potter\" | characters$uni_name != \"Harry Potter\") & !(characters$notability &gt; 90), ]?\n\nAll Harry Potter characters with a notability over 90.\nAll characters that are not from the Harry Potter universe and have a notability under 90.\nAll characters with a notability over 90.\nAll characters with a notability under 90.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nAll Harry Potter characters with a notability over 90.\nAll characters that are not from the Harry Potter universe and have a notability under 90.\nAll characters with a notability over 90.\nAll characters with a notability under 90.\n\nKind of a trick question: because we select all characters that are from the Harry Potter universe OR are not from there, we select all characters independent of their TV show. But we select all characters that have notability under 90 (beware of the ! in front of the respective comparison)."
  },
  {
    "objectID": "qmd/subsetting/subsetting_exercise.html#exercise-3",
    "href": "qmd/subsetting/subsetting_exercise.html#exercise-3",
    "title": "Subsetting data: Exercises",
    "section": "Exercise 3",
    "text": "Exercise 3\n\nWhich character(s) from “Game of Thrones” has a notability rating over 90? Use Base R.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou need to define a logical vector which contains TRUE values for all “Game of Thrones” characters that have a notability over 90.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ncharacters[characters$uni_name == \"Game of Thrones\" & characters$notability &gt; 90, ]\n\n     id             name uni_id        uni_name notability\n18 GOT2 Tyrion Lannister    GOT Game of Thrones       90.8\n                                                         link\n18 https://openpsychometrics.org/tests/characters/stats/GOT/2\n                                                                     image_link\n18 https://openpsychometrics.org/tests/characters/test-resources/pics/GOT/2.jpg\n\n\n\n\n\nThat’s only Tyrion Lannister.\n\nWhich characters from “How I Met Your Mother” or “Breaking Bad” are included in the data? Use the tidyverse.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the filter() function.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nlibrary(tidyverse)\nfilter(characters, uni_name %in% c(\"How I Met Your Mother\", \"Breaking Bad\"))\n\n       id              name uni_id              uni_name notability\n1  HIMYM4    Barney Stinson  HIMYM How I Met Your Mother       76.0\n2  HIMYM3 Robin Scherbatsky  HIMYM How I Met Your Mother       74.2\n3  HIMYM5       Lily Aldrin  HIMYM How I Met Your Mother       74.1\n4  HIMYM2  Marshall Eriksen  HIMYM How I Met Your Mother       71.0\n5  HIMYM1         Ted Mosby  HIMYM How I Met Your Mother       63.7\n6     BB1      Walter White     BB          Breaking Bad       91.3\n7     BB3     Jesse Pinkman     BB          Breaking Bad       88.9\n8     BB9  Mike Ehrmantraut     BB          Breaking Bad       82.5\n9     BB8         Gus Fring     BB          Breaking Bad       79.6\n10    BB4     Hank Schrader     BB          Breaking Bad       74.8\n11    BB7      Saul Goodman     BB          Breaking Bad       73.8\n12   BB10     Jane Margolis     BB          Breaking Bad       61.3\n13    BB2      Skyler White     BB          Breaking Bad       55.4\n14    BB6       Flynn White     BB          Breaking Bad       46.8\n15    BB5    Marie Schrader     BB          Breaking Bad       27.9\n                                                           link\n1  https://openpsychometrics.org/tests/characters/stats/HIMYM/4\n2  https://openpsychometrics.org/tests/characters/stats/HIMYM/3\n3  https://openpsychometrics.org/tests/characters/stats/HIMYM/5\n4  https://openpsychometrics.org/tests/characters/stats/HIMYM/2\n5  https://openpsychometrics.org/tests/characters/stats/HIMYM/1\n6     https://openpsychometrics.org/tests/characters/stats/BB/1\n7     https://openpsychometrics.org/tests/characters/stats/BB/3\n8     https://openpsychometrics.org/tests/characters/stats/BB/9\n9     https://openpsychometrics.org/tests/characters/stats/BB/8\n10    https://openpsychometrics.org/tests/characters/stats/BB/4\n11    https://openpsychometrics.org/tests/characters/stats/BB/7\n12   https://openpsychometrics.org/tests/characters/stats/BB/10\n13    https://openpsychometrics.org/tests/characters/stats/BB/2\n14    https://openpsychometrics.org/tests/characters/stats/BB/6\n15    https://openpsychometrics.org/tests/characters/stats/BB/5\n                                                                       image_link\n1  https://openpsychometrics.org/tests/characters/test-resources/pics/HIMYM/4.jpg\n2  https://openpsychometrics.org/tests/characters/test-resources/pics/HIMYM/3.jpg\n3  https://openpsychometrics.org/tests/characters/test-resources/pics/HIMYM/5.jpg\n4  https://openpsychometrics.org/tests/characters/test-resources/pics/HIMYM/2.jpg\n5  https://openpsychometrics.org/tests/characters/test-resources/pics/HIMYM/1.jpg\n6     https://openpsychometrics.org/tests/characters/test-resources/pics/BB/1.jpg\n7     https://openpsychometrics.org/tests/characters/test-resources/pics/BB/3.jpg\n8     https://openpsychometrics.org/tests/characters/test-resources/pics/BB/9.jpg\n9     https://openpsychometrics.org/tests/characters/test-resources/pics/BB/8.jpg\n10    https://openpsychometrics.org/tests/characters/test-resources/pics/BB/4.jpg\n11    https://openpsychometrics.org/tests/characters/test-resources/pics/BB/7.jpg\n12   https://openpsychometrics.org/tests/characters/test-resources/pics/BB/10.jpg\n13    https://openpsychometrics.org/tests/characters/test-resources/pics/BB/2.jpg\n14    https://openpsychometrics.org/tests/characters/test-resources/pics/BB/6.jpg\n15    https://openpsychometrics.org/tests/characters/test-resources/pics/BB/5.jpg"
  },
  {
    "objectID": "qmd/loops/loops_exercise.html",
    "href": "qmd/loops/loops_exercise.html",
    "title": "Loops: Exercises",
    "section": "",
    "text": "Note\n\n\n\nThese exercises are optional."
  },
  {
    "objectID": "qmd/loops/loops_exercise.html#exercise-1",
    "href": "qmd/loops/loops_exercise.html#exercise-1",
    "title": "Loops: Exercises",
    "section": "Exercise 1",
    "text": "Exercise 1\nPrint each fictional universe (column: uni_name) in the characters_stats data frame into your console once, like this: \"The fictional universe 'fictional universe' is part of the characters data set.\"\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nfor(universe in unique(characters_stats$uni_name)){\n  print(paste0(\"The fictional universe '\", universe, \"' is part of the characters data set.\"))\n}\n\n[1] \"The fictional universe 'Arrested Development' is part of the characters data set.\"\n[1] \"The fictional universe 'Avatar: The Last Airbender' is part of the characters data set.\"\n[1] \"The fictional universe 'Arcane' is part of the characters data set.\"\n[1] \"The fictional universe 'Archer' is part of the characters data set.\"\n[1] \"The fictional universe 'It's Always Sunny in Philadelphia' is part of the characters data set.\"\n[1] \"The fictional universe 'Bones' is part of the characters data set.\"\n[1] \"The fictional universe 'Brooklyn Nine-Nine' is part of the characters data set.\"\n[1] \"The fictional universe 'Beauty and the Beast' is part of the characters data set.\"\n[1] \"The fictional universe 'Breaking Bad' is part of the characters data set.\"\n[1] \"The fictional universe 'The Big Bang Theory' is part of the characters data set.\"\n[1] \"The fictional universe 'The Breakfast Club' is part of the characters data set.\"\n[1] \"The fictional universe 'Broad City' is part of the characters data set.\"\n[1] \"The fictional universe 'Bob's Burgers' is part of the characters data set.\"\n[1] \"The fictional universe 'Battlestar Galactica' is part of the characters data set.\"\n[1] \"The fictional universe 'Buffy the Vampire Slayer' is part of the characters data set.\"\n[1] \"The fictional universe 'Community' is part of the characters data set.\"\n[1] \"The fictional universe 'Calvin and Hobbes' is part of the characters data set.\"\n[1] \"The fictional universe 'Criminal Minds' is part of the characters data set.\"\n[1] \"The fictional universe 'Craze Ex-Girlfriend' is part of the characters data set.\"\n[1] \"The fictional universe 'Dexter' is part of the characters data set.\"\n...\n\n\nWe don’t have to use i as counter (even though it is convention)."
  },
  {
    "objectID": "qmd/loops/loops_exercise.html#exercise-2",
    "href": "qmd/loops/loops_exercise.html#exercise-2",
    "title": "Loops: Exercises",
    "section": "Exercise 2",
    "text": "Exercise 2\nRemember how we used the group_by() command to calculate the number of gold medals for each country? Well, now you know enough to do something similar without using the tidyverse, but just a for-loop.\n\nSubset a data frame that only contains the characters of one (your favorite) fictional universe.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n\ncharacters_friends &lt;- characters_stats %&gt;%\n  filter(uni_name == \"Friends\")\n\n\n\n\n\n\nNow calculate the mean rating over all characters in this fictional universe for each question and print the result in a statement containing the sentence: \"The mean rating for the fictional universe 'your_universe' on the question 'question' is: 'mean_rating'.\"\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nBuild a for loop that goes over all unique questions in your subsetted data frames. Inside this for-loop you can subset again, this time only the rows containing the question that the loop is at at the moment, and calculate its mean rating from here. Then use paste() to build and print the statement.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nfor(i in unique(characters_friends$question)){ # goes over all unique questions\n  \n  ## Build a subset that only consists of ratings about the current question:\n  question_dat &lt;- characters_friends %&gt;%\n    filter(question == i)\n  \n  ## Calculate the mean for that subset:\n  question_mean &lt;- mean(question_dat$rating)\n  \n  ## Build and print the final statement:\n  statement &lt;- paste(\"The mean rating for the fictional universe 'Friends' on the question '\", i, \"' is:\", question_mean)\n  print(statement)\n}\n\n[1] \"The mean rating for the fictional universe 'Friends' on the question ' messy_neat ' is: 47.6833333333333\"\n[1] \"The mean rating for the fictional universe 'Friends' on the question ' disorganized_self.disciplined ' is: 45.1666666666667\"\n[1] \"The mean rating for the fictional universe 'Friends' on the question ' diligent_lazy ' is: 42.2333333333333\"\n[1] \"The mean rating for the fictional universe 'Friends' on the question ' on.time_tardy ' is: 53.3166666666667\"\n[1] \"The mean rating for the fictional universe 'Friends' on the question ' competitive_cooperative ' is: 33.6\"\n[1] \"The mean rating for the fictional universe 'Friends' on the question ' scheduled_spontaneous ' is: 55.5333333333333\"\n[1] \"The mean rating for the fictional universe 'Friends' on the question ' ADHD_OCD ' is: 40.7833333333333\"\n[1] \"The mean rating for the fictional universe 'Friends' on the question ' chaotic_orderly ' is: 41.6666666666667\"\n[1] \"The mean rating for the fictional universe 'Friends' on the question ' motivated_unmotivated ' is: 32.2833333333333\"\n[1] \"The mean rating for the fictional universe 'Friends' on the question ' bossy_meek ' is: 41.4666666666667\"\n[1] \"The mean rating for the fictional universe 'Friends' on the question ' persistent_quitter ' is: 29.05\"\n[1] \"The mean rating for the fictional universe 'Friends' on the question ' overachiever_underachiever ' is: 41.85\"\n[1] \"The mean rating for the fictional universe 'Friends' on the question ' muddy_washed ' is: 64.2166666666667\"\n[1] \"The mean rating for the fictional universe 'Friends' on the question ' beautiful_ugly ' is: 19.5\"\n[1] \"The mean rating for the fictional universe 'Friends' on the question ' slacker_workaholic ' is: 53.5333333333333\"\n[1] \"The mean rating for the fictional universe 'Friends' on the question ' driven_unambitious ' is: 34.1833333333333\"\n[1] \"The mean rating for the fictional universe 'Friends' on the question ' outlaw_sheriff ' is: 50.2666666666667\"\n[1] \"The mean rating for the fictional universe 'Friends' on the question ' precise_vague ' is: 51.55\"\n[1] \"The mean rating for the fictional universe 'Friends' on the question ' bad.cook_good.cook ' is: 37.6333333333333\"\n[1] \"The mean rating for the fictional universe 'Friends' on the question ' manicured_scruffy ' is: 32.4166666666667\"\n...\n\n\nThere seem to be pretty beautiful people on the fictional universe …\n\n\n\n\nTweak your for loop so the mean values get saved in a new data frame, containing the question and the mean rating for each question.\n\n\n\n\n\n\n\nHints\n\n\n\n\n\n\nBuild an empty data frame where you will save your results.\nNow you can’t easily loop over the question column itself, because you need the position of each element to save it in a new data frame: for(i in 1:length(unique(characters_friends$question))){.\nBecause of that you can save the result of your calculateion in row i of your new data frame.\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n## Build an empty data frame for storing the results:\nmean_ratings &lt;- data.frame()\n\nfor(i in 1:length(unique(characters_friends$question))){\n  ## Extract the question on position i:\n  question_i &lt;- unique(characters_friends$question)[i]\n  \n  ## Extract all rows that contain values for this question:\n  question_dat &lt;- characters_friends %&gt;%\n    filter(question == question_i)\n  \n  ## Calculate the mean for that question\n  question_mean &lt;- mean(question_dat$rating)\n\n  ## Save the question in the row corresponding to the position of i:\n  mean_ratings[i, \"question\"] &lt;- question_i\n  \n  ## Save the mean in the row corresponding to the position of i:\n  mean_ratings[i, \"mean\"] &lt;- question_mean\n}\n\nhead(mean_ratings)\n\n                       question     mean\n1                    messy_neat 47.68333\n2 disorganized_self.disciplined 45.16667\n3                 diligent_lazy 42.23333\n4                 on.time_tardy 53.31667\n5       competitive_cooperative 33.60000\n6         scheduled_spontaneous 55.53333\n\n\n\nLet’s compare that with a group_by()\n\n\ncharacters_friends %&gt;%\n  group_by(question) %&gt;%\n  summarise(mean_rating = mean(rating)) %&gt;%\n  ## Let's look at the rating of this question for comparison:\n  filter(question == 'beautiful_ugly')\n\n# A tibble: 1 × 2\n  question       mean_rating\n  &lt;chr&gt;                &lt;dbl&gt;\n1 beautiful_ugly        19.5\n\n\n\nGreat, its the same!"
  },
  {
    "objectID": "qmd/plotting/plotting_exercise.html",
    "href": "qmd/plotting/plotting_exercise.html",
    "title": "Plotting: Exercises",
    "section": "",
    "text": "Previous code\n\n\n\n\n\n\nlibrary(tidyverse)\n\n## Load the data\ncharacters &lt;- readRDS(file = here::here(\"raw_data\", \"characters.rds\"))\npsych_stats &lt;- read.csv(\n  file = here::here(\"raw_data\", \"psych_stats.csv\"),\n  sep = \";\"\n)\n\n## Reshape psych_stats into long format:\npsych_stats &lt;- psych_stats %&gt;%\n  pivot_longer(cols = messy_neat:innocent_jaded, \n               names_to = \"question\", \n               values_to = \"rating\")\n\n## Merge it\ncharacters_stats &lt;- merge(\n  x = characters,\n  y = psych_stats,\n  by.x = \"id\", \n  by.y = \"char_id\"\n)"
  },
  {
    "objectID": "qmd/plotting/plotting_exercise.html#exercise-1",
    "href": "qmd/plotting/plotting_exercise.html#exercise-1",
    "title": "Plotting: Exercises",
    "section": "Exercise 1",
    "text": "Exercise 1\nNow, let’s make a nice plot out of the data we’ve got.\n\nSelect up to 15 questions you want to display in the plot and save them into a new vector.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nI’m just gonna take the first 15 questions from all unique ones:\n\nquestions &lt;- unique(characters_stats$question)[1:10]\nquestions\n\n [1] \"messy_neat\"                    \"disorganized_self.disciplined\"\n [3] \"diligent_lazy\"                 \"on.time_tardy\"                \n [5] \"competitive_cooperative\"       \"scheduled_spontaneous\"        \n [7] \"ADHD_OCD\"                      \"chaotic_orderly\"              \n [9] \"motivated_unmotivated\"         \"bossy_meek\"                   \n\n\n\n\n\n\nSelect one show (your favorite), extract it from the data frame and save it into a new data set. It should only contain the questions you have selected in the first step.\n\n\ncharacters_subset &lt;- characters_stats %&gt;% \n  filter(uni_name %in% c(\"Friends\"), \n         question %in% questions)"
  },
  {
    "objectID": "qmd/final_exercise/final_exercise.html",
    "href": "qmd/final_exercise/final_exercise.html",
    "title": "The Big Picture: Exercise",
    "section": "",
    "text": "1\nThis exercise revisits most topics presented in the workshop (but will also go beyond it slightly in some cases to provide some additional input).\nIf you are a R beginner and followed the workshop, you can do this last exercise in the end to test your knowledge. If you already have some R experience, you can do this exercise before the rest of the workshop and use it to identify weak points to follow up on. It will be a bit harder than the other workshop exercises to challenge you one last time and think about concepts you might want to revisit, so don’t worry if some exercises feel a bit harder, we haven’t talked about everything yet. Use all resources at your disposal (cheat sheets, stack overflow …), that’s how you would work on a real project as well.\nSo, in order to provide you with a totally fresh data set, let’s look at beach volleyball. The data was collected from international beach volleyball championships, and displays a lot of stats on each single match. For this exercise we want to focus on a simple questions: Does height differences in volleyball matter so much, that taller teams have a winning advantage? If that would be the case, the mean height of the winning team should be significantly larger than the mean height of the losing team. Let’s take a look!"
  },
  {
    "objectID": "qmd/final_exercise/final_exercise.html#exercise-1",
    "href": "qmd/final_exercise/final_exercise.html#exercise-1",
    "title": "The Big Picture: Exercise",
    "section": "Exercise 1",
    "text": "Exercise 1\n\nDownload the data sets vb_w and vb_l and load the data into R.\n\n\n\n\n\n\n\nHints\n\n\n\n\n\n\nAdmittedly not the easiest data loading exercise. One file is a .csv file, the other an SPSS file (.sav). Take a look here to see how to load them into R.\nYou need to install haven to load the .sav file.\nYou need to look at the sep argument in read.csv(): It needs to specify how the values in the .csv file are seperated. Use a text editor to take a look into the file itself to find out what the separator should be. We have seen a simmilar example in this exercise.\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n# install.packages(\"haven\") # Commented out, only execute if the package needs to be installed.\nlibrary(haven)\nlibrary(tidyverse) ## Will use later on\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nvb_w &lt;- read.csv(file = here::here(\"raw_data\", \"vb_w.csv\"), sep = \" \")\nvb_l &lt;- read_sav(file = here::here(\"raw_data\", \"vb_l.sav\"))\n\n\n\n\n\nMerge vb_l and vb_w.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the argument by in merge() to select the columns id and gender on which the data sets wil get merged.\n\n\n\n\nvb &lt;- merge(vb_l,\n  vb_w,\n  by = c(\"id\", \"gender\")\n)\n\n\nSelect only the columns from the data frames that are relevant to this question, and an identifier column, so we can merge them in the next step.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nThe relevant columns are: c(\"gender\", \"l_p1_hgt\", \"l_p2_hgt\", \"w_p1_hgt\", \"w_p2_hgt\").\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nvb &lt;- vb[, c(\"id\", \"gender\", \"l_p1_hgt\", \"l_p2_hgt\", \"w_p1_hgt\", \"w_p2_hgt\")]\n\n\n\n\n\nRemove any remaining NAs from this data set.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse na_omit() to remove all NAs at once.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nvb &lt;- na.omit(vb)\n\n\n\n\n\nCalculate the mean height by team. Add the results in two new columns to the vb data frame.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou will need to calculate the mean of the two columns by row. There is a function called rowMeans() which can do exactly that. Provide a data frame consisting only of the relevant columns as input.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nvb$winning_height &lt;- rowMeans(vb[, c(\"w_p1_hgt\", \"w_p2_hgt\")])\nvb$losing_height &lt;- rowMeans(vb[, c(\"l_p1_hgt\", \"l_p2_hgt\")])"
  },
  {
    "objectID": "qmd/final_exercise/final_exercise.html#exercise-2",
    "href": "qmd/final_exercise/final_exercise.html#exercise-2",
    "title": "The Big Picture: Exercise",
    "section": "Exercise 2",
    "text": "Exercise 2\nNow, let’s do a paired paired t-test comparing the mean winners height against the mean losers height.\n\nOne assumption of the paired t-test is a normal distribution of the differences of the pairs. Check this assumption visually by creating a histogram of the winning_height - losing_height difference. Use a for-loop to create one histogram from the men and one for the women data set. You need to explicitly print() the plot if you want to display it from within a for-loop.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nThe start of your for loop should look like this: for(i in c(\"M\", \"W\")){. Inside, filter for men/women.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nfor (i in c(\"M\", \"W\")) {\n  vb_gender &lt;- vb %&gt;% filter(gender == i)\n\n  p &lt;- ggplot(\n    data = vb_gender,\n    mapping = aes(x = winning_height - losing_height)\n  ) +\n    geom_histogram(binwidth = 0.5)\n\n  print(p)\n}\n\n\n\n\n\n\n\n\n\n\n\nDo a paired t-test comparing the winning teams height vs the losing team height. Again use a for-loop to test for men and women separately. Save the result in a list), and name the list.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the function t.test() and set the argument paired = \"true\".\n\n\n\n\n\n\n\n\n\nCaution\n\n\n\n\n\n\nresult_list &lt;- list()\n\nfor (i in c(\"M\", \"W\")) {\n  vb_gender &lt;- vb %&gt;% filter(gender == i)\n\n  result_list[[i]] &lt;- t.test(vb_gender$winning_height, vb_gender$losing_height, paired = \"true\")\n}\n\nresult_list\n\n$M\n\n    Paired t-test\n\ndata:  vb_gender$winning_height and vb_gender$losing_height\nt = 23.111, df = 32168, p-value &lt; 2.2e-16\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 0.2439251 0.2891347\nsample estimates:\nmean difference \n      0.2665299 \n\n\n$W\n\n    Paired t-test\n\ndata:  vb_gender$winning_height and vb_gender$losing_height\nt = 16.38, df = 30646, p-value &lt; 2.2e-16\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 0.1839846 0.2340009\nsample estimates:\nmean difference \n      0.2089927 \n\n\nTh p-value is &lt; 0.001. However, we have a very large sample, so almost all group differences will become significant.\n\n\n\n\n\n\nNote\n\n\n\nActually, this would be a perfect application for lapply():\n\nresult_list &lt;- lapply(c(\"M\", \"W\"), function(x) {\n  vb_gender &lt;- vb %&gt;% filter(gender == x)\n  t_test_result &lt;- t.test(vb_gender$winning_height, vb_gender$losing_height, paired = \"true\")\n  return(t_test_result)\n})\nnames(result_list) &lt;- c(\"M\", \"W\")\n\nThe output of lapply() is a list, so we don’t have to define an empty list in the beginning of the loop.\n\n\n\n\n\n\nLook at the mean differences. Not very big, right? Let’s calculate a standardized effect size, Cohen’s d:\n\n\\(d = \\frac{\\overline{x}_1 - \\overline{x}_2}{\\sqrt{(s^2_1 + s^2_2)/2}}\\)\nWrite a function to do that, then add it to your loop.\n\n\n\n\n\n\nCaution\n\n\n\n\n\n\ncohens_d &lt;- function(x_1, x_2, var_1, var_2) {\n  d &lt;- (x_1 - x_2) / (sqrt(var_1 + var_2) / 2)\n  return(d)\n}\n\n\nfor (i in c(\"M\", \"W\")) {\n  vb_gender &lt;- vb %&gt;% filter(gender == i)\n\n  result_list[[i]] &lt;- t.test(vb_gender$winning_height, vb_gender$losing_height, paired = \"true\")\n  d &lt;- cohens_d(\n    x_1 = mean(vb_gender$winning_height),\n    x_2 = mean(vb_gender$losing_height),\n    var_1 = var(vb_gender$winning_height),\n    var_2 = var(vb_gender$losing_height)\n  )\n  print(d)\n}\n\n[1] 0.2444149\n[1] 0.1793589\n\n\nSo, following Cohen’s conventions, this could be interpreted as a (very) small effect sizes. The height differences in professional volleyball are therefore probably negligible, as the size differences will be very small anyways, but still, teams with taller players seem to have a very small edge."
  },
  {
    "objectID": "qmd/final_exercise/final_exercise.html#exercise-3",
    "href": "qmd/final_exercise/final_exercise.html#exercise-3",
    "title": "The Big Picture: Exercise",
    "section": "Exercise 3",
    "text": "Exercise 3\n\nReform the vb data frame (with both men and women in it) into long format, so all heights can be found in one column, with the winning/losing information in another column.\n\n\n\n\n\n\n\nCaution\n\n\n\n\n\n\n\nvb_long &lt;- vb %&gt;%\n  pivot_longer(\n    cols = c(\"winning_height\", \"losing_height\"),\n    names_to = \"result\",\n    values_to = \"mean_height\"\n  )\n\n\n\n\n\n\n[Use ggplot}(../plotting/plotting.qmd) to build a violin plot showing the winners and losers height distribution by gender. Violin plots are similar to box plots but have the advantage of conveying more distributional information. If you want, you can also add a small box plot on top of the violin plot to have the advantage of both. Give meaningful axis labels and a plot title.\n\n\n\n\n\n\n\nCaution\n\n\n\n\n\n\n\nvb_long &lt;- vb_long %&gt;%\n  mutate(group = paste0(.$result, .$gender))\n\nggplot(vb_long,\n  mapping = aes(x = group, y = mean_height, fill = gender)\n) +\n  geom_violin() +\n  geom_boxplot(width = 0.1, color = \"grey\", alpha = 0.2, position = \"dodge\") +\n  scale_fill_brewer(palette = \"Dark2\") +\n  theme_bw()"
  },
  {
    "objectID": "qmd/final_exercise/final_exercise.html#footnotes",
    "href": "qmd/final_exercise/final_exercise.html#footnotes",
    "title": "The Big Picture: Exercise",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nImage by Mitchell Luo on Unsplash.↩︎"
  },
  {
    "objectID": "qmd/plotting/plotting.html",
    "href": "qmd/plotting/plotting.html",
    "title": "Plotting",
    "section": "",
    "text": "Note\n\n\n\nThis chapter is optional. It is not necessary to follow the rest of the conference, but you will get started with plotting in R.\nNow, let’s take a closer look at how ggplot2 works. We already had a quick glimpse at it: Plots are build from different layers to create complex outputs. There are endless possibilities for different plot types, look at the R graph gallery for some inspiration and code.\nFirst, let’s plot a relatively simple plot to get you familiar with how ggplot2 works. After that, we will use the preparation we have done in the last chapters to plot the number of gold medals each country has won over the years on a world map, which gets slightly more complex."
  },
  {
    "objectID": "qmd/plotting/plotting.html#first-plot",
    "href": "qmd/plotting/plotting.html#first-plot",
    "title": "Plotting",
    "section": "First plot",
    "text": "First plot\nFor this plot, we want to find the country with the most medal winners for each sport. The preparation is pretty similar to what we have done before.\n\n\nbest_by_sport &lt;- athletes %&gt;%\n  ## Get all gold medalists\n  filter(Medal == \"Gold\") %&gt;%\n  ## Group them by sport and region\n  group_by(Sport, Region) %&gt;%\n  ## count the number of medals each country has per sport category\n  count(Medal) %&gt;%\n  ## Now only group by sport, so we can extract the maximum medal row by sport, and not by sport and country\n  group_by(Sport) %&gt;%\n  ## Extract the country with the most medals\n  slice(which.max(n)) \n\n\nggplot()\nIn general, a ggplot starts with the ggplot() function. In it we define the data we want to use, and some aesthetics. The ggplot() function then draws our (currently still empty) plotting area, with the defined axes (see next section).\n\n\naes()\nAesthetics set parameters dependent on the data. In most cases, we will define our x and y axis here. We can also group data together by groups found in a column. If we want the data to have a different color, form, filling etc. depending on values in a column, we can define that here as well (we will look at that later on).\n\np &lt;- ggplot(\n  data = best_by_sport,\n  aes(\n    x = Sport,\n    y = n,\n  )\n)\n\np\n\n\n\n\nIn this case, the sport is plotted on the x axis and the number of gold medals (n) on the y axis. Bar filling will vary depending on the region.\n\n\ngeom_()\nThe geoms do the actual plotting. For example, if we want a barplot:\n\np +\n  geom_col()\n\n\n\n\nLooking pretty boring, right? Let’s give each country another color by defining the fill aesthetic. Also, lets order the x axis depending on the number of gold medalists:\n\np &lt;- p +\n  geom_col(aes(fill = Region, x = reorder(Sport, n)))\np\n\n\n\n\nCorrect! We can define the aesthetics also within the geom_() functions. In this case they will only be used for that specific function, and not for the whole plot (which would be the case if we had defined the fill aesthetic in the ggplot() function).\n\np +\n  geom_point()\n\n\n\n\nThis gives us black points now. If we had defined our aesthetics in the ggplot() function, the points would have the same colors as the bars. Also note that we layed another geom (geom_point()) over our plot, we added a new layer (that’s what I meant earlier on by saying plots consist of different layers).\n\n\nGeneral plotting options\nWe can tweak all aspects of the appearance of a plot. For example, we might want to turn the x axis labels by 90 degrees to actually make them readable:\n\np &lt;- p +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\np\n\n\n\n\nOr we could label the bars with the country:\n\np &lt;- p +\n  geom_text(aes(label = Region), hjust = -0.3, angle = 90, size = 2.5)\np\n\n\n\n\nOr use different colors and a different theme:\n\np &lt;- p +\n  theme_classic() +\n  ## And turn the axis labels again, because the new theme has overwritten our theme\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +\n  ## Specify which colors are used for the filling\n  scale_fill_manual(values = viridisLite::viridis(19))\n\np  \n\n\n\n\nFinally, change the title and axis labels:\n\np +\n  ggtitle(\"Country with the most Olympic gold medal winners by sport\") +\n  xlab(\"Sport\") +\n  ylab(\"Number of gold medal winners\")\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nOf course we don’t have to assign every intermediate step to the p object. Normally, we would just combine all layers by using the +.\n\n\nPretty cool! Now we know that the most Olympic Tug-Of-War gold medalists are from the UK! Also note that we are looking at the number of people from each country winning a gold medal, so team sports are counted multiple times."
  },
  {
    "objectID": "qmd/plotting/plotting.html#second-plot",
    "href": "qmd/plotting/plotting.html#second-plot",
    "title": "Plotting",
    "section": "Second plot",
    "text": "Second plot\nLet’s take a look at a different plot, just to see what can be easily achieved with ggplot2 (and we have prepared the data to do that, so we don’t want to waste the work).\nSo, let’s build our coordinate system:\n\np &lt;- ggplot(\n  data = medal_countries,\n  mapping = aes(x = long, y = lat, group = group)\n)\np\n\n\n\n\nNow we add the map by using the polygon geom:\n\np &lt;- p +\n  geom_polygon(aes(fill = n))\np\n\n\n\n\nRemember what aes() does? Here we can specify which aspects of the plot should change in dependence of the data, so in this case the polygon filling (which are our countries) will change depending on n (the number of gold medalists).\nIn the end we can clean up the plot by rescaling the x and y axis, provide a new colour scale, titles and theme:\n\n  p +\n  coord_fixed(1.3) +\n  scale_fill_distiller(palette =\"YlOrBr\", direction = 1) + \n  ggtitle(\"Olympic Gold Medal winners\") +\n  guides(fill=guide_legend(title=\"Gold medal \\n winners\")) +\n  theme_void()\n\n\n\n\nNote that the medals for team sports are counted multiple times, as our data contained the gold medal wins by person, and not by discipline."
  },
  {
    "objectID": "qmd/loops/loops.html",
    "href": "qmd/loops/loops.html",
    "title": "Loops and conditions",
    "section": "",
    "text": "1"
  },
  {
    "objectID": "qmd/loops/loops.html#for-loops",
    "href": "qmd/loops/loops.html#for-loops",
    "title": "Loops and conditions",
    "section": "For-loops",
    "text": "For-loops\n\nMotivation\nWhen programming, you often want to repeat an operation multiple times. For example, assume you want to print the number of gold medals for each country into your console. The most intuitive way would be to just copy paste the code with changed country names:\n\nprint(\n  paste0(\n    medal_counts[medal_counts$Region == \"Algeria\", \"n\"], \n    \" Olympic gold medalists are from \", \n    medal_counts[medal_counts$Region == \"Algeria\", \"Region\"], \n    \".\")\n  )\n\n[1] \"5 Olympic gold medalists are from Algeria.\"\n\nprint(\n  paste0(\n    medal_counts[medal_counts$Region == \"Argentina\", \"n\"], \n    \" Olympic gold medalists are from \", \n    medal_counts[medal_counts$Region == \"Argentina\", \"Region\"], \n    \".\")\n  )\n\n[1] \"91 Olympic gold medalists are from Argentina.\"\n\nprint(\n  paste0(\n    medal_counts[medal_counts$Region == \"Armenia\", \"n\"], \n    \" Olympic gold medalists are from \", \n    medal_counts[medal_counts$Region == \"Armenia\", \"Region\"], \n    \".\")\n  )\n\n[1] \"2 Olympic gold medalists are from Armenia.\"\n\nprint(\n  paste0(medal_counts[medal_counts$Region == \"Australia\", \"n\"], \n         \" Olympic gold medalists are from \", \n         medal_counts[medal_counts$Region == \"Australia\", \"Region\"],\n         \".\")\n  )\n\n[1] \"368 Olympic gold medalists are from Australia.\"\n\n\nThis could go on …\nHere we paste together a sentence consisting of data and some pre specified character strings, which we then print into the console. However, this can become pretty tedious if we want to add more countries, and what if we want to change something in the print statement? In this case, we would have to go over all rows and change it multiple times. So, let’s write a loop that does that automatically for us:\n\nfor(i in unique(medal_counts$Region)){\n  print(\n    paste0(\n      medal_counts[medal_counts$Region == i, \"n\"], \n      \" Olympic gold medalists are from \", \n      i, \n      \".\" )\n    )\n}\n\n[1] \"5 Olympic gold medalists are from Algeria.\"\n[1] \"91 Olympic gold medalists are from Argentina.\"\n[1] \"2 Olympic gold medalists are from Armenia.\"\n[1] \"368 Olympic gold medalists are from Australia.\"\n[1] \"108 Olympic gold medalists are from Austria.\"\n[1] \"7 Olympic gold medalists are from Azerbaijan.\"\n[1] \"14 Olympic gold medalists are from Bahamas.\"\n[1] \"1 Olympic gold medalists are from Bahrain.\"\n[1] \"24 Olympic gold medalists are from Belarus.\"\n[1] \"98 Olympic gold medalists are from Belgium.\"\n[1] \"109 Olympic gold medalists are from Brazil.\"\n[1] \"54 Olympic gold medalists are from Bulgaria.\"\n[1] \"1 Olympic gold medalists are from Burundi.\"\n[1] \"20 Olympic gold medalists are from Cameroon.\"\n[1] \"463 Olympic gold medalists are from Canada.\"\n[1] \"3 Olympic gold medalists are from Chile.\"\n[1] \"351 Olympic gold medalists are from China.\"\n[1] \"5 Olympic gold medalists are from Colombia.\"\n[1] \"1 Olympic gold medalists are from Costa Rica.\"\n[1] \"58 Olympic gold medalists are from Croatia.\"\n[1] \"164 Olympic gold medalists are from Cuba.\"\n[1] \"123 Olympic gold medalists are from Czech Republic.\"\n[1] \"179 Olympic gold medalists are from Denmark.\"\n[1] \"3 Olympic gold medalists are from Dominican Republic.\"\n[1] \"1 Olympic gold medalists are from Ecuador.\"\n[1] \"7 Olympic gold medalists are from Egypt.\"\n[1] \"13 Olympic gold medalists are from Estonia.\"\n[1] \"22 Olympic gold medalists are from Ethiopia.\"\n[1] \"13 Olympic gold medalists are from Fiji.\"\n[1] \"198 Olympic gold medalists are from Finland.\"\n[1] \"501 Olympic gold medalists are from France.\"\n[1] \"8 Olympic gold medalists are from Georgia.\"\n[1] \"1301 Olympic gold medalists are from Germany.\"\n[1] \"62 Olympic gold medalists are from Greece.\"\n[1] \"1 Olympic gold medalists are from Grenada.\"\n[1] \"1 Olympic gold medalists are from Haiti.\"\n[1] \"432 Olympic gold medalists are from Hungary.\"\n[1] \"138 Olympic gold medalists are from India.\"\n[1] \"1 Olympic gold medalists are from Individual Olympic Athletes.\"\n[1] \"11 Olympic gold medalists are from Indonesia.\"\n[1] \"18 Olympic gold medalists are from Iran.\"\n[1] \"9 Olympic gold medalists are from Ireland.\"\n[1] \"1 Olympic gold medalists are from Israel.\"\n[1] \"575 Olympic gold medalists are from Italy.\"\n[1] \"1 Olympic gold medalists are from Ivory Coast.\"\n[1] \"38 Olympic gold medalists are from Jamaica.\"\n[1] \"247 Olympic gold medalists are from Japan.\"\n[1] \"1 Olympic gold medalists are from Jordan.\"\n[1] \"20 Olympic gold medalists are from Kazakhstan.\"\n[1] \"34 Olympic gold medalists are from Kenya.\"\n[1] \"1 Olympic gold medalists are from Kosovo.\"\n[1] \"3 Olympic gold medalists are from Latvia.\"\n[1] \"2 Olympic gold medalists are from Liechtenstein.\"\n[1] \"6 Olympic gold medalists are from Lithuania.\"\n[1] \"4 Olympic gold medalists are from Luxembourg.\"\n[1] \"30 Olympic gold medalists are from Mexico.\"\n[1] \"2 Olympic gold medalists are from Mongolia.\"\n[1] \"6 Olympic gold medalists are from Morocco.\"\n[1] \"1 Olympic gold medalists are from Mozambique.\"\n[1] \"1 Olympic gold medalists are from Nepal.\"\n[1] \"287 Olympic gold medalists are from Netherlands.\"\n[1] \"90 Olympic gold medalists are from New Zealand.\"\n[1] \"23 Olympic gold medalists are from Nigeria.\"\n[1] \"16 Olympic gold medalists are from North Korea.\"\n[1] \"378 Olympic gold medalists are from Norway.\"\n[1] \"42 Olympic gold medalists are from Pakistan.\"\n[1] \"1 Olympic gold medalists are from Panama.\"\n[1] \"1 Olympic gold medalists are from Peru.\"\n[1] \"117 Olympic gold medalists are from Poland.\"\n[1] \"4 Olympic gold medalists are from Portugal.\"\n[1] \"1 Olympic gold medalists are from Puerto Rico.\"\n[1] \"161 Olympic gold medalists are from Romania.\"\n[1] \"1599 Olympic gold medalists are from Russia.\"\n[1] \"157 Olympic gold medalists are from Serbia.\"\n[1] \"15 Olympic gold medalists are from Slovakia.\"\n[1] \"8 Olympic gold medalists are from Slovenia.\"\n[1] \"32 Olympic gold medalists are from South Africa.\"\n[1] \"221 Olympic gold medalists are from South Korea.\"\n[1] \"110 Olympic gold medalists are from Spain.\"\n[1] \"1 Olympic gold medalists are from Suriname.\"\n[1] \"479 Olympic gold medalists are from Sweden.\"\n[1] \"175 Olympic gold medalists are from Switzerland.\"\n[1] \"1 Olympic gold medalists are from Syria.\"\n[1] \"3 Olympic gold medalists are from Taiwan.\"\n[1] \"1 Olympic gold medalists are from Tajikistan.\"\n[1] \"9 Olympic gold medalists are from Thailand.\"\n[1] \"7 Olympic gold medalists are from Trinidad.\"\n[1] \"3 Olympic gold medalists are from Tunisia.\"\n[1] \"40 Olympic gold medalists are from Turkey.\"\n[1] \"678 Olympic gold medalists are from UK.\"\n[1] \"2638 Olympic gold medalists are from USA.\"\n[1] \"2 Olympic gold medalists are from Uganda.\"\n[1] \"47 Olympic gold medalists are from Ukraine.\"\n[1] \"1 Olympic gold medalists are from United Arab Emirates.\"\n[1] \"31 Olympic gold medalists are from Uruguay.\"\n[1] \"10 Olympic gold medalists are from Uzbekistan.\"\n[1] \"2 Olympic gold medalists are from Venezuela.\"\n[1] \"1 Olympic gold medalists are from Vietnam.\"\n[1] \"17 Olympic gold medalists are from Zimbabwe.\"\n\n\nSo this little piece of code can do what we started to do in the above code section, but already for all countries. Also, if we want to change something, we only have to change it once.\n\n\n\n\n\n\nTip\n\n\n\nIn general, try not to repeat yourself when writing code. As a general rule of thumb, use loops and/or functions if you need to copy/paste something more than two times.\n\n\n\n\nHow to write a for-loop?\nLet’s take a step back and look at what we are actually doing here. A for loop is generally constructed like this:\nfor(counter in values){\n  repeat something with changing counter\n}\nWhat does that mean? Let’s look at a simple example first. We want to multiply the values from 10 to 20 with 100 and then print them into our console:\n\nfor(i in 10:20){\n  new_i &lt;- i * 100\n  print(new_i)\n}\n\n[1] 1000\n[1] 1100\n[1] 1200\n[1] 1300\n[1] 1400\n[1] 1500\n[1] 1600\n[1] 1700\n[1] 1800\n[1] 1900\n[1] 2000\n\n\n\nIn the first iteration, i takes the value of the first vector element behind in, which is 10.\nThe operation in the loop body gets executed, in this case the current value gets multiplied by 100 and then printed into the console.\nAfter the operation is finished, i takes the next value, in this case 11, and the whole process starts again.\nThe loop is finished after the operation on the last value has been executed, in this case 20.\n\nLet’s get back to our initial example. Try to figure out what happens here by yourself. What is the first and the last value i gets assigned?\n\nfor(i in unique(medal_counts$Region)){\n  print(\n    paste0(\n      medal_counts[medal_counts$Region == i, \"n\"], \n      \" Olympic gold medalists are from \", \n      i, \n      \".\" )\n    )\n}\n\n[1] \"5 Olympic gold medalists are from Algeria.\"\n[1] \"91 Olympic gold medalists are from Argentina.\"\n[1] \"2 Olympic gold medalists are from Armenia.\"\n[1] \"368 Olympic gold medalists are from Australia.\"\n[1] \"108 Olympic gold medalists are from Austria.\"\n[1] \"7 Olympic gold medalists are from Azerbaijan.\"\n[1] \"14 Olympic gold medalists are from Bahamas.\"\n[1] \"1 Olympic gold medalists are from Bahrain.\"\n[1] \"24 Olympic gold medalists are from Belarus.\"\n[1] \"98 Olympic gold medalists are from Belgium.\"\n[1] \"109 Olympic gold medalists are from Brazil.\"\n[1] \"54 Olympic gold medalists are from Bulgaria.\"\n[1] \"1 Olympic gold medalists are from Burundi.\"\n[1] \"20 Olympic gold medalists are from Cameroon.\"\n[1] \"463 Olympic gold medalists are from Canada.\"\n[1] \"3 Olympic gold medalists are from Chile.\"\n[1] \"351 Olympic gold medalists are from China.\"\n[1] \"5 Olympic gold medalists are from Colombia.\"\n[1] \"1 Olympic gold medalists are from Costa Rica.\"\n[1] \"58 Olympic gold medalists are from Croatia.\"\n[1] \"164 Olympic gold medalists are from Cuba.\"\n[1] \"123 Olympic gold medalists are from Czech Republic.\"\n[1] \"179 Olympic gold medalists are from Denmark.\"\n[1] \"3 Olympic gold medalists are from Dominican Republic.\"\n[1] \"1 Olympic gold medalists are from Ecuador.\"\n[1] \"7 Olympic gold medalists are from Egypt.\"\n[1] \"13 Olympic gold medalists are from Estonia.\"\n[1] \"22 Olympic gold medalists are from Ethiopia.\"\n[1] \"13 Olympic gold medalists are from Fiji.\"\n[1] \"198 Olympic gold medalists are from Finland.\"\n[1] \"501 Olympic gold medalists are from France.\"\n[1] \"8 Olympic gold medalists are from Georgia.\"\n[1] \"1301 Olympic gold medalists are from Germany.\"\n[1] \"62 Olympic gold medalists are from Greece.\"\n[1] \"1 Olympic gold medalists are from Grenada.\"\n[1] \"1 Olympic gold medalists are from Haiti.\"\n[1] \"432 Olympic gold medalists are from Hungary.\"\n[1] \"138 Olympic gold medalists are from India.\"\n[1] \"1 Olympic gold medalists are from Individual Olympic Athletes.\"\n[1] \"11 Olympic gold medalists are from Indonesia.\"\n[1] \"18 Olympic gold medalists are from Iran.\"\n[1] \"9 Olympic gold medalists are from Ireland.\"\n[1] \"1 Olympic gold medalists are from Israel.\"\n[1] \"575 Olympic gold medalists are from Italy.\"\n[1] \"1 Olympic gold medalists are from Ivory Coast.\"\n[1] \"38 Olympic gold medalists are from Jamaica.\"\n[1] \"247 Olympic gold medalists are from Japan.\"\n[1] \"1 Olympic gold medalists are from Jordan.\"\n[1] \"20 Olympic gold medalists are from Kazakhstan.\"\n[1] \"34 Olympic gold medalists are from Kenya.\"\n[1] \"1 Olympic gold medalists are from Kosovo.\"\n[1] \"3 Olympic gold medalists are from Latvia.\"\n[1] \"2 Olympic gold medalists are from Liechtenstein.\"\n[1] \"6 Olympic gold medalists are from Lithuania.\"\n[1] \"4 Olympic gold medalists are from Luxembourg.\"\n[1] \"30 Olympic gold medalists are from Mexico.\"\n[1] \"2 Olympic gold medalists are from Mongolia.\"\n[1] \"6 Olympic gold medalists are from Morocco.\"\n[1] \"1 Olympic gold medalists are from Mozambique.\"\n[1] \"1 Olympic gold medalists are from Nepal.\"\n[1] \"287 Olympic gold medalists are from Netherlands.\"\n[1] \"90 Olympic gold medalists are from New Zealand.\"\n[1] \"23 Olympic gold medalists are from Nigeria.\"\n[1] \"16 Olympic gold medalists are from North Korea.\"\n[1] \"378 Olympic gold medalists are from Norway.\"\n[1] \"42 Olympic gold medalists are from Pakistan.\"\n[1] \"1 Olympic gold medalists are from Panama.\"\n[1] \"1 Olympic gold medalists are from Peru.\"\n[1] \"117 Olympic gold medalists are from Poland.\"\n[1] \"4 Olympic gold medalists are from Portugal.\"\n[1] \"1 Olympic gold medalists are from Puerto Rico.\"\n[1] \"161 Olympic gold medalists are from Romania.\"\n[1] \"1599 Olympic gold medalists are from Russia.\"\n[1] \"157 Olympic gold medalists are from Serbia.\"\n[1] \"15 Olympic gold medalists are from Slovakia.\"\n[1] \"8 Olympic gold medalists are from Slovenia.\"\n[1] \"32 Olympic gold medalists are from South Africa.\"\n[1] \"221 Olympic gold medalists are from South Korea.\"\n[1] \"110 Olympic gold medalists are from Spain.\"\n[1] \"1 Olympic gold medalists are from Suriname.\"\n[1] \"479 Olympic gold medalists are from Sweden.\"\n[1] \"175 Olympic gold medalists are from Switzerland.\"\n[1] \"1 Olympic gold medalists are from Syria.\"\n[1] \"3 Olympic gold medalists are from Taiwan.\"\n[1] \"1 Olympic gold medalists are from Tajikistan.\"\n[1] \"9 Olympic gold medalists are from Thailand.\"\n[1] \"7 Olympic gold medalists are from Trinidad.\"\n[1] \"3 Olympic gold medalists are from Tunisia.\"\n[1] \"40 Olympic gold medalists are from Turkey.\"\n[1] \"678 Olympic gold medalists are from UK.\"\n[1] \"2638 Olympic gold medalists are from USA.\"\n[1] \"2 Olympic gold medalists are from Uganda.\"\n[1] \"47 Olympic gold medalists are from Ukraine.\"\n[1] \"1 Olympic gold medalists are from United Arab Emirates.\"\n[1] \"31 Olympic gold medalists are from Uruguay.\"\n[1] \"10 Olympic gold medalists are from Uzbekistan.\"\n[1] \"2 Olympic gold medalists are from Venezuela.\"\n[1] \"1 Olympic gold medalists are from Vietnam.\"\n[1] \"17 Olympic gold medalists are from Zimbabwe.\"\n\n\nIn this example we don’t loop over some numbers, but over the unique regions in our medal_counts data frame:\n\nunique(medal_counts$Region)\n\n [1] \"Algeria\"                     \"Argentina\"                  \n [3] \"Armenia\"                     \"Australia\"                  \n [5] \"Austria\"                     \"Azerbaijan\"                 \n [7] \"Bahamas\"                     \"Bahrain\"                    \n [9] \"Belarus\"                     \"Belgium\"                    \n[11] \"Brazil\"                      \"Bulgaria\"                   \n[13] \"Burundi\"                     \"Cameroon\"                   \n[15] \"Canada\"                      \"Chile\"                      \n[17] \"China\"                       \"Colombia\"                   \n[19] \"Costa Rica\"                  \"Croatia\"                    \n[21] \"Cuba\"                        \"Czech Republic\"             \n[23] \"Denmark\"                     \"Dominican Republic\"         \n[25] \"Ecuador\"                     \"Egypt\"                      \n[27] \"Estonia\"                     \"Ethiopia\"                   \n[29] \"Fiji\"                        \"Finland\"                    \n[31] \"France\"                      \"Georgia\"                    \n[33] \"Germany\"                     \"Greece\"                     \n[35] \"Grenada\"                     \"Haiti\"                      \n[37] \"Hungary\"                     \"India\"                      \n[39] \"Individual Olympic Athletes\" \"Indonesia\"                  \n[41] \"Iran\"                        \"Ireland\"                    \n[43] \"Israel\"                      \"Italy\"                      \n[45] \"Ivory Coast\"                 \"Jamaica\"                    \n[47] \"Japan\"                       \"Jordan\"                     \n[49] \"Kazakhstan\"                  \"Kenya\"                      \n[51] \"Kosovo\"                      \"Latvia\"                     \n[53] \"Liechtenstein\"               \"Lithuania\"                  \n[55] \"Luxembourg\"                  \"Mexico\"                     \n[57] \"Mongolia\"                    \"Morocco\"                    \n[59] \"Mozambique\"                  \"Nepal\"                      \n[61] \"Netherlands\"                 \"New Zealand\"                \n[63] \"Nigeria\"                     \"North Korea\"                \n[65] \"Norway\"                      \"Pakistan\"                   \n[67] \"Panama\"                      \"Peru\"                       \n[69] \"Poland\"                      \"Portugal\"                   \n[71] \"Puerto Rico\"                 \"Romania\"                    \n[73] \"Russia\"                      \"Serbia\"                     \n[75] \"Slovakia\"                    \"Slovenia\"                   \n[77] \"South Africa\"                \"South Korea\"                \n[79] \"Spain\"                       \"Suriname\"                   \n[81] \"Sweden\"                      \"Switzerland\"                \n[83] \"Syria\"                       \"Taiwan\"                     \n[85] \"Tajikistan\"                  \"Thailand\"                   \n[87] \"Trinidad\"                    \"Tunisia\"                    \n[89] \"Turkey\"                      \"UK\"                         \n[91] \"USA\"                         \"Uganda\"                     \n[93] \"Ukraine\"                     \"United Arab Emirates\"       \n[95] \"Uruguay\"                     \"Uzbekistan\"                 \n[97] \"Venezuela\"                   \"Vietnam\"                    \n[99] \"Zimbabwe\"                   \n\n\ni takes each of these elements in turn, then the corresponding n value of each country gets extracted and pasted into some sentence."
  },
  {
    "objectID": "qmd/loops/loops.html#conditions",
    "href": "qmd/loops/loops.html#conditions",
    "title": "Loops and conditions",
    "section": "Conditions",
    "text": "Conditions\n\nIf-else statement\nHave you noticed that our output doesn’t sound that correct if we only have one gold medal winner in a country?\n\"1 Olympic gold medalists are from Mozambique.\"\nTo solve this, we can add a conditional statement which only gets executed, if some condition is met. This can be done by an if else statement:\n\nfor(i in unique(medal_counts$Region)){\n  n_medals &lt;- medal_counts[medal_counts$Region == i, \"n\"]\n  \n  if(n_medals == 1){\n    print(\n    paste0(\n      \"One Olympic gold medalist is from \", \n      i, \n      \".\" )\n    )\n  }else{\n  print(\n    paste0(\n      n_medals, \n      \" Olympic gold medalists are from \", \n      i, \n      \".\" )\n    )\n  }\n}\n\n[1] \"5 Olympic gold medalists are from Algeria.\"\n[1] \"91 Olympic gold medalists are from Argentina.\"\n[1] \"2 Olympic gold medalists are from Armenia.\"\n[1] \"368 Olympic gold medalists are from Australia.\"\n[1] \"108 Olympic gold medalists are from Austria.\"\n[1] \"7 Olympic gold medalists are from Azerbaijan.\"\n[1] \"14 Olympic gold medalists are from Bahamas.\"\n[1] \"One Olympic gold medalist is from Bahrain.\"\n[1] \"24 Olympic gold medalists are from Belarus.\"\n[1] \"98 Olympic gold medalists are from Belgium.\"\n[1] \"109 Olympic gold medalists are from Brazil.\"\n[1] \"54 Olympic gold medalists are from Bulgaria.\"\n[1] \"One Olympic gold medalist is from Burundi.\"\n[1] \"20 Olympic gold medalists are from Cameroon.\"\n[1] \"463 Olympic gold medalists are from Canada.\"\n[1] \"3 Olympic gold medalists are from Chile.\"\n[1] \"351 Olympic gold medalists are from China.\"\n[1] \"5 Olympic gold medalists are from Colombia.\"\n[1] \"One Olympic gold medalist is from Costa Rica.\"\n[1] \"58 Olympic gold medalists are from Croatia.\"\n[1] \"164 Olympic gold medalists are from Cuba.\"\n[1] \"123 Olympic gold medalists are from Czech Republic.\"\n[1] \"179 Olympic gold medalists are from Denmark.\"\n[1] \"3 Olympic gold medalists are from Dominican Republic.\"\n[1] \"One Olympic gold medalist is from Ecuador.\"\n[1] \"7 Olympic gold medalists are from Egypt.\"\n[1] \"13 Olympic gold medalists are from Estonia.\"\n[1] \"22 Olympic gold medalists are from Ethiopia.\"\n[1] \"13 Olympic gold medalists are from Fiji.\"\n[1] \"198 Olympic gold medalists are from Finland.\"\n[1] \"501 Olympic gold medalists are from France.\"\n[1] \"8 Olympic gold medalists are from Georgia.\"\n[1] \"1301 Olympic gold medalists are from Germany.\"\n[1] \"62 Olympic gold medalists are from Greece.\"\n[1] \"One Olympic gold medalist is from Grenada.\"\n[1] \"One Olympic gold medalist is from Haiti.\"\n[1] \"432 Olympic gold medalists are from Hungary.\"\n[1] \"138 Olympic gold medalists are from India.\"\n[1] \"One Olympic gold medalist is from Individual Olympic Athletes.\"\n[1] \"11 Olympic gold medalists are from Indonesia.\"\n[1] \"18 Olympic gold medalists are from Iran.\"\n[1] \"9 Olympic gold medalists are from Ireland.\"\n[1] \"One Olympic gold medalist is from Israel.\"\n[1] \"575 Olympic gold medalists are from Italy.\"\n[1] \"One Olympic gold medalist is from Ivory Coast.\"\n[1] \"38 Olympic gold medalists are from Jamaica.\"\n[1] \"247 Olympic gold medalists are from Japan.\"\n[1] \"One Olympic gold medalist is from Jordan.\"\n[1] \"20 Olympic gold medalists are from Kazakhstan.\"\n[1] \"34 Olympic gold medalists are from Kenya.\"\n[1] \"One Olympic gold medalist is from Kosovo.\"\n[1] \"3 Olympic gold medalists are from Latvia.\"\n[1] \"2 Olympic gold medalists are from Liechtenstein.\"\n[1] \"6 Olympic gold medalists are from Lithuania.\"\n[1] \"4 Olympic gold medalists are from Luxembourg.\"\n[1] \"30 Olympic gold medalists are from Mexico.\"\n[1] \"2 Olympic gold medalists are from Mongolia.\"\n[1] \"6 Olympic gold medalists are from Morocco.\"\n[1] \"One Olympic gold medalist is from Mozambique.\"\n[1] \"One Olympic gold medalist is from Nepal.\"\n[1] \"287 Olympic gold medalists are from Netherlands.\"\n[1] \"90 Olympic gold medalists are from New Zealand.\"\n[1] \"23 Olympic gold medalists are from Nigeria.\"\n[1] \"16 Olympic gold medalists are from North Korea.\"\n[1] \"378 Olympic gold medalists are from Norway.\"\n[1] \"42 Olympic gold medalists are from Pakistan.\"\n[1] \"One Olympic gold medalist is from Panama.\"\n[1] \"One Olympic gold medalist is from Peru.\"\n[1] \"117 Olympic gold medalists are from Poland.\"\n[1] \"4 Olympic gold medalists are from Portugal.\"\n[1] \"One Olympic gold medalist is from Puerto Rico.\"\n[1] \"161 Olympic gold medalists are from Romania.\"\n[1] \"1599 Olympic gold medalists are from Russia.\"\n[1] \"157 Olympic gold medalists are from Serbia.\"\n[1] \"15 Olympic gold medalists are from Slovakia.\"\n[1] \"8 Olympic gold medalists are from Slovenia.\"\n[1] \"32 Olympic gold medalists are from South Africa.\"\n[1] \"221 Olympic gold medalists are from South Korea.\"\n[1] \"110 Olympic gold medalists are from Spain.\"\n[1] \"One Olympic gold medalist is from Suriname.\"\n[1] \"479 Olympic gold medalists are from Sweden.\"\n[1] \"175 Olympic gold medalists are from Switzerland.\"\n[1] \"One Olympic gold medalist is from Syria.\"\n[1] \"3 Olympic gold medalists are from Taiwan.\"\n[1] \"One Olympic gold medalist is from Tajikistan.\"\n[1] \"9 Olympic gold medalists are from Thailand.\"\n[1] \"7 Olympic gold medalists are from Trinidad.\"\n[1] \"3 Olympic gold medalists are from Tunisia.\"\n[1] \"40 Olympic gold medalists are from Turkey.\"\n[1] \"678 Olympic gold medalists are from UK.\"\n[1] \"2638 Olympic gold medalists are from USA.\"\n[1] \"2 Olympic gold medalists are from Uganda.\"\n[1] \"47 Olympic gold medalists are from Ukraine.\"\n[1] \"One Olympic gold medalist is from United Arab Emirates.\"\n[1] \"31 Olympic gold medalists are from Uruguay.\"\n[1] \"10 Olympic gold medalists are from Uzbekistan.\"\n[1] \"2 Olympic gold medalists are from Venezuela.\"\n[1] \"One Olympic gold medalist is from Vietnam.\"\n[1] \"17 Olympic gold medalists are from Zimbabwe.\"\n\n\nLet’s look at a more simple example to explain the concept:\nif(condition){\n  do something\n}else{\n  do something else\n}\nFor example:\n\nx &lt;- 10\n\nif(x &lt; 100){\n  x * 2\n}else{\n  x\n}\n\n[1] 20\n\n\nInside the if() we define our condition. Then, inside the { } we define an operation that gets executed, if this condition is met. Inside the else{ } part we define an operation that gets executed if the condition in if() is not met.\nIn our inital example we check if the number of gold medalists is equal to one. If that is the case, we print the specific statement. If not, we print the other.\n\n\nifelse()\nWe can use this concept for adding new values conditionally to a data frame. For example, let’s build a dichotomous variable to check which countries have equal to or more than 100 gold medal winners:\nNote that the look of this ifelse() function is a bit different from our if else statement, but the logic behind it is exactly the same: Here we add the new column n_100 which gets filled with TRUE and FALSE. If the statement medal_counts$n &gt;= 100, which is the first argument of the ifelse() function, is met, the function returns a TRUE, if not a FALSE.\n\n\n\n\n\n\nTip\n\n\n\nIt should be noted that in general it is good practice to try to avoid using for loops and use functions from the apply-family instead, as for-loops allow you to write horrible code. Still, sometimes for-loops are the better option, depending on the use case. Also, their structure is pretty much the same over many programming languages."
  },
  {
    "objectID": "qmd/loops/loops.html#footnotes",
    "href": "qmd/loops/loops.html#footnotes",
    "title": "Loops and conditions",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nImage by Tine Ivanic on Unsplash.↩︎"
  },
  {
    "objectID": "qmd/subsetting/subsetting.html",
    "href": "qmd/subsetting/subsetting.html",
    "title": "Subsetting",
    "section": "",
    "text": "Previous code\n\n\n\n\n\n\nathletes &lt;- readRDS(file = here::here(\"raw_data\", \"athletes.rds\"))\nSubsetting means extracting smaller sets of data from a bigger set. For example, we can extract specific rows from a data frame, or specific values from a vector. Let’s take a look at how that is achieved in R:"
  },
  {
    "objectID": "qmd/subsetting/subsetting.html#data-frames",
    "href": "qmd/subsetting/subsetting.html#data-frames",
    "title": "Subsetting",
    "section": "Data frames",
    "text": "Data frames\nIn R we use square brackets [,] to extract specific rows and columns.\n\nRows\nIn front of the , we write the rows we want to extract:\n\n# Extract the first and the fourth row\nathletes[c(1, 4), ]\n\n  NOC     ID              Name Sex Age Height Weight        Team       Games\n1 AFG 132181       Najam Yahya   M  NA     NA     NA Afghanistan 1956 Summer\n4 AFG    502 Ahmad Shah Abouwi   M  NA     NA     NA Afghanistan 1956 Summer\n  Year Season      City  Sport               Event Medal      Region\n...\n\n\n\n\nColumns\nBehind it the columns:\n\n# Extract the second and the fourth column:\nathletes[, c(2, 4)]\n\n          ID Sex\n1     132181   M\n2      87371   M\n3      44977   M\n...\n\n# Extract the columns by name:\nathletes[, c(\"Year\", \"Sport\")]\n\n      Year                     Sport\n1     1956                    Hockey\n2     1948                    Hockey\n3     1980                 Wrestling\n...\n\n# Or only the column Year (and turn it into a vector right away):\nathletes$Year\n\n    [1] 1956 1948 1980 1956 1964 1960 1936 1956 1972 1956 1960 1948 1980 1948\n   [15] 1960 1936 1960 1968 1948 1972 1956 1980 1956 2016 1968 1948 1980 1936\n   [29] 1988 1948 1956 1988 1956 1972 1960 1980 1972 2004 1980 1960 1972 1980\n   [43] 1956 1964 1948 2008 1996 1980 1968 1960 1972 1972 1948 1936 2004 1936\n...\n\n\n\n\n\n\n\n\nTip\n\n\n\nAlways use column names instead of position if possible. This way, your code will still work if the column position changes.\n\n\n\n\nRows & Columns\nAnd of course we can combine both calls:\n\nathletes[c(1, 4), c(2, 4)]\n\n      ID Sex\n1 132181   M\n4    502   M\n\nathletes[c(1, 4), c(\"Year\", \"Sport\")]\n\n  Year  Sport\n1 1956 Hockey\n4 1956 Hockey\n\n\nWe can also use Boolean values (every row/column must get a value here, so we extract the first 100 rows by repeating TRUE 100 times, and than add FALSE for the remaining rows):\n\nstr(athletes[c(rep(TRUE, 100), rep(FALSE, 271016)), ])\n\n'data.frame':   100 obs. of  16 variables:\n $ NOC   : chr  \"AFG\" \"AFG\" \"AFG\" \"AFG\" ...\n $ ID    : int  132181 87371 44977 502 109153 29626 1076 121376 80210 87374 ...\n $ Name  : chr  \"Najam Yahya\" \"Ahmad Jahan Nuristani\" \"Mohammad Halilula\" \"Ahmad Shah Abouwi\" ...\n $ Sex   : chr  \"M\" \"M\" \"M\" \"M\" ...\n $ Age   : int  NA NA 28 NA 24 28 28 NA NA NA ...\n $ Height: int  NA NA 163 NA NA 168 NA NA NA NA ...\n $ Weight: num  NA NA 57 NA 74 73 NA NA 57 NA ...\n $ Team  : chr  \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ...\n $ Games : chr  \"1956 Summer\" \"1948 Summer\" \"1980 Summer\" \"1956 Summer\" ...\n $ Year  : int  1956 1948 1980 1956 1964 1960 1936 1956 1972 1956 ...\n $ Season: chr  \"Summer\" \"Summer\" \"Summer\" \"Summer\" ...\n $ City  : chr  \"Melbourne\" \"London\" \"Moskva\" \"Melbourne\" ...\n $ Sport : chr  \"Hockey\" \"Hockey\" \"Wrestling\" \"Hockey\" ...\n $ Event : chr  \"Hockey Men's Hockey\" \"Hockey Men's Hockey\" \"Wrestling Men's Bantamweight, Freestyle\" \"Hockey Men's Hockey\" ...\n $ Medal : chr  NA NA NA NA ...\n $ Region: chr  \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ...\n\n\n\n\n\n\n\n\nTip\n\n\n\nInstead of writing 271016 we should actually use the current row number, in case that changes as well:\n\nstr(athletes[c(rep(TRUE, 100), rep(FALSE, nrow(athletes) - 100)), ])\n\n'data.frame':   100 obs. of  16 variables:\n $ NOC   : chr  \"AFG\" \"AFG\" \"AFG\" \"AFG\" ...\n $ ID    : int  132181 87371 44977 502 109153 29626 1076 121376 80210 87374 ...\n $ Name  : chr  \"Najam Yahya\" \"Ahmad Jahan Nuristani\" \"Mohammad Halilula\" \"Ahmad Shah Abouwi\" ...\n $ Sex   : chr  \"M\" \"M\" \"M\" \"M\" ...\n $ Age   : int  NA NA 28 NA 24 28 28 NA NA NA ...\n $ Height: int  NA NA 163 NA NA 168 NA NA NA NA ...\n $ Weight: num  NA NA 57 NA 74 73 NA NA 57 NA ...\n $ Team  : chr  \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ...\n $ Games : chr  \"1956 Summer\" \"1948 Summer\" \"1980 Summer\" \"1956 Summer\" ...\n $ Year  : int  1956 1948 1980 1956 1964 1960 1936 1956 1972 1956 ...\n $ Season: chr  \"Summer\" \"Summer\" \"Summer\" \"Summer\" ...\n $ City  : chr  \"Melbourne\" \"London\" \"Moskva\" \"Melbourne\" ...\n $ Sport : chr  \"Hockey\" \"Hockey\" \"Wrestling\" \"Hockey\" ...\n $ Event : chr  \"Hockey Men's Hockey\" \"Hockey Men's Hockey\" \"Wrestling Men's Bantamweight, Freestyle\" \"Hockey Men's Hockey\" ...\n $ Medal : chr  NA NA NA NA ...\n $ Region: chr  \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ...\n\n\n\n\n\n\nConditional filtering\nNow the stuff we looked at in logical operators comes in handy! We can filter rows which match some condition. For example, we might want to look at all athletes from Germany:\n\nathletes[athletes$Team == \"Germany\", ]\n\n       NOC     ID\n107246 GER   7385\n107247 GER 114424\n107248 GER 112937\n...\n\n\n\n\n\n\n\n\nUnfold if you want to take a closer look at what is happening here\n\n\n\n\n\nTake a close look at the comparison before the ,:\n\nathletes$Team == \"Germany\"\n\n    [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n   [13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n   [25] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n   [37] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n...\n\n\nathletes$Team is a vector, so comparing its values to a specified value yields a logical vector with the respective TRUE and FALSE values. We can insert this logical vector in front of the , to extract all rows corresponding to that condition.\n\n\n\nIf we want to extract multiple nationalities at once, we need the %in% operator:\n\nathletes[athletes$Team %in% c(\"Kenya\", \"Norway\"), ]\n\n       NOC     ID                                                          Name\n156375 KEN  60617                                               Nixon Kiprotich\n156376 KEN  85669                                             Benjamin Ngaruiya\n156377 KEN  60620                                    Wilson Arap Chuma Kiprugut\n...\n\n\nBy the way, if we want to save our extracted data frame, we can assign it a new name (otherwise it will only get printed into the console, but we can’t go on working with it):\n\nathletes_team &lt;- athletes[athletes$Team %in% c(\"Kenya\", \"Norway\"), ]\nathletes_team\n\n       NOC     ID                                                          Name\n156375 KEN  60617                                               Nixon Kiprotich\n156376 KEN  85669                                             Benjamin Ngaruiya\n156377 KEN  60620                                    Wilson Arap Chuma Kiprugut\n...\n\n\nWe can also combine multiple logical vectors using & (“and”) and | (“or”). For example, we might want to look at all german athletes before the year 2000:\n\nathletes_2 &lt;- athletes[athletes$Team == \"Germany\" & athletes$Year &lt; 2000, ]\nhead(athletes_2)\n\n       NOC     ID                   Name Sex Age Height Weight    Team\n107246 GER   7385     Dirk Peter Balster   M  26    195     90 Germany\n107247 GER 114424 Kathleen Stark (-Kern)   F  16    166     51 Germany\n107250 GER   9399     Petra Behle-Schaaf   F  23    177     67 Germany\n107252 GER   9398 Jochen Friedrich Behle   M  37    183     73 Germany\n107253 GER  47318          Martin Heinze   M  21    172     73 Germany\n107254 GER  96348        Ramona Portwich   F  25    175     70 Germany\n             Games Year Season        City                Sport\n107246 1992 Summer 1992 Summer   Barcelona               Rowing\n107247 1992 Summer 1992 Summer   Barcelona           Gymnastics\n107250 1992 Winter 1992 Winter Albertville             Biathlon\n107252 1998 Winter 1998 Winter      Nagano Cross Country Skiing\n107253 1960 Summer 1960 Summer        Roma            Wrestling\n107254 1992 Summer 1992 Summer   Barcelona             Canoeing\n                                            Event Medal  Region\n107246                 Rowing Men's Coxless Fours  &lt;NA&gt; Germany\n107247             Gymnastics Women's Uneven Bars  &lt;NA&gt; Germany\n107250     Biathlon Women's 7.5 kilometres Sprint  &lt;NA&gt; Germany\n107252   Cross Country Skiing Men's 10 kilometres  &lt;NA&gt; Germany\n107253    Wrestling Men's Welterweight, Freestyle  &lt;NA&gt; Germany\n107254 Canoeing Women's Kayak Doubles, 500 metres  Gold Germany\n\n\nOr at all judo athletes weighting over 100 or under 50 kg:\n\nathletes_3 &lt;- athletes[(athletes$Sport == \"Judo\") & (athletes$Weight &gt; 100 | athletes$Weight &lt; 50) , ]\nhead(athletes_3)\n\n      NOC    ID                Name  Sex Age Height Weight    Team       Games\nNA   &lt;NA&gt;    NA                &lt;NA&gt; &lt;NA&gt;  NA     NA     NA    &lt;NA&gt;        &lt;NA&gt;\nNA.1 &lt;NA&gt;    NA                &lt;NA&gt; &lt;NA&gt;  NA     NA     NA    &lt;NA&gt;        &lt;NA&gt;\nNA.2 &lt;NA&gt;    NA                &lt;NA&gt; &lt;NA&gt;  NA     NA     NA    &lt;NA&gt;        &lt;NA&gt;\nNA.3 &lt;NA&gt;    NA                &lt;NA&gt; &lt;NA&gt;  NA     NA     NA    &lt;NA&gt;        &lt;NA&gt;\n471   ALG 13895 Mohamed Bouaichaoui    M  25    178    120 Algeria 2004 Summer\nNA.4 &lt;NA&gt;    NA                &lt;NA&gt; &lt;NA&gt;  NA     NA     NA    &lt;NA&gt;        &lt;NA&gt;\n     Year Season   City Sport                  Event Medal  Region\nNA     NA   &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;                   &lt;NA&gt;  &lt;NA&gt;    &lt;NA&gt;\nNA.1   NA   &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;                   &lt;NA&gt;  &lt;NA&gt;    &lt;NA&gt;\nNA.2   NA   &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;                   &lt;NA&gt;  &lt;NA&gt;    &lt;NA&gt;\nNA.3   NA   &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;                   &lt;NA&gt;  &lt;NA&gt;    &lt;NA&gt;\n471  2004 Summer Athina  Judo Judo Men's Heavyweight  &lt;NA&gt; Algeria\nNA.4   NA   &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;                   &lt;NA&gt;  &lt;NA&gt;    &lt;NA&gt;\n\n\nHmm, that looks a bit weird. Some rows only contain NA values. That’s because there are missing values in the Weight column. We will look at that closer in the missings chapter and ignore that problem for now.\nIn the long run, always having to specify the name of the data frame for each column or row with condition can become a bit annoying and clutters the code. Also this code leaves all rows with missing values…\nInstead, we can use the filter() function from the tidyverse:\n\n\nRows: Tidyverse\n\n\nlibrary(tidyverse)\n\nathletes %&gt;% \n  filter(Sport == \"Judo\", (Weight &gt; 100 | Weight &lt; 50))\n\n    NOC     ID                                 Name Sex Age Height Weight\n1   ALG  13895                  Mohamed Bouaichaoui   M  25    178  120.0\n2   ALG  82643                        Meriem Moussa   F  20    150   48.0\n3   ALG  80035                      Boualem Miloudi   M  23    192  106.0\n...\n\n\n\nNote how we can just write our conditions without connecting them with & (filter() does that automatically for us). Also, we don’t have to put the column names into \"\", because filter() knows that this are column names of the athletes data frame, which makes coding a bit more pleasant. And finally, missing rows are automatically removed, which makes sense in many cases!\n\n\nColumns: Tidyverse\nFor extracting columns, we need select():\n\n\nathletes %&gt;%\n  select(Year, Sport)\n\n      Year                     Sport\n1     1956                    Hockey\n2     1948                    Hockey\n3     1980                 Wrestling\n..."
  },
  {
    "objectID": "qmd/subsetting/subsetting.html#vectors",
    "href": "qmd/subsetting/subsetting.html#vectors",
    "title": "Subsetting",
    "section": "Vectors",
    "text": "Vectors\nFinally, let’s take a quick look at how to extract elements from a vector, which shouldn’t be a problem after already dealing with data frames. It’s pretty straight forward: we just put the position of the element we want to extract behind the vector in square brackets (without a ,, as we only have a one dimensional object). Let’s quickly define a vector for illustration:\n\nvec_sport &lt;- athletes$Sport # remember: `$` returns a vector\n\nAnd look at the second element:\n\nvec_sport[2]\n\n[1] \"Hockey\"\n\n\nOf course we can also do that for multiple elements:\n\nvec_sport[c(2, 3, 4)]\n\n[1] \"Hockey\"    \"Wrestling\" \"Hockey\"   \n\n## Or, less to write:\nvec_sport[2:4]\n\n[1] \"Hockey\"    \"Wrestling\" \"Hockey\"   \n\n\nAnother way would be to provide a logical vector, which defines for each position if we want to extract the element or not (like we already did for data frames):\n\nvec_sport[c(rep(TRUE, 100), rep(FALSE, 65))]\n\n    [1] \"Hockey\"                    \"Hockey\"                   \n    [3] \"Wrestling\"                 \"Hockey\"                   \n    [5] \"Wrestling\"                 \"Wrestling\"                \n    [7] \"Hockey\"                    \"Hockey\"                   \n..."
  },
  {
    "objectID": "qmd/subsetting/subsetting.html#lists",
    "href": "qmd/subsetting/subsetting.html#lists",
    "title": "Subsetting",
    "section": "Lists",
    "text": "Lists\nWhen subsetting lists we have to options:\n\n# Define an example list:\nshow_list &lt;- list(\"TV-Show\" = c(\"Friends\", \"How I Met Your Mother\"), \n                  \"dat\" = data.frame(\"name\" = c(\"Monica\", \"Ted\"), \n                                     \"age\" = c(24, 27)\n                                     )\n                  )\n\n\nWe can extract a list element. This is done by single square brackets:\n\n\nstr(show_list[2])\n\nList of 1\n $ dat:'data.frame':    2 obs. of  2 variables:\n  ..$ name: chr [1:2] \"Monica\" \"Ted\"\n  ..$ age : num [1:2] 24 27\n\n\nNote how the result is still a list? It’s like taking out a drawer from a closet, but keeping the content inside this drawer.\n\nWe can extract the element that is stored inside the list element. This is done by double square brackets:\n\n\nstr(show_list[[2]])\n\n'data.frame':   2 obs. of  2 variables:\n $ name: chr  \"Monica\" \"Ted\"\n $ age : num  24 27\n\n\nHere the result is the data frame that was saved inside the list. It’s like taking the content out of the drawer."
  },
  {
    "objectID": "qmd/workflow/workflow.html",
    "href": "qmd/workflow/workflow.html",
    "title": "Workflow",
    "section": "",
    "text": "Over time, it will become increasingly hard to organize all your files, working directories and workspaces in a sensible manner. A reasonable big project will consist of multiple script files, data, output and plots. To keep everything toghether, RStudio Projects can be used (highly recommended). Therefore, when starting a new project in R, the first thing you should do is creating an RStudio project.\nYou can create a new RStudio project by clicking on File - New Project in the RStudio window. You can either create a totally new directory, or choose an already existing folder for the project."
  },
  {
    "objectID": "qmd/workflow/workflow.html#rstudio-projects",
    "href": "qmd/workflow/workflow.html#rstudio-projects",
    "title": "Workflow",
    "section": "",
    "text": "Over time, it will become increasingly hard to organize all your files, working directories and workspaces in a sensible manner. A reasonable big project will consist of multiple script files, data, output and plots. To keep everything toghether, RStudio Projects can be used (highly recommended). Therefore, when starting a new project in R, the first thing you should do is creating an RStudio project.\nYou can create a new RStudio project by clicking on File - New Project in the RStudio window. You can either create a totally new directory, or choose an already existing folder for the project."
  },
  {
    "objectID": "qmd/workflow/workflow.html#scripts",
    "href": "qmd/workflow/workflow.html#scripts",
    "title": "Workflow",
    "section": "Scripts",
    "text": "Scripts\nScripts are the documents code is saved in. Therefore, every time you start a new project, you should also create at least one script to put your code in. If you have a lot of code, you can also split it up among several scripts to make it more readable.\nYou can create a new script by clicking on File - New File - R Script in the RStudio window.\nNow it’s your turn! In the Workflow: Exercises you will set yourself up for the following workshop."
  },
  {
    "objectID": "qmd/missing/missing.html",
    "href": "qmd/missing/missing.html",
    "title": "Missing values",
    "section": "",
    "text": "1\nRemember the weird NA rows we encountered when subsetting by condition? We were able to steer around that by using filter(), but let’s take a closer look at that now.\nMissing values are denoted in R by NA (or NaN in some cases). They nullify a calculation or comparison pretty strongly - if one missing value is found somewhere along the line, the result will also be NA (if not specified otherwise):\nc(4, NA) &gt; 3\n\n[1] TRUE   NA\nThat’s why we got some NA rows when trying to extract specific rows by weight: these rows had an NA in the weight column, and R returned rows with NA's as a result.\nTo check if values are NA, we can use is.na():\nis.na(athletes$Weight)\n\n    [1]  TRUE  TRUE FALSE  TRUE FALSE FALSE  TRUE  TRUE FALSE  TRUE FALSE  TRUE\n   [13] FALSE  TRUE FALSE  TRUE FALSE FALSE  TRUE FALSE  TRUE FALSE  TRUE FALSE\n   [25] FALSE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE\n   [37] FALSE  TRUE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE FALSE  TRUE FALSE\n...\nSome TRUEs, so there are missing values here. Let’s count them (Summing a logical vector counts the number of TRUE values.):\nsum(is.na(athletes$Weight))\n\n[1] 62785\nWe seem to have 62785 missings in this column.\nThere are multiple different ways to deal with missings. For our comparison problem, we can add the new condition that all rows selected shouldn’t have an NA in the Weight column:\nathletes[(athletes$Sport == \"Judo\") & (athletes$Weight &gt; 100 | athletes$Weight &lt; 50) & !is.na(athletes$Weight), ]\n\n       NOC     ID                                 Name Sex Age Height Weight\n471    ALG  13895                  Mohamed Bouaichaoui   M  25    178  120.0\n673    ALG  82643                        Meriem Moussa   F  20    150   48.0\n702    ALG  80035                      Boualem Miloudi   M  23    192  106.0\n...\nWhat happens here? Like always when filtering specific rows, we define a logical vector, which has a TRUE for all rows that have a missing on ID and a FALSE for all others (by using the ! operator, which inverts the boolean values - otherwise we would extract all rows with missing values in the Weight column):\n!is.na(athletes$Weight)\n\n    [1] FALSE FALSE  TRUE FALSE  TRUE  TRUE FALSE FALSE  TRUE FALSE  TRUE FALSE\n   [13]  TRUE FALSE  TRUE FALSE  TRUE  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE\n   [25]  TRUE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE\n   [37]  TRUE FALSE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE  TRUE FALSE  TRUE\n...\nWe also assign the new name athletes_na to the resulting data frame, so we don’t overwrite the original one.\nRemoving NA's from a data frame works pretty similar:\nathletes_na &lt;- athletes[!is.na(athletes$Weight), ]\nhead(athletes_na)\n\n   NOC     ID                 Name Sex Age Height Weight        Team\n3  AFG  44977    Mohammad Halilula   M  28    163     57 Afghanistan\n5  AFG 109153   Shakar Khan Shakar   M  24     NA     74 Afghanistan\n6  AFG  29626 Sultan Mohammad Dost   M  28    168     73 Afghanistan\n9  AFG  80210             Alam Mir   M  NA     NA     57 Afghanistan\n11 AFG 116125 Nizam-ud-din Subhani   M  34    168    111 Afghanistan\n13 AFG 133692    Khojawahid Zahedi   M  20    178     74 Afghanistan\n         Games Year Season   City     Sport\n3  1980 Summer 1980 Summer Moskva Wrestling\n5  1964 Summer 1964 Summer  Tokyo Wrestling\n6  1960 Summer 1960 Summer   Roma Wrestling\n9  1972 Summer 1972 Summer Munich Wrestling\n11 1960 Summer 1960 Summer   Roma Wrestling\n13 1980 Summer 1980 Summer Moskva Wrestling\n                                       Event Medal      Region\n3    Wrestling Men's Bantamweight, Freestyle  &lt;NA&gt; Afghanistan\n5    Wrestling Men's Welterweight, Freestyle  &lt;NA&gt; Afghanistan\n6    Wrestling Men's Welterweight, Freestyle  &lt;NA&gt; Afghanistan\n9  Wrestling Men's Bantamweight, Greco-Roman  &lt;NA&gt; Afghanistan\n11    Wrestling Men's Heavyweight, Freestyle  &lt;NA&gt; Afghanistan\n13   Wrestling Men's Welterweight, Freestyle  &lt;NA&gt; Afghanistan\nBoth code versions will remove all rows containing NAs in the weight column.\nAs already stated, it is not always necessary to remove NAs manually from the data set. In other cases it might be feasible to ignore them, and many functions can deal with missing values by themselves."
  },
  {
    "objectID": "qmd/missing/missing.html#footnotes",
    "href": "qmd/missing/missing.html#footnotes",
    "title": "Missing values",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nImage by Pierre Bamin on Unsplash.↩︎"
  },
  {
    "objectID": "qmd/load_data/load_data_exercise.html",
    "href": "qmd/load_data/load_data_exercise.html",
    "title": "Loading data: Exercises",
    "section": "",
    "text": "Download the data set characters.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nRight-click on the respective data set found under this link, select ‘save as’ and then choose a folder on your notebook where to save it. We have talked about where that optimally should be in Workflow: Exercises.\n\n\n\n\nLoad it into R, and assign the name characters.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nIt is a .rds file.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ncharacters &lt;- readRDS(file = here::here(\"raw_data\", \"characters.rds\"))"
  },
  {
    "objectID": "qmd/load_data/load_data_exercise.html#exercise-1",
    "href": "qmd/load_data/load_data_exercise.html#exercise-1",
    "title": "Loading data: Exercises",
    "section": "",
    "text": "Download the data set characters.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nRight-click on the respective data set found under this link, select ‘save as’ and then choose a folder on your notebook where to save it. We have talked about where that optimally should be in Workflow: Exercises.\n\n\n\n\nLoad it into R, and assign the name characters.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nIt is a .rds file.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ncharacters &lt;- readRDS(file = here::here(\"raw_data\", \"characters.rds\"))"
  },
  {
    "objectID": "qmd/load_data/load_data_exercise.html#exercies-2",
    "href": "qmd/load_data/load_data_exercise.html#exercies-2",
    "title": "Loading data: Exercises",
    "section": "Exercies 2",
    "text": "Exercies 2\n\n\n\n\n\n\nAdvanced exercise\n\n\n\n\n\n\nDownload the psych_stats data set.\nLoad it into R and assign the name psych_stats. Did that work as expected? If not, why not?\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nTake a look at the .csv file by opening it in a text editor. Look at the documentation of read.csv() and take a look at the sep argument. Can you define another separator, so R can deduce, which elements need to be separated into different cells?\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nLet’s try the read.csv() function:\n\npsych_stats &lt;- read.csv(file = here::here(\"raw_data\", \"psych_stats.csv\"))\n\nhead(psych_stats)\n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 char_id.messy_neat.disorganized_self.disciplined.diligent_lazy.on.time_tardy.competitive_cooperative.scheduled_spontaneous.ADHD_OCD.chaotic_orderly.motivated_unmotivated.bossy_meek.persistent_quitter.overachiever_underachiever.muddy_washed.beautiful_ ...\n1 1;F2;95.7;95.2;6.09999999999999;6.2;6.40000000000001;6.59999999999999;92.9;92.2;7.8;7.90000000000001;7.90000000000001;8.2;91;9.2;90.8;9.5;90.3;9.90000000000001;90;10.6;89.3;89;11;88.9;11.7;11.9;88.1;87.8;12.2;87.4;12.8;12.9;13.6;13.7;13.7;86.3;85.9;14.6;14.7;14.8;85;15.1;84.7;84.7;15.5;84.3;15.8;15.9;83.8;16.2;16.6;16.7;83.3;16.7;17.3;82.7;82.6;17.7;17.8;82;18.1;18.3;81.4;18.6;81.1;18.9;18.9;80.7;19.3;80.6;19.6;19.6;19.6;80;79.7;20.4;20.5;79.2;79.2;79.2;78.8;21.3;21.7;21.7;78.2;78.2;21.9;78.1;77.9;22.1;22.2;22.2;77.8;77.7;22.3;22.4;22.7;22.8;77;76.8;76.7;76.6;23.4;76.6;23.6;76.3;76.3;23.7;23.8;23.8;23.9;76.1;24;24;75.7;24.4;75.6;24.4;24.6;75.4;24.7;75.3;24.8;24.8;75.1;25;74.6;25.5;74.5;25.5;74.4;25.8;74.1;74;26.1;26.1;73.8;26.2;73.8;73.7;26.4;26.4;26.6;73.3;27.3;72.5;72.5;72.3;72.3;27.8;28;28;28.1;28.2;71.7;71.6;28.7;71.3;28.8;28.8;28.8;71.1;29;29;70.9;29.1;70.8;70.8;29.3;29.4;29.6;70.4;30.9;70.3;29.8;29.9;70.1;29.9;29.9;69.6;30.5;30.7;69.2;69.2;69.2;69;31;31.1;68.8;31.2;68.8;31.3;68.7;31.4;31.9;67.9;67.8;32.3;32.4;32.6;67.4;32.7;67.3;67.3;32.8;67.1;33;33;66.9;66.7;66.6;33.4;66.3;66.3;33.8;34.2;34.5;34.5;65.4;34.6;65.3;65.3;65.1;35;35.2;35.3;35.3;35.4;64.6;35.5;35.6;35.8;35.9;36;36;36.1;36.1;36.2;36.2;36.5;63.4;36.6;36.7;63.2;63.1;63.1;62.9;62.8;37.4;37.5;62.5;37.6;37.6;38.4;38.4;39.2;39.4;39.5;39.6;39.6;39.6;39.8;60;40.1;59.8;40.5;59.4;59.3;40.7;59.2;59.1;40.9;59;58.9;41.1;58.8;41.2;58.7;41.5;41.6;58.4;58.3;58.3;42;42.1;42.1;57.9;57.3;57.2;57.2;57;57;43;56.9;56.6;56.4;43.6;56.3;56.2;44;44.1;44.3;55.6;44.5;44.6;44.6;55.3;44.9;45;45.1;45.6;45.6;54.2;54.2;45.9;54.1;53.8;53.7;53.7;46.3;53.5;46.6;53.3;53.3;53.2;53.1;46.9;53.1;53.1;53;53;52.8;47.2;52.8;47.3;52.7;52.4;47.7;47.7;52.3;47.8;47.8;52.2;52;48.1;48.1;51.8;48.2;48.2;51.6;51.6;48.5;51.3;48.7;51.2;51.2;51.2;48.8;51;49.1;49.7;50.4;49.5;50.5\n2                                                            2;F1;30.2;25.9;51.8;77.9;28.9;72.3;31.8;27;31.8;30.6;35.8;43.8;80.2;5.3;45.9;30.3;39.3;64.7;11.1;7.7;34.2;58.8;23.9;32.5;31.3;47.1;62.3;41.8;33.1;43.2;49.9;14.6;41.6;28.8;42.5;74.6;72.6;55.1;9.40000000000001;29.1;41.4;71.7;41.3;37.9;29.9;84.1;40.4;20.8;28;70;60.2;26.3;51.9;52.7;18.9;77.2;76.5;37.9;32.3;80.1;43.7;59.5;33.2;23.3;69.2;21.9;16.4;35.5;22.3;42.3;17.8;69.9;70.7;57.5;37.8;20.8;56.7;85.4;75.6;68.6;79.6;44.5;72.3;27.8;66.2;37.7;47.5;89.4;80.5;32.1;56.1;50.8;34.2;37.4;69.2;55.2;9;52.8;71;51;43.9;68.5;66.8;68.4;12.2;23.4;92;15.8;7.2;46.1;43.6;53.2;58.5;31.5;54.6;32.5;73.2;53.3;62.4;88;52.1;47.1;35;60.3;35;34;66.8;79.7;36.1;36.4;34.2;28.8;34;55.9;38.3;40.9;24.8;71.2;86.2;31.8;37.3;31.1;64.8;39.2;13.4;43.1;83.5;76;55.8;35.7;33.7;61.5;58.7;20.5;57.6;63.8;39.4;47.8;44.4;27.1;30.6;47.4;16.3;19.6;40.1;52.6;54.4;40.7;19.3;26.9;63.7;36.9;63.3;30.2;27;43.9;11.4;38;30.8;31.8;13.5;72.5;34.3;22.6;89.7;74.2;45.2;17.5;65.9;30.5;62.8;20.3;82.1;46.6;28.1;28.9;37.7;52.8;40.1;65.7;33;72;73.8;64.4;54.2;41.6;40.6;66.1;79.6;78.7;39.2;56.1;72.4;73.2;59;30.3;13.6;24.4;59.7;52;71.5;27.3;63.5;64;41.8;27.3;16.4;41.5;48.4;24;44.4;32.3;27;58.3;30.3;14.4;36.6;58.7;63.7;40;81;22.7;27.1;88.2;45.6;15.6;77.7;81.1;37.2;47.2;85.4;23.2;23.8;40.3;67.3;84.4;68.1;69.3;41.6;34.4;65.1;53.7;52;65.3;23.6;25.5;76.1;73.5;27.5;76.3;52.5;48.6;45.6;70.4;47.1;45.4;20.9;83.6;38.8;64.2;13.3;31.2;77.7;41.1;61.2;72.2;62.1;72.3;25.6;55;23.8;57.2;30.2;29.3;15.2;74.9;33;61.9;77.1;44.9;37.3;62.8;76.8;52.7;53.2;39.9;20;37.6;15.8;44.8;26.1;21.4;42.5;64.9;59.8;56.1;72;60.3;52.1;27.6;28.5;40.6;71;53.8;49;44.7;52.7;19.8;72.1;52.4;57.9;48.5;46;67.8;62;32.2;57.9;80.3;42.3;65.5;45.7;66;36.9;41.5;34.8;16.1;19.9;57.5;43.6;24.2;34.6;63.6;59.3;34.9;56.7;66.7;52.5;61.3;81;33.1;66.6;39.9;70.3;64.2\n3                                                          3;F5;45.3;42.4;52.2;57.1;42.8;54.9;26.7;38.2;52.3;64.8;43.9;55.8;58.7;26.2;53.4;49.8;46.7;53.2;28.2;45.6;28.8;66.4;58.3;47;52.6;37.1;52.3;45.9;61.1;44.3;67.1;31.9;73.7;20;56.8;67.2;49.8;55.9;28.5;22.6;56.6;56.5;46.5;54.6;34.7;65.4;66.3;18.3;49.9;63.5;46.3;42.7;47.4;73.5;48.4;48.2;66.6;73.9;20;82.2;38.1;41.5;20.7;43.9;30.7;34;41.5;66.6;24.6;44.9;39.1;58.3;55.5;56.7;62;25;28.8;67.2;73.7;79.9;52.8;40.9;54.4;24.7;47;66.9;41.8;68.5;64.7;56.1;39;73.8;30.6;59.7;42.9;70;22.4;54.9;43.4;35.3;43.5;45.8;46.6;72.1;20.1;76.3;35.5;29.7;54.5;53.3;61.4;46.9;66.3;36.2;62.6;27.2;68.9;36.6;53.3;68.7;41;74.1;72.2;58.6;25.6;63;58.7;48.7;50.2;38.7;26.3;48.2;32.3;54.7;52.8;33.1;52.3;42;73.4;17.3;44.6;51.8;73.1;71.2;38.6;39.8;33;72.8;56.2;45.9;35.9;57;55.1;45.3;59;46.7;70.4;51;15.4;53.2;41;44.7;22.9;22.8;48.8;35.1;47.5;45.9;38;38.9;18.9;38.5;74.2;63.1;40.7;68;63.9;61.8;46.1;40.7;44.6;38.7;55.5;67.7;57.2;58.2;33.4;25.7;74.1;29.3;65.4;23.5;69.2;48.1;62;35.4;39.7;39.1;63.9;42.7;61.5;29.8;61.1;66.8;47.6;43.5;60.3;66.6;66.7;60.3;51.3;53.2;13.3;67.5;33.8;52.7;43;46.6;51.3;26.7;59.3;67.2;53.7;51.9;35.5;59.9;22.4;32.3;68;38.9;36.7;48.4;43.3;61;47.2;44;47;42.1;61.7;42.1;61.9;53.4;51.5;64.9;50.7;44.7;67.2;53.5;51;42.5;62.4;37.9;31.5;51.1;35;33.3;36.7;45.5;61.5;26.1;52.4;47.8;30.7;59.5;36.9;70;67.9;63.2;56.8;53.6;65.7;54.8;55.7;48.3;55;53.2;29.8;27.6;47.6;45.9;66.4;71.3;44.8;40.8;57;53.6;37.9;46.1;61.1;48.5;44;37.4;9.40000000000001;50.3;48.5;26.9;53.1;56.7;58.1;42.3;42.8;63.1;47.4;48.6;60.6;51.8;38.9;38;27.8;44.6;46.8;63;73.4;66.4;21.8;53.5;57.5;54.1;70.2;52.8;37.2;48.5;45;48.3;34.2;35.4;43.2;64.4;40.4;54.2;44;24.9;58.6;61.1;83;41.8;37.1;37.7;45.3;50.6;62.5;65.6;39.5;33.2;71.8;44.9;60.5;61.2;25.4;44.7;17.8;66.5;44.1;72.2;89.3;39.9;42.2;79.5;50.3;45.8;40.2;72.4;55.5;53.9\n4                         4;F4;13;11;78.1;84.1;44.2;91.3;10.4;12.6;45.6;60.8;33.8;68.8;42.7;11;17.6;49.4;23.8;78;31.2;47.6;11;10.4;66.3;14.9;48.1;77.2;35.1;17.3;56.7;14;86.2;44.3;40.2;66.1;77.5;43.4;27.1;85.9;15.7;41.5;37.9;89.1;13.7;17;55.6;84.3;44.3;42.2;19.2;82;63.1;30.2;24.4;74.2;74.4;43.9;32.9;33.6;15.3;78.4;69;80;7.40000000000001;62;36.8;25.7;49.5;22;24.7;36.3;26.9;80.4;87.6;34.4;35;10.6;82.6;66.5;43.8;76.9;35.2;43.4;86.8;24.3;32.5;22.2;69.8;82.5;69.6;79.8;59.6;79.8;15.8;14.4;72.9;72.1;18.4;67.2;30.4;23.8;28.2;20.1;71.5;73.8;9.5;11.7;56.3;18;83.2;83.1;32.8;51.3;46.8;46.6;58;43.6;73.6;68.7;82.4;94.2;38;37;73.5;61.9;20.3;30.5;16.5;90.1;43.4;52.4;12.3;67.2;41;77.8;29.7;28.7;13.1;49;78.6;6.09999999999999;68.9;73.2;47;24;20.9;25.5;47.7;80.9;64.6;82.6;35.4;70.4;79;9.90000000000001;40;50.3;59.5;36.4;58;19.5;37.6;39.7;10.9;23.4;20.4;68.5;20.6;30.5;31.1;45.9;60.8;29.6;75.8;16.8;9.09999999999999;38.7;28.6;4.8;10.9;14.4;39.3;80.4;16;37.5;92.8;86.5;60.4;15.7;86.8;17.1;56.9;12.2;49.2;32.8;34.4;14.2;33.8;46.8;66.3;82;48.1;90.9;42.3;57.3;74.3;28.5;39.1;66;71.9;50.5;38.9;73.6;19;74.7;85;36.3;7.09999999999999;62;70.7;18.7;31.1;19.4;74.3;64.2;31.2;36.5;6.2;27.3;63.5;18.9;85.6;10.6;16.1;63.9;26.8;40.4;55.6;73.5;82.7;26.4;81.1;64.8;37.1;80.7;53.1;16.3;85.1;63.7;38.4;62.1;63.4;43.6;35.3;45.2;80.9;62.7;89.6;47.3;51;19.2;68.1;44.9;41.8;78.8;17;21.3;40.1;73.6;14.6;33.4;23.6;80.4;35;63.9;74.6;59.5;15.9;33.1;41.9;68.8;33;68.9;77.7;37.9;64.6;75.1;18.7;73.7;31.4;43;20;23.4;9;14.6;14.2;78.4;59.2;72;90;48.6;54.9;64.5;80.7;49.5;40.4;84.3;9.5;48.2;23.1;43.6;17;37.4;15.4;90.1;41.8;30.1;76.3;88.6;75.6;18.6;23.3;30.6;48.1;61.5;37.1;15;40.8;42;68.8;37.5;43.3;54.2;26.1;70.9;91.8;27;77;84.3;36.7;38.7;32.7;72.7;26.3;29.2;12.1;7.40000000000001;11.6;62.9;57;12.7;28.9;81.3;81.5;27.8;29.8;61.1;20;85.6;53.1;15;77.4;10.8;68.1;44.3\n5        5;F3;20.9;20.9;45.2;74;55.3;94.9;12.8;11.2;24.7;40.1;21.3;51.3;48.1;11.4;32;43.4;16.1;78.1;29.4;62.5;15.4;16.9;57.1;22.1;27.6;53.6;33.2;13.9;31.4;15.3;87.4;39.2;30.9;58;59.4;76.6;35.2;81;18.2;19.6;70.6;92.9;26;5.40000000000001;30;45.4;39.3;21.7;17.4;54.9;79.3;36.7;20.4;57.9;69.9;48.3;39.9;41.9;14.5;83.2;55.3;41.1;16.6;10.5;56.7;39.1;73.2;39.7;26.4;61.5;22.6;61.9;78.9;13.7;22.2;15.3;50.6;42.1;42.1;83.6;69.2;74.1;93;10.7;36.7;59.9;71.2;60.1;74.9;69;71.1;64.2;20.3;8;86.2;75.4;42.6;90;44.3;17.4;9.59999999999999;23.6;87.1;23.8;10.5;67.2;58.7;14.4;21.2;77;79.2;59.4;43.5;37.1;78.4;34.1;26.8;86.1;77.9;69.1;40.2;47.1;64;54.9;18.1;14.9;17.5;87.1;66;45.9;26.1;73.1;32.7;43.6;18.4;22.2;12.8;18.4;60.8;8.8;56.9;64;42.2;17.4;23.4;21.2;56.6;75.6;73.6;35.9;88.8;37.9;70.2;10.7;29;66.8;67.4;16.6;88.6;19.3;31.7;58.3;7.8;38.1;23.3;68.2;40.3;21.4;23.2;51.6;34.8;85.4;65.55;8.2;13.9;35.1;56.7;62.9;15.9;41.1;48.2;84.4;42.4;57;83.1;86.4;63;10.7;86.2;6.90000000000001;74.2;12.5;65.8;59.2;62.1;12.3;33.1;29.3;87.8;87.6;74.9;59.4;32.6;35.6;94.6;36.5;34.7;53.7;64.1;38.6;53.5;90.2;28.3;71.4;85.1;63.9;13.7;81.7;73.1;24.2;26.4;15.3;85;52.7;21.5;45.3;8.40000000000001;26.7;73.7;15.4;92.7;11.2;35.3;60.8;11.9;45.2;40.4;32.8;80.1;21.4;72.1;70.5;77.3;55.6;66.1;20;90.8;14.4;30.7;77.8;60.7;27.8;51.3;62.8;72.3;36.8;38.3;16.8;77.9;16.2;51.1;44.1;62.9;75.5;28.1;22.7;71.1;64.6;28.8;31.4;16.3;75.5;31.2;61.1;36.7;59.3;18.5;44.7;57.2;29.2;81.3;90.5;42.6;33.4;66.3;93.1;93.1;75.2;15.4;61;18.1;32.4;10.6;3.8;14.7;65.8;81.4;62.6;72.7;60.5;34.6;75.1;74.3;49.4;28.8;14.5;46.3;59.6;26.5;68.9;11;21.1;16.9;83.4;26.7;44.1;51.2;79.4;88.6;33.8;46.5;10.6;21.2;62.4;42.1;19.2;21.6;59.7;9.5;56.2;63.4;44;31.1;88.4;86.4;34.5;81.9;45.3;46.9;32.3;23.2;45.5;30.6;16;14.2;22.5;4.5;51.3;35.2;19.6;48.9;51.1;70.6;40.7;38.4;20.4;18.7;71.1;53.5;28;79.5;12.2;76;42\n6                                                      6;F6;81;75.6;20;20.6;24;13.2;70.1;68.8;31.5;44.6;31.6;23.2;64.6;53.9;81.5;22.7;85.4;25.4;35.9;20.5;76.7;88.9;28.5;87.7;41.8;37.8;80.8;83.7;48.8;82.5;36.7;44.3;69.5;11.9;44;84.2;71.9;22.1;55.1;47.5;52.4;20.9;81.2;82;31.1;77.9;60.9;49.6;83;35.5;39.5;36.6;76.4;68.4;24.4;78.5;77;78.2;40.3;47.8;60.4;48.6;74.2;58.6;29.2;25.8;14.4;71.6;47.4;60.8;37;23.2;57.1;88.8;61.7;39.5;19.3;84.3;69.3;81.9;60.6;18.4;27.4;33.1;68.2;68.5;29.2;78.1;67.2;33.7;31.9;28.2;71.4;84.8;16.5;41.6;18.8;23.1;56.1;62.2;74.3;84.9;54.3;80.2;38.2;94.1;41.3;27.4;53.8;34.1;27;37.2;65;45.4;36.6;42.8;39.3;16.8;31.5;56.5;38.1;81.7;19.9;52.2;33.1;84.5;77.6;30.8;28.9;22.6;50.2;23.6;38.8;53.8;42.8;47.3;72.8;52.4;70.5;75;29.4;29;75.7;83.6;20.3;74.9;58.4;43.8;50.5;37.1;19.3;66.3;39.1;62.5;74.8;52.9;66;78.2;13.6;63.5;43;73.4;30.6;26.7;61.4;27.3;78.5;62.8;43.2;26;19;26.7;68.65;66.4;72.4;73.6;74.1;38.1;69.2;43.2;55.8;47.3;61.3;88.2;40.2;25.9;23.7;48.2;63.6;38.9;61.5;61.2;77.8;29.7;70.2;80.9;78.2;50.4;31.5;21.3;65.6;10.6;84.2;77.5;16.6;47.9;75.4;66;44.4;55;68.9;25.6;75.4;54.3;35.4;28.2;63.5;17.6;52.7;48;70.8;63.7;65.6;69.8;21.6;69.2;59.8;48;55.8;51.9;20;70.7;45.9;42.4;59.4;47.9;67.6;39.7;29.7;38.2;40.9;32.2;57.5;17.8;51.9;65.6;29.9;47.8;36.7;26.5;60.2;22.4;14.9;58.6;49.5;32.1;6.5;46.1;81;70.1;24.8;44.3;22.1;35.5;59.9;62.9;65.8;70.2;77.5;71.3;81.5;34.2;47.2;51;44;60.1;37.9;19.3;68.1;51.8;77.3;71.5;63.2;47;42.6;22.2;45.2;44.8;62.3;57.8;57.2;58.5;52.9;74.5;46.3;54.1;31.9;56.7;58.8;36.2;50.2;67.9;63.9;47.6;80.3;43.5;71.4;62.6;21.5;37.8;90.7;71.7;71.8;53.3;24.4;58.3;47.8;41.1;49.2;64.3;65;72;65.4;38.4;41.6;65.6;66.2;52.2;45.8;51.5;23.4;33.8;54.2;35.8;39.6;52.8;36.1;18.8;34.6;70.5;59.1;54.8;51.9;69.8;79.1;61.3;92.6;48.4;23.2;55;40.4;38.1;38.5;74.2;60.3;48.9;47.3;75.3;72.7;46.6;19.1;75.9;44.1;57.4\n\n\nHuh, that looks weird. If we take a look at the file by opening it in a text editor, we can see that the values are seperated by ;. So let’s call the help for read.csv():\n\n?read.csv\n\nThe sep argument specifies that the seperator needs to be a white space (meaning tabs, spaces … - look at the details in the documentation).\nSo, we can do the following:\n\npsych_stats &lt;- read.csv(\n  file = here::here(\"raw_data\", \"psych_stats.csv\"),\n  sep = \";\"\n)\n\nhead(psych_stats)\n\n  char_id messy_neat disorganized_self.disciplined diligent_lazy on.time_tardy\n1      F2       95.7                          95.2           6.1           6.2\n2      F1       30.2                          25.9          51.8          77.9\n3      F5       45.3                          42.4          52.2          57.1\n4      F4       13.0                          11.0          78.1          84.1\n5      F3       20.9                          20.9          45.2          74.0\n6      F6       81.0                          75.6          20.0          20.6\n  competitive_cooperative scheduled_spontaneous ADHD_OCD chaotic_orderly\n1                     6.4                   6.6     92.9            92.2\n2                    28.9                  72.3     31.8            27.0\n3                    42.8                  54.9     26.7            38.2\n4                    44.2                  91.3     10.4            12.6\n5                    55.3                  94.9     12.8            11.2\n6                    24.0                  13.2     70.1            68.8\n  motivated_unmotivated bossy_meek persistent_quitter\n1                   7.8        7.9                7.9\n2                  31.8       30.6               35.8\n3                  52.3       64.8               43.9\n4                  45.6       60.8               33.8\n5                  24.7       40.1               21.3\n6                  31.5       44.6               31.6\n  overachiever_underachiever muddy_washed beautiful_ugly slacker_workaholic\n1                        8.2         91.0            9.2               90.8\n2                       43.8         80.2            5.3               45.9\n3                       55.8         58.7           26.2               53.4\n4                       68.8         42.7           11.0               17.6\n5                       51.3         48.1           11.4               32.0\n6                       23.2         64.6           53.9               81.5\n  driven_unambitious outlaw_sheriff precise_vague bad.cook_good.cook\n1                9.5           90.3           9.9               90.0\n2               30.3           39.3          64.7               11.1\n3               49.8           46.7          53.2               28.2\n4               49.4           23.8          78.0               31.2\n5               43.4           16.1          78.1               29.4\n6               22.7           85.4          25.4               35.9\n  manicured_scruffy lenient_strict relaxed_tense demanding_unchallenging\n1              10.6           89.3          89.0                    11.0\n2               7.7           34.2          58.8                    23.9\n3              45.6           28.8          66.4                    58.3\n4              47.6           11.0          10.4                    66.3\n5              62.5           15.4          16.9                    57.1\n6              20.5           76.7          88.9                    28.5\n  drop.out_valedictorian go.getter_slugabed competent_incompetent\n1                   88.9               11.7                  11.9\n2                   32.5               31.3                  47.1\n3                   47.0               52.6                  37.1\n4                   14.9               48.1                  77.2\n5                   22.1               27.6                  53.6\n6                   87.7               41.8                  37.8\n  aloof_obsessed flexible_rigid active_slothful loose_tight pointed_random\n1           88.1           87.8            12.2        87.4           12.8\n2           62.3           41.8            33.1        43.2           49.9\n3           52.3           45.9            61.1        44.3           67.1\n4           35.1           17.3            56.7        14.0           86.2\n5           33.2           13.9            31.4        15.3           87.4\n6           80.8           83.7            48.8        82.5           36.7\n  fresh_stinky dominant_submissive anxious_calm clean_perverted\n1         12.9                13.6         13.7            13.7\n2         14.6                41.6         28.8            42.5\n3         31.9                73.7         20.0            56.8\n4         44.3                40.2         66.1            77.5\n5         39.2                30.9         58.0            59.4\n6         44.3                69.5         11.9            44.0\n  neutral_opinionated always.down_picky hurried_leisurely attractive_repulsive\n1                86.3              85.9              14.6                 14.7\n2                74.6              72.6              55.1                  9.4\n3                67.2              49.8              55.9                 28.5\n4                43.4              27.1              85.9                 15.7\n5                76.6              35.2              81.0                 18.2\n6                84.2              71.9              22.1                 55.1\n  devoted_unfaithful helpless_resourceful deliberate_spontaneous\n1               14.8                 85.0                   15.1\n2               29.1                 41.4                   71.7\n3               22.6                 56.6                   56.5\n4               41.5                 37.9                   89.1\n5               19.6                 70.6                   92.9\n6               47.5                 52.4                   20.9\n  plays.hard_works.hard imaginative_practical frenzied_sleepy queer_straight\n1                  84.7                  84.7            15.5           84.3\n2                  41.3                  37.9            29.9           84.1\n3                  46.5                  54.6            34.7           65.4\n4                  13.7                  17.0            55.6           84.3\n5                  26.0                   5.4            30.0           45.4\n6                  81.2                  82.0            31.1           77.9\n  assertive_passive fast.talking_slow.talking astonishing_methodical\n1              15.8                      15.9                   83.8\n2              40.4                      20.8                   28.0\n3              66.3                      18.3                   49.9\n4              44.3                      42.2                   19.2\n5              39.3                      21.7                   17.4\n6              60.9                      49.6                   83.0\n  hoarder_unprepared consistent_variable involved_remote backdoor_official\n1               16.2                16.6            16.7              83.3\n2               70.0                60.2            26.3              51.9\n3               63.5                46.3            42.7              47.4\n4               82.0                63.1            30.2              24.4\n5               54.9                79.3            36.7              20.4\n6               35.5                39.5            36.6              76.4\n  captain_first.mate refined_rugged accommodating_stubborn barbaric_civilized\n1               16.7           17.3                   82.7               82.6\n2               52.7           18.9                   77.2               76.5\n3               73.5           48.4                   48.2               66.6\n4               74.2           74.4                   43.9               32.9\n5               57.9           69.9                   48.3               39.9\n6               68.4           24.4                   78.5               77.0\n  alpha_beta loyal_traitorous trash_treasure fast_slow perceptive_unobservant\n1       17.7             17.8           82.0      18.1                   18.3\n2       37.9             32.3           80.1      43.7                   59.5\n3       73.9             20.0           82.2      38.1                   41.5\n4       33.6             15.3           78.4      69.0                   80.0\n5       41.9             14.5           83.2      55.3                   41.1\n6       78.2             40.3           47.8      60.4                   48.6\n  goof.off_studious feminist_sexist desperate_high.standards impatient_patient\n1              81.4            18.6                     81.1              18.9\n2              33.2            23.3                     69.2              21.9\n3              20.7            43.9                     30.7              34.0\n4               7.4            62.0                     36.8              25.7\n5              16.6            10.5                     56.7              39.1\n6              74.2            58.6                     29.2              25.8\n  preppy_punk.rock naive_paranoid important_irrelevant apprentice_master\n1             18.9           80.7                 19.3              80.6\n2             16.4           35.5                 22.3              42.3\n3             41.5           66.6                 24.6              44.9\n4             49.5           22.0                 24.7              36.3\n5             73.2           39.7                 26.4              61.5\n6             14.4           71.6                 47.4              60.8\n  healthy_sickly morning.lark_night.owl alert_oblivious\n1           19.6                   19.6            19.6\n2           17.8                   69.9            70.7\n3           39.1                   58.3            55.5\n4           26.9                   80.4            87.6\n5           22.6                   61.9            78.9\n6           37.0                   23.2            57.1\n  f....the.police_tattle.tale experimental_reliable loud_quiet high.IQ_low.IQ\n1                        80.0                  79.7       20.4           20.5\n2                        57.5                  37.8       20.8           56.7\n3                        56.7                  62.0       25.0           28.8\n4                        34.4                  35.0       10.6           82.6\n5                        13.7                  22.2       15.3           50.6\n6                        88.8                  61.7       39.5           19.3\n  oppressed_privileged animalistic_human still_twitchy thick_thin\n1                 79.2              79.2          79.2       78.8\n2                 85.4              75.6          68.6       79.6\n3                 67.2              73.7          79.9       52.8\n4                 66.5              43.8          76.9       35.2\n5                 42.1              42.1          83.6       69.2\n6                 84.3              69.3          81.9       60.6\n  repetitive_varied rational_whimsical egalitarian_racist\n1              21.3               21.7               21.7\n2              44.5               72.3               27.8\n3              40.9               54.4               24.7\n4              43.4               86.8               24.3\n5              74.1               93.0               10.7\n6              18.4               27.4               33.1\n  disreputable_prestigious ignorant_knowledgeable hard.work_natural.talent\n1                     78.2                   78.2                     21.9\n2                     66.2                   37.7                     47.5\n3                     47.0                   66.9                     41.8\n4                     32.5                   22.2                     69.8\n5                     36.7                   59.9                     71.2\n6                     68.2                   68.5                     29.2\n  androgynous_gendered dispassionate_romantic eloquent_unpolished\n1                 78.1                   77.9                22.1\n2                 89.4                   80.5                32.1\n3                 68.5                   64.7                56.1\n4                 82.5                   69.6                79.8\n5                 60.1                   74.9                69.0\n6                 78.1                   67.2                33.7\n  permanent_transient intense_lighthearted mischievous_well.behaved\n1                22.2                 22.2                     77.8\n2                56.1                 50.8                     34.2\n3                39.0                 73.8                     30.6\n4                59.6                 79.8                     15.8\n5                71.1                 64.2                     20.3\n6                31.9                 28.2                     71.4\n  adventurous_stick.in.the.mud obedient_rebellious authoritarian_democratic\n1                         77.7                22.3                     22.4\n2                         37.4                69.2                     55.2\n3                         59.7                42.9                     70.0\n4                         14.4                72.9                     72.1\n5                          8.0                86.2                     75.4\n6                         84.8                16.5                     41.6\n  city.slicker_country.bumpkin traditional_unorthodox lewd_tasteful\n1                         22.7                   22.8          77.0\n2                          9.0                   52.8          71.0\n3                         22.4                   54.9          43.4\n4                         18.4                   67.2          30.4\n5                         42.6                   90.0          44.3\n6                         18.8                   23.1          56.1\n  folksy_presidential abstract_concrete chill_offended builder_explorer\n1                76.8              76.7           76.6             23.4\n2                51.0              43.9           68.5             66.8\n3                35.3              43.5           45.8             46.6\n4                23.8              28.2           20.1             71.5\n5                17.4               9.6           23.6             87.1\n6                62.2              74.3           84.9             54.3\n  mysterious_unambiguous chatty_reserved jock_nerd slovenly_stylish\n1                   76.6            23.6      76.3             76.3\n2                   68.4            12.2      23.4             92.0\n3                   72.1            20.1      76.3             35.5\n4                   73.8             9.5      11.7             56.3\n5                   23.8            10.5      67.2             58.7\n6                   80.2            38.2      94.1             41.3\n  flower.child_goth feminine_masculine businesslike_chivalrous\n1              23.7               23.8                    23.8\n2              15.8                7.2                    46.1\n3              29.7               54.5                    53.3\n4              18.0               83.2                    83.1\n5              14.4               21.2                    77.0\n6              27.4               53.8                    34.1\n  literal_metaphorical noob_pro direct_roundabout legit_scrub\n1                 23.9     76.1              24.0        24.0\n2                 43.6     53.2              58.5        31.5\n3                 61.4     46.9              66.3        36.2\n4                 32.8     51.3              46.8        46.6\n5                 79.2     59.4              43.5        37.1\n6                 27.0     37.2              65.0        45.4\n  jealous_opinionated believable_poorly.written philosophical_real\n1                75.7                      24.4               75.6\n2                54.6                      32.5               73.2\n3                62.6                      27.2               68.9\n4                58.0                      43.6               73.6\n5                78.4                      34.1               26.8\n6                36.6                      42.8               39.3\n  factual_poetic proper_scandalous asexual_sexual domestic_industrial\n1           24.4              24.6           75.4                24.7\n2           53.3              62.4           88.0                52.1\n3           36.6              53.3           68.7                41.0\n4           68.7              82.4           94.2                38.0\n5           86.1              77.9           69.1                40.2\n6           16.8              31.5           56.5                38.1\n  bad.boy_white.knight triggered_trolling resolute_wavering clumsy_coordinated\n1                 75.3               24.8              24.8               75.1\n2                 47.1               35.0              60.3               35.0\n3                 74.1               72.2              58.6               25.6\n4                 37.0               73.5              61.9               20.3\n5                 47.1               64.0              54.9               18.1\n6                 81.7               19.9              52.2               33.1\n  badass_weakass accepting_judgemental cautious_impulsive princess_queen\n1           25.0                  74.6               25.5           74.5\n2           34.0                  66.8               79.7           36.1\n3           63.0                  58.7               48.7           50.2\n4           30.5                  16.5               90.1           43.4\n5           14.9                  17.5               87.1           66.0\n6           84.5                  77.6               30.8           28.9\n  hypochondriac_stoic juvenile_mature pretentious_unassuming flimsy_sturdy\n1                25.5            74.4                   25.8          74.1\n2                36.4            34.2                   28.8          34.0\n3                38.7            26.3                   48.2          32.3\n4                52.4            12.3                   67.2          41.0\n5                45.9            26.1                   73.1          32.7\n6                22.6            50.2                   23.6          38.8\n  cryptic_straightforward extreme_moderate nurturing_poisonous\n1                    74.0             26.1                26.1\n2                    55.9             38.3                40.9\n3                    54.7             52.8                33.1\n4                    77.8             29.7                28.7\n5                    43.6             18.4                22.2\n6                    53.8             42.8                47.3\n  instinctual_reasoned giving_receiving rural_urban playful_serious\n1                 73.8             26.2        73.8            73.7\n2                 24.8             71.2        86.2            31.8\n3                 52.3             42.0        73.4            17.3\n4                 13.1             49.0        78.6             6.1\n5                 12.8             18.4        60.8             8.8\n6                 72.8             52.4        70.5            75.0\n  cultured_rustic highbrow_lowbrow decisive_hesitant brave_careful\n1            26.4             26.4              26.6          73.3\n2            37.3             31.1              64.8          39.2\n3            44.6             51.8              73.1          71.2\n4            68.9             73.2              47.0          24.0\n5            56.9             64.0              42.2          17.4\n6            29.4             29.0              75.7          83.6\n  emotional_unemotional edgy_politically.correct gamer_non.gamer\n1                  27.3                     72.5            72.5\n2                  13.4                     43.1            83.5\n3                  38.6                     39.8            33.0\n4                  20.9                     25.5            47.7\n5                  23.4                     21.2            56.6\n6                  20.3                     74.9            58.4\n  antagonist_protagonist bored_interested complicated_simple basic_hipster\n1                   72.3             72.3               27.8          28.0\n2                   76.0             55.8               35.7          33.7\n3                   72.8             56.2               45.9          35.9\n4                   80.9             64.6               82.6          35.4\n5                   75.6             73.6               35.9          88.8\n6                   43.8             50.5               37.1          19.3\n  enlightened_lost focused.on.the.future_focused.on.the.present bold_shy\n1             28.0                                         28.1     28.2\n2             61.5                                         58.7     20.5\n3             57.0                                         55.1     45.3\n4             70.4                                         79.0      9.9\n5             37.9                                         70.2     10.7\n6             66.3                                         39.1     62.5\n  anarchist_statist resigned_resistant ferocious_pacifist avant.garde_classical\n1              71.7               71.6               28.7                  71.3\n2              57.6               63.8               39.4                  47.8\n3              59.0               46.7               70.4                  51.0\n4              40.0               50.3               59.5                  36.4\n5              29.0               66.8               67.4                  16.6\n6              74.8               52.9               66.0                  78.2\n  skeptical_spiritual bright_depressed feisty_gracious generalist_specialist\n1                28.8             28.8            28.8                  71.1\n2                44.4             27.1            30.6                  47.4\n3                15.4             53.2            41.0                  44.7\n4                58.0             19.5            37.6                  39.7\n5                88.6             19.3            31.7                  58.3\n6                13.6             63.5            43.0                  73.4\n  expressive_stoic English_German ludicrous_sensible claustrophobic_spelunker\n1             29.0           29.0               70.9                     29.1\n2             16.3           19.6               40.1                     52.6\n3             22.9           22.8               48.8                     35.1\n4             10.9           23.4               20.4                     68.5\n5              7.8           38.1               23.3                     68.2\n6             30.6           26.7               61.4                     27.3\n  child.free_pronatalist circular_linear French_Russian biased_impartial\n1                   70.8            70.8           29.3             29.4\n2                   54.4            40.7           19.3             26.9\n3                   47.5            45.9           38.0             38.9\n4                   20.6            30.5           31.1             45.9\n5                   40.3            21.4           23.2             51.6\n6                   78.5            62.8           43.2             26.0\n  boy_girl.next.door_celebrity codependent_independent hard_soft\n1                         29.6                    70.4     30.90\n2                         63.7                    36.9     63.30\n3                         18.9                    38.5     74.20\n4                         60.8                    29.6     75.80\n5                         34.8                    85.4     65.55\n6                         19.0                    26.7     68.65\n  fantastical_realistic cheery_sorrowful mighty_puny overspender_penny.pincher\n1                  70.3             29.8        29.9                      70.1\n2                  30.2             27.0        43.9                      11.4\n3                  63.1             40.7        68.0                      63.9\n4                  16.8              9.1        38.7                      28.6\n5                   8.2             13.9        35.1                      56.7\n6                  66.4             72.4        73.6                      74.1\n  Italian_Swedish happy_sad foolish_wise main.character_side.character\n1            29.9      29.9         69.6                          30.5\n2            38.0      30.8         31.8                          13.5\n3            61.8      46.1         40.7                          44.6\n4             4.8      10.9         14.4                          39.3\n5            62.9      15.9         41.1                          48.2\n6            38.1      69.2         43.2                          55.8\n  down2earth_head.clouds dunce_genius cool_dorky reclusive_social gloomy_sunny\n1                   30.7         69.2       69.2             69.2         69.0\n2                   72.5         34.3       22.6             89.7         74.2\n3                   38.7         55.5       67.7             57.2         58.2\n4                   80.4         16.0       37.5             92.8         86.5\n5                   84.4         42.4       57.0             83.1         86.4\n6                   47.3         61.3       88.2             40.2         25.9\n  pensive_serene expressive_monotone cruel_kind soulful_soulless rap_rock\n1           31.0                31.1       68.8             31.2     68.8\n2           45.2                17.5       65.9             30.5     62.8\n3           33.4                25.7       74.1             29.3     65.4\n4           60.4                15.7       86.8             17.1     56.9\n5           63.0                10.7       86.2              6.9     74.2\n6           23.7                48.2       63.6             38.9     61.5\n  charismatic_uninspiring blacksmith_tailor patriotic_unpatriotic fire_water\n1                    31.3              68.7                  31.4       31.9\n2                    20.3              82.1                  46.6       28.1\n3                    23.5              69.2                  48.1       62.0\n4                    12.2              49.2                  32.8       34.4\n5                    12.5              65.8                  59.2       62.1\n6                    61.2              77.8                  29.7       70.2\n  bold_serious efficient_overprepared frank_sugarcoated predictable_quirky\n1         67.9                   67.8              32.3               32.4\n2         28.9                   37.7              52.8               40.1\n3         35.4                   39.7              39.1               63.9\n4         14.2                   33.8              46.8               66.3\n5         12.3                   33.1              29.3               87.8\n6         80.9                   78.2              50.4               31.5\n  tame_wild plastic_wooden intellectual_physical compersive_jealous\n1      32.6           67.4                  32.7               67.3\n2      65.7           33.0                  72.0               73.8\n3      42.7           61.5                  29.8               61.1\n4      82.0           48.1                  90.9               42.3\n5      87.6           74.9                  59.4               32.6\n6      21.3           65.6                  10.6               84.2\n  musical_off.key conventional_creative indiscreet_tactful rhythmic_stuttering\n1            67.3                  32.8               67.1                33.0\n2            64.4                  54.2               41.6                40.6\n3            66.8                  47.6               43.5                60.3\n4            57.3                  74.3               28.5                39.1\n5            35.6                  94.6               36.5                34.7\n6            77.5                  16.6               47.9                75.4\n  proactive_reactive creepy_disarming autistic_neurotypical air_earth\n1               33.0             66.9                  66.7      66.6\n2               66.1             79.6                  78.7      39.2\n3               66.6             66.7                  60.3      51.3\n4               66.0             71.9                  50.5      38.9\n5               53.7             64.1                  38.6      53.5\n6               66.0             44.4                  55.0      68.9\n  close.minded_open.minded comedic_dramatic genocidal_not.genocidal\n1                     33.4             66.3                    66.3\n2                     56.1             72.4                    73.2\n3                     53.2             13.3                    67.5\n4                     73.6             19.0                    74.7\n5                     90.2             28.3                    71.4\n6                     25.6             75.4                    54.3\n  guarded_open arrogant_humble extrovert_introvert sheltered_street.smart\n1         33.8            34.2                34.5                   34.5\n2         59.0            30.3                13.6                   24.4\n3         33.8            52.7                43.0                   46.6\n4         85.0            36.3                 7.1                   62.0\n5         85.1            63.9                13.7                   81.7\n6         35.4            28.2                63.5                   17.6\n  envious_prideful one.faced_two.faced poor_rich idealist_realist\n1             65.4                34.6      65.3             65.3\n2             59.7                52.0      71.5             27.3\n3             51.3                26.7      59.3             67.2\n4             70.7                18.7      31.1             19.4\n5             73.1                24.2      26.4             15.3\n6             52.7                48.0      70.8             63.7\n  apathetic_curious armoured_vulnerable love.focused_money.focused\n1              65.1                35.0                       35.2\n2              63.5                64.0                       41.8\n3              53.7                51.9                       35.5\n4              74.3                64.2                       31.2\n5              85.0                52.7                       21.5\n6              65.6                69.8                       21.6\n  fortunate_unlucky playful_shy heroic_villainous salacious_wholesome\n1              35.3        35.3              35.4                64.6\n2              27.3        16.4              41.5                48.4\n3              59.9        22.4              32.3                68.0\n4              36.5         6.2              27.3                63.5\n5              45.3         8.4              26.7                73.7\n6              69.2        59.8              48.0                55.8\n  exuberant_subdued corporate_freelance joyful_miserable cocky_timid\n1              35.5                35.6             35.8        35.9\n2              24.0                44.4             32.3        27.0\n3              38.9                36.7             48.4        43.3\n4              18.9                85.6             10.6        16.1\n5              15.4                92.7             11.2        35.3\n6              51.9                20.0             70.7        45.9\n  devout_heathen emancipated_enslaved cosmopolitan_provincial\n1           36.0                 36.0                    36.1\n2           58.3                 30.3                    14.4\n3           61.0                 47.2                    44.0\n4           63.9                 26.8                    40.4\n5           60.8                 11.9                    45.2\n6           42.4                 59.4                    47.9\n  chosen.one_everyman introspective_not.introspective formal_intimate\n1                36.1                            36.2            36.2\n2                36.6                            58.7            63.7\n3                47.0                            42.1            61.7\n4                55.6                            73.5            82.7\n5                40.4                            32.8            80.1\n6                67.6                            39.7            29.7\n  crazy_sane old_young bourgeoisie_proletariat insider_outsider\n1       36.5      63.4                    36.6             36.7\n2       40.0      81.0                    22.7             27.1\n3       42.1      61.9                    53.4             51.5\n4       26.4      81.1                    64.8             37.1\n5       21.4      72.1                    70.5             77.3\n6       38.2      40.9                    32.2             57.5\n  historical_modern debased_pure summer_winter geriatric_vibrant\n1              63.2         63.1          63.1              62.9\n2              88.2         45.6          15.6              77.7\n3              64.9         50.7          44.7              67.2\n4              80.7         53.1          16.3              85.1\n5              55.6         66.1          20.0              90.8\n6              17.8         51.9          65.6              29.9\n  arcane_mainstream existentialist_nihilist average_deviant\n1              62.8                    37.4            37.5\n2              81.1                    37.2            47.2\n3              53.5                    51.0            42.5\n4              63.7                    38.4            62.1\n5              14.4                    30.7            77.8\n6              47.8                    36.7            26.5\n  confidential_gossiping moody_stable sensitive_thick.skinned\n1                   62.5         37.6                    37.6\n2                   85.4         23.2                    23.8\n3                   62.4         37.9                    31.5\n4                   63.4         43.6                    35.3\n5                   60.7         27.8                    51.3\n6                   60.2         22.4                    14.9\n  empirical_theoretical cynical_gullible frugal_lavish bookish_sporty\n1                  38.4             38.4          39.2           39.4\n2                  40.3             67.3          84.4           68.1\n3                  51.1             35.0          33.3           36.7\n4                  45.2             80.9          62.7           89.6\n5                  62.8             72.3          36.8           38.3\n6                  58.6             49.5          32.1            6.5\n  freak_normie short_tall loveable_punchable analysis_common.sense\n1         39.5       39.6               39.6                  39.6\n2         69.3       41.6               34.4                  65.1\n3         45.5       61.5               26.1                  52.4\n4         47.3       51.0               19.2                  68.1\n5         16.8       77.9               16.2                  51.1\n6         46.1       81.0               70.1                  24.8\n  respectful_rude self.destructive_self.improving dry_moist indulgent_sober\n1            39.8                            60.0      40.1            59.8\n2            53.7                            52.0      65.3            23.6\n3            47.8                            30.7      59.5            36.9\n4            44.9                            41.8      78.8            17.0\n5            44.1                            62.9      75.5            28.1\n6            44.3                            22.1      35.5            59.9\n  ambitious_realistic macho_metrosexual attentive_interrupting doer_thinker\n1                40.5              59.4                   59.3         40.7\n2                25.5              76.1                   73.5         27.5\n3                70.0              67.9                   63.2         56.8\n4                21.3              40.1                   73.6         14.6\n5                22.7              71.1                   64.6         28.8\n6                62.9              65.8                   70.2         77.5\n  blue.collar_ivory.tower kinky_vanilla quarrelsome_warm deranged_reasonable\n1                    59.2          59.1             40.9                59.0\n2                    76.3          52.5             48.6                45.6\n3                    53.6          65.7             54.8                55.7\n4                    33.4          23.6             80.4                35.0\n5                    31.4          16.3             75.5                31.2\n6                    71.3          81.5             34.2                47.2\n  minimalist_pack.rat contrarian_yes.man cunning_honorable exaggerating_factual\n1                58.9               41.1              58.8                 41.2\n2                70.4               47.1              45.4                 20.9\n3                48.3               55.0              53.2                 29.8\n4                63.9               74.6              59.5                 15.9\n5                61.1               36.7              59.3                 18.5\n6                51.0               44.0              60.1                 37.9\n  cheesy_chic Coke_Pepsi deep_shallow trendy_vintage normal_weird demure_vain\n1        58.7       41.5         41.6           58.4         58.3        58.3\n2        83.6       38.8         64.2           13.3         31.2        77.7\n3        27.6       47.6         45.9           66.4         71.3        44.8\n4        33.1       41.9         68.8           33.0         68.9        77.7\n5        44.7       57.2         29.2           81.3         90.5        42.6\n6        19.3       68.1         51.8           77.3         71.5        63.2\n  angelic_demonic objective_subjective monochrome_multicolored cannibal_vegan\n1            42.0                 42.1                    42.1           57.9\n2            41.1                 61.2                    72.2           62.1\n3            40.8                 57.0                    53.6           37.9\n4            37.9                 64.6                    75.1           18.7\n5            33.4                 66.3                    93.1           93.1\n6            47.0                 42.6                    22.2           45.2\n  bashful_exhibitionist literary_mathematical communal_individualist\n1                  57.3                  57.2                   57.2\n2                  72.3                  25.6                   55.0\n3                  46.1                  61.1                   48.5\n4                  73.7                  31.4                   43.0\n5                  75.2                  15.4                   61.0\n6                  44.8                  62.3                   57.8\n  flamboyant_modest forgiving_vengeful funny_humorless\n1              57.0               57.0            43.0\n2              23.8               57.2            30.2\n3              44.0               37.4             9.4\n4              20.0               23.4             9.0\n5              18.1               32.4            10.6\n6              57.2               58.5            52.9\n  open.to.new.experinces_uncreative emotional_logical\n1                              56.9              56.6\n2                              29.3              15.2\n3                              50.3              48.5\n4                              14.6              14.2\n5                               3.8              14.7\n6                              74.5              46.3\n  low.self.esteem_narcissistic entitled_grateful machiavellian_transparent\n1                         56.4              43.6                      56.3\n2                         74.9              33.0                      61.9\n3                         26.9              53.1                      56.7\n4                         78.4              59.2                      72.0\n5                         65.8              81.4                      62.6\n6                         54.1              31.9                      56.7\n  chaste_lustful libertarian_socialist Greek_Roman concise_long.winded\n1           56.2                  44.0        44.1                44.3\n2           77.1                  44.9        37.3                62.8\n3           58.1                  42.3        42.8                63.1\n4           90.0                  48.6        54.9                64.5\n5           72.7                  60.5        34.6                75.1\n6           58.8                  36.2        50.2                67.9\n  distant_touchy.feely eastern_western forward.thinking_stuck.in.the.past\n1                 55.6            44.5                               44.6\n2                 76.8            52.7                               53.2\n3                 47.4            48.6                               60.6\n4                 80.7            49.5                               40.4\n5                 74.3            49.4                               28.8\n6                 63.9            47.6                               80.3\n  cat.person_dog.person nonpolitical_political fixable_unfixable\n1                  44.6                   55.3              44.9\n2                  39.9                   20.0              37.6\n3                  51.8                   38.9              38.0\n4                  84.3                    9.5              48.2\n5                  14.5                   46.3              59.6\n6                  43.5                   71.4              62.6\n  dramatic_no.nonsense centrist_radical crafty_scholarly decorative_utilitarian\n1                 45.0             45.1             45.6                   45.6\n2                 15.8             44.8             26.1                   21.4\n3                 27.8             44.6             46.8                   63.0\n4                 23.1             43.6             17.0                   37.4\n5                 26.5             68.9             11.0                   21.1\n6                 21.5             37.8             90.7                   71.7\n  self.assured_self.conscious cold_warm awkward_suspicious melee_ranged\n1                        54.2      54.2               45.9         54.1\n2                        42.5      64.9               59.8         56.1\n3                        73.4      66.4               21.8         53.5\n4                        15.4      90.1               41.8         30.1\n5                        16.9      83.4               26.7         44.1\n6                        71.8      53.3               24.4         58.3\n  rough_smooth bitter_sweet regular_zany blissful_haunted charming_trusting\n1         53.8         53.7         53.7             46.3              53.5\n2         72.0         60.3         52.1             27.6              28.5\n3         57.5         54.1         70.2             52.8              37.2\n4         76.3         88.6         75.6             18.6              23.3\n5         51.2         79.4         88.6             33.8              46.5\n6         47.8         41.1         49.2             64.3              65.0\n  extraordinary_mundane altruistic_selfish fearmongering_reassuring\n1                  46.6               53.3                     53.3\n2                  40.6               71.0                     53.8\n3                  48.5               45.0                     48.3\n4                  30.6               48.1                     61.5\n5                  10.6               21.2                     62.4\n6                  72.0               65.4                     38.4\n  oxymoron_tautology glad_mad generous_stingy extravagant_thrifty indie_pop\n1               53.2     53.1            46.9                53.1      53.1\n2               49.0     44.7            52.7                19.8      72.1\n3               34.2     35.4            43.2                64.4      40.4\n4               37.1     15.0            40.8                42.0      68.8\n5               42.1     19.2            21.6                59.7       9.5\n6               41.6     65.6            66.2                52.2      45.8\n  innocent_worldly cringeworthy_inspiring atheist_theist\n1             53.0                   53.0           52.8\n2             52.4                   57.9           48.5\n3             54.2                   44.0           24.9\n4             37.5                   43.3           54.2\n5             56.2                   63.4           44.0\n6             51.5                   23.4           33.8\n  complimentary_insulting conservative_liberal angry_good.humored\n1                    47.2                 52.8               47.3\n2                    46.0                 67.8               62.0\n3                    58.6                 61.1               83.0\n4                    26.1                 70.9               91.8\n5                    31.1                 88.4               86.4\n6                    54.2                 35.8               39.6\n  hedonist_monastic high.tech_low.tech awkward_charming orange_purple\n1              52.7               52.4             47.7          47.7\n2              32.2               57.9             80.3          42.3\n3              41.8               37.1             37.7          45.3\n4              27.0               77.0             84.3          36.7\n5              34.5               81.9             45.3          46.9\n6              52.8               36.1             18.8          34.6\n  equitable_hypocritical luddite_technophile sage_whippersnapper\n1                   52.3                47.8                47.8\n2                   65.5                45.7                66.0\n3                   50.6                62.5                65.6\n4                   38.7                32.7                72.7\n5                   32.3                23.2                45.5\n6                   70.5                59.1                54.8\n  empath_psychopath interesting_tiresome confident_insecure flirtatious_prudish\n1              52.2                 52.0               48.1                48.1\n2              36.9                 41.5               34.8                16.1\n3              39.5                 33.2               71.8                44.9\n4              26.3                 29.2               12.1                 7.4\n5              30.6                 16.0               14.2                22.5\n6              51.9                 69.8               79.1                61.3\n  artistic_scientific masochistic_pain.avoidant gatherer_hunter\n1                51.8                      48.2            48.2\n2                19.9                      57.5            43.6\n3                60.5                      61.2            25.4\n4                11.6                      62.9            57.0\n5                 4.5                      51.3            35.2\n6                92.6                      48.4            23.2\n  gregarious_private ironic_profound deep_epic suspicious_trusting\n1               51.6            51.6      48.5                51.3\n2               24.2            34.6      63.6                59.3\n3               44.7            17.8      66.5                44.1\n4               12.7            28.9      81.3                81.5\n5               19.6            48.9      51.1                70.6\n6               55.0            40.4      38.1                38.5\n  flourishing_traumatized genuine_sarcastic conspiracist_sheeple\n1                    48.7              51.2                 51.2\n2                    34.9              56.7                 66.7\n3                    72.2              89.3                 39.9\n4                    27.8              29.8                 61.1\n5                    40.7              38.4                 20.4\n6                    74.2              60.3                 48.9\n  family.first_work.first fighter_lover never.cries_often.crying\n1                    51.2          48.8                     51.0\n2                    52.5          61.3                     81.0\n3                    42.2          79.5                     50.3\n4                    20.0          85.6                     53.1\n5                    18.7          71.1                     53.5\n6                    47.3          75.3                     72.7\n  open.book_secretive mild_spicy optimistic_pessimistic chortling_giggling\n1                49.1       49.7                   50.4               49.5\n2                33.1       66.6                   39.9               70.3\n3                45.8       40.2                   72.4               55.5\n4                15.0       77.4                   10.8               68.1\n5                28.0       79.5                   12.2               76.0\n6                46.6       19.1                   75.9               44.1\n  innocent_jaded\n1           50.5\n2           64.2\n3           53.9\n4           44.3\n5           42.0\n6           57.4\n\n\nThis looks better!"
  },
  {
    "objectID": "qmd/functions/functions_exercise.html",
    "href": "qmd/functions/functions_exercise.html",
    "title": "Functions: Exercises",
    "section": "",
    "text": "Take a look at the following function:\n\nfun_1 &lt;- function(x, y){ \n res &lt;- round(x/y^2, digits = 2)\n print(paste0(\"This returns:\", res))\n}\n\n\nWhat does it do?\n\n\nIt calculates the rounded quotient of x and y^2 and prints the result with some text.\nIt calculates the rounded quotient of x and y^2 but doesn’t do anything with it.\nIt calculates the rounded quotient of x and y^2, prints this result with some text and returns only the result without any text.\nIt only returns the rounded quotient of x and y^2 without any text.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nLet’s take a look:\n\nout_fun_1 &lt;- fun_1(86, 1.87)\n\n[1] \"This returns:24.59\"\n\nout_fun_1\n\n[1] \"This returns:24.59\"\n\n\nHmm, so option one seems to be correct:\n\nIt calculates the rounded quotient of x and y^2 and prints the result with some text.\nIt calculates the rounded quotient of x and y^2 but doesn’t do anything with it.\nIt calculates the rounded quotient of x and y^2, prints this result with some text and returns only the result without any text.\nIt only returns the rounded quotient of x and y^2 without any text.\n\nActually, this function calculates the Body Mass Index (BMI): \\(\\frac{weight(kg)}{height(m)^2}\\). However, it doesn’t return a numeric value, but just prints the result of the calculation along with some text.\n\n\n\n\nImprove it, so it becomes clearer what it does, and it returns something more meaningful.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nAssign a more informative name and more informative argument names. Use return() to make clear what the function returns. Print a more informative statement.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ncalc_bmi &lt;- function(kg, meter){ \n \n  res &lt;- round(kg/meter^2, digits = 2)\n \n  print(paste0(\"Your BMI is: \", res))\n \n  return(res)\n}\n\nmy_bmi &lt;- calc_bmi(86, 1.87)\n\n[1] \"Your BMI is: 24.59\"\n\nmy_bmi\n\n[1] 24.59\n\n\nHere we gave the function and its arguments some more informative names and used the return() function to clearly return the result of the calculation, and we can save it in an object. Also, we wrote a more informative printed statement."
  },
  {
    "objectID": "qmd/functions/functions_exercise.html#exerise-1",
    "href": "qmd/functions/functions_exercise.html#exerise-1",
    "title": "Functions: Exercises",
    "section": "",
    "text": "Take a look at the following function:\n\nfun_1 &lt;- function(x, y){ \n res &lt;- round(x/y^2, digits = 2)\n print(paste0(\"This returns:\", res))\n}\n\n\nWhat does it do?\n\n\nIt calculates the rounded quotient of x and y^2 and prints the result with some text.\nIt calculates the rounded quotient of x and y^2 but doesn’t do anything with it.\nIt calculates the rounded quotient of x and y^2, prints this result with some text and returns only the result without any text.\nIt only returns the rounded quotient of x and y^2 without any text.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nLet’s take a look:\n\nout_fun_1 &lt;- fun_1(86, 1.87)\n\n[1] \"This returns:24.59\"\n\nout_fun_1\n\n[1] \"This returns:24.59\"\n\n\nHmm, so option one seems to be correct:\n\nIt calculates the rounded quotient of x and y^2 and prints the result with some text.\nIt calculates the rounded quotient of x and y^2 but doesn’t do anything with it.\nIt calculates the rounded quotient of x and y^2, prints this result with some text and returns only the result without any text.\nIt only returns the rounded quotient of x and y^2 without any text.\n\nActually, this function calculates the Body Mass Index (BMI): \\(\\frac{weight(kg)}{height(m)^2}\\). However, it doesn’t return a numeric value, but just prints the result of the calculation along with some text.\n\n\n\n\nImprove it, so it becomes clearer what it does, and it returns something more meaningful.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nAssign a more informative name and more informative argument names. Use return() to make clear what the function returns. Print a more informative statement.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ncalc_bmi &lt;- function(kg, meter){ \n \n  res &lt;- round(kg/meter^2, digits = 2)\n \n  print(paste0(\"Your BMI is: \", res))\n \n  return(res)\n}\n\nmy_bmi &lt;- calc_bmi(86, 1.87)\n\n[1] \"Your BMI is: 24.59\"\n\nmy_bmi\n\n[1] 24.59\n\n\nHere we gave the function and its arguments some more informative names and used the return() function to clearly return the result of the calculation, and we can save it in an object. Also, we wrote a more informative printed statement."
  },
  {
    "objectID": "qmd/packages/packages_exercise.html",
    "href": "qmd/packages/packages_exercise.html",
    "title": "Packages: Exercises",
    "section": "",
    "text": "For this exercise, we are going to install all the packages we are going to need for the exercises in the coming chapters. So please install and load the following packages:\n\ntidyverse\nhere\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe top of your script now should look something like this:\n\n# install.packages(\"tidyverse\")\n# install.packages(\"here\")\n\nlibrary(tidyverse)\nlibrary(here)\n\nI have commented out the install.packages() calls after executing them, because I don’t want them to be installed every time I run the script, once is enough!"
  },
  {
    "objectID": "qmd/packages/packages_exercise.html#exercise-1",
    "href": "qmd/packages/packages_exercise.html#exercise-1",
    "title": "Packages: Exercises",
    "section": "",
    "text": "For this exercise, we are going to install all the packages we are going to need for the exercises in the coming chapters. So please install and load the following packages:\n\ntidyverse\nhere\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe top of your script now should look something like this:\n\n# install.packages(\"tidyverse\")\n# install.packages(\"here\")\n\nlibrary(tidyverse)\nlibrary(here)\n\nI have commented out the install.packages() calls after executing them, because I don’t want them to be installed every time I run the script, once is enough!"
  },
  {
    "objectID": "qmd/data_structures/data_structures.html",
    "href": "qmd/data_structures/data_structures.html",
    "title": "Data structures",
    "section": "",
    "text": "There are five main data structures in R which differ on their dimensions (one dimension, two dimensions, n dimensions) and the type of the elements they are containing (same type, different types):1\n\n\n\n\n\nHomogeneous\nHeterogeneous\n\n\n\n\n1d\natomic vector\nlist\n\n\n2d\nmatrix\ndata.frame\n\n\nnd\narray\n\n\n\n\n\nLet’s take a closer look at the two we will use mostly throughout this workshop:\n\n\nAtomic vectors (from hereon only called vectors) contain elements of only the same type:\n\nnum_vec &lt;- c(2023, 8, 8)\nnum_vec\n\n[1] 2023    8    8\n\nchar_vec &lt;- c(\"This\", \"is\", \"a\", \"vec\", \".\")\nchar_vec\n\n[1] \"This\" \"is\"   \"a\"    \"vec\"  \".\"   \n\nlog_vec &lt;- c(TRUE, FALSE)\nlog_vec\n\n[1]  TRUE FALSE\n\n\n\n\nIf we take a look at the structure of the vectors we have just created, we see se a short description of the data type we are dealing with in front of the vector:\n\nstr(num_vec)\n\n num [1:3] 2023 8 8\n\nstr(char_vec)\n\n chr [1:5] \"This\" \"is\" \"a\" \"vec\" \".\"\n\nstr(log_vec)\n\n logi [1:2] TRUE FALSE\n\n\nThe first one is num (numeric) so it only stores numeric values. The second one is char (character), so it only can contain strings. And last but not least we have logi (logical) for boolean values. Why is that important? Well, some functions only make sense for specific data types. For example:\n\nmean(char_vec)\n\nWarning in mean.default(char_vec): argument is not numeric or logical:\nreturning NA\n\n\n[1] NA\n\n\ngives us a warning, because the input has the wrong format.\n\n\n\n\nA data frame is two dimensional and can store elements of different types. It is the closest to data tables we are probably most used to working with.\n\npersons &lt;- data.frame(name = c(\"Anna\", \"Alex\", \"John\", \"Jessi\"),\n                      age = c(19, 17, 18, 18),\n                      birth_month = c(\"Jan\", \"Sep\", \"Oct\", \"Mar\"),\n                      big5_extro = c(3.5, 2, 4.5, 4.2)\n                      )\n\nNote that we do nothing else here than combining vectors to a data frame. Each vector will be one column.\n\n\nAdding new columns to a data frame is pretty straight forward. We just define the column name, and then assign it some input. For example, we could add a column with the neuroticsm ratings for each person:\n\npersons$big5_neuro &lt;- c(1, 3, 2, 4)\npersons\n\n   name age birth_month big5_extro big5_neuro\n1  Anna  19         Jan        3.5          1\n2  Alex  17         Sep        2.0          3\n3  John  18         Oct        4.5          2\n4 Jessi  18         Mar        4.2          4\n\n\nOr, using the tidyverse with the help of mutate():\n\n\nlibrary(tidyverse)\n\npersons &lt;- mutate(persons, big5_agree= c(2, 5, 2, 1) )\n\n\n\n\n\nA special type of data frames are the so called tibbles. Tibbles are a modern version of data frames and the standard data frame type of the tidyverse, as they have some advantageous characteristics (e.g., note the more informative printing of the data frame). So don’t be confused if you run into them, in general they behave like data frames.\n\n\npersons_tibble &lt;- tibble(\n  name = c(\"Anna\", \"Alex\", \"John\", \"Jessi\"),\n  age = c(19, 17, 18, 18),\n  birth_month = c(\"Jan\", \"Sep\", \"Oct\", \"Mar\"),\n  big5_extro = c(3.5, 2, 4.5, 4.2)\n)\npersons_tibble\n\n# A tibble: 4 × 4\n  name    age birth_month big5_extro\n  &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;\n1 Anna     19 Jan                3.5\n2 Alex     17 Sep                2  \n3 John     18 Oct                4.5\n4 Jessi    18 Mar                4.2\n\n\n\n\n\n\n\nA list is a one dimensional object, which can, unlike a vector, contain elements of different types, but also of different lengths. For example, we can store a vectors of different lengths and data frames in a list, which makes it the most versatile data structure:\n\npersonality_rating &lt;- list(\n     big5 = data.frame(name = c(\"Jessi\", \"John\"),\n                       extraversion = c(4.3, 2), \n                       openness = c(3.8, NA)),\n     rating_type = \"self_rating\"\n     )\npersonality_rating\n\n$big5\n   name extraversion openness\n1 Jessi          4.3      3.8\n2  John          2.0       NA\n\n$rating_type\n[1] \"self_rating\"\n\n\nHere, we define the list personality_rating, which includes a data frame with the personality rating, and some meta information in the form of a character vector, describing the rating type. We won’t use it any more in this workshop, but keep in mind it exists, as it quickly becomes necessary for managing more complex tasks."
  },
  {
    "objectID": "qmd/data_structures/data_structures.html#vector",
    "href": "qmd/data_structures/data_structures.html#vector",
    "title": "Data structures",
    "section": "",
    "text": "Atomic vectors (from hereon only called vectors) contain elements of only the same type:\n\nnum_vec &lt;- c(2023, 8, 8)\nnum_vec\n\n[1] 2023    8    8\n\nchar_vec &lt;- c(\"This\", \"is\", \"a\", \"vec\", \".\")\nchar_vec\n\n[1] \"This\" \"is\"   \"a\"    \"vec\"  \".\"   \n\nlog_vec &lt;- c(TRUE, FALSE)\nlog_vec\n\n[1]  TRUE FALSE\n\n\n\n\nIf we take a look at the structure of the vectors we have just created, we see se a short description of the data type we are dealing with in front of the vector:\n\nstr(num_vec)\n\n num [1:3] 2023 8 8\n\nstr(char_vec)\n\n chr [1:5] \"This\" \"is\" \"a\" \"vec\" \".\"\n\nstr(log_vec)\n\n logi [1:2] TRUE FALSE\n\n\nThe first one is num (numeric) so it only stores numeric values. The second one is char (character), so it only can contain strings. And last but not least we have logi (logical) for boolean values. Why is that important? Well, some functions only make sense for specific data types. For example:\n\nmean(char_vec)\n\nWarning in mean.default(char_vec): argument is not numeric or logical:\nreturning NA\n\n\n[1] NA\n\n\ngives us a warning, because the input has the wrong format."
  },
  {
    "objectID": "qmd/data_structures/data_structures.html#data-frame",
    "href": "qmd/data_structures/data_structures.html#data-frame",
    "title": "Data structures",
    "section": "",
    "text": "A data frame is two dimensional and can store elements of different types. It is the closest to data tables we are probably most used to working with.\n\npersons &lt;- data.frame(name = c(\"Anna\", \"Alex\", \"John\", \"Jessi\"),\n                      age = c(19, 17, 18, 18),\n                      birth_month = c(\"Jan\", \"Sep\", \"Oct\", \"Mar\"),\n                      big5_extro = c(3.5, 2, 4.5, 4.2)\n                      )\n\nNote that we do nothing else here than combining vectors to a data frame. Each vector will be one column.\n\n\nAdding new columns to a data frame is pretty straight forward. We just define the column name, and then assign it some input. For example, we could add a column with the neuroticsm ratings for each person:\n\npersons$big5_neuro &lt;- c(1, 3, 2, 4)\npersons\n\n   name age birth_month big5_extro big5_neuro\n1  Anna  19         Jan        3.5          1\n2  Alex  17         Sep        2.0          3\n3  John  18         Oct        4.5          2\n4 Jessi  18         Mar        4.2          4\n\n\nOr, using the tidyverse with the help of mutate():\n\n\nlibrary(tidyverse)\n\npersons &lt;- mutate(persons, big5_agree= c(2, 5, 2, 1) )\n\n\n\n\n\nA special type of data frames are the so called tibbles. Tibbles are a modern version of data frames and the standard data frame type of the tidyverse, as they have some advantageous characteristics (e.g., note the more informative printing of the data frame). So don’t be confused if you run into them, in general they behave like data frames.\n\n\npersons_tibble &lt;- tibble(\n  name = c(\"Anna\", \"Alex\", \"John\", \"Jessi\"),\n  age = c(19, 17, 18, 18),\n  birth_month = c(\"Jan\", \"Sep\", \"Oct\", \"Mar\"),\n  big5_extro = c(3.5, 2, 4.5, 4.2)\n)\npersons_tibble\n\n# A tibble: 4 × 4\n  name    age birth_month big5_extro\n  &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;\n1 Anna     19 Jan                3.5\n2 Alex     17 Sep                2  \n3 John     18 Oct                4.5\n4 Jessi    18 Mar                4.2"
  },
  {
    "objectID": "qmd/data_structures/data_structures.html#honorable-mention-list",
    "href": "qmd/data_structures/data_structures.html#honorable-mention-list",
    "title": "Data structures",
    "section": "",
    "text": "A list is a one dimensional object, which can, unlike a vector, contain elements of different types, but also of different lengths. For example, we can store a vectors of different lengths and data frames in a list, which makes it the most versatile data structure:\n\npersonality_rating &lt;- list(\n     big5 = data.frame(name = c(\"Jessi\", \"John\"),\n                       extraversion = c(4.3, 2), \n                       openness = c(3.8, NA)),\n     rating_type = \"self_rating\"\n     )\npersonality_rating\n\n$big5\n   name extraversion openness\n1 Jessi          4.3      3.8\n2  John          2.0       NA\n\n$rating_type\n[1] \"self_rating\"\n\n\nHere, we define the list personality_rating, which includes a data frame with the personality rating, and some meta information in the form of a character vector, describing the rating type. We won’t use it any more in this workshop, but keep in mind it exists, as it quickly becomes necessary for managing more complex tasks."
  },
  {
    "objectID": "qmd/data_structures/data_structures.html#footnotes",
    "href": "qmd/data_structures/data_structures.html#footnotes",
    "title": "Data structures",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nTable from Advanced R.↩︎"
  },
  {
    "objectID": "qmd/peeking/peeking_exercise.html",
    "href": "qmd/peeking/peeking_exercise.html",
    "title": "Getting an Overview: Exercises",
    "section": "",
    "text": "Previous code\n\n\n\n\n\n\nlibrary(tidyverse)\n\n## Load the data\ncharacters &lt;- readRDS(file = here::here(\"raw_data\", \"characters.rds\"))\npsych_stats &lt;- read.csv(\n  file = here::here(\"raw_data\", \"psych_stats.csv\"),\n  sep = \";\"\n)"
  },
  {
    "objectID": "qmd/peeking/peeking_exercise.html#exercise-1",
    "href": "qmd/peeking/peeking_exercise.html#exercise-1",
    "title": "Getting an Overview: Exercises",
    "section": "Exercise 1",
    "text": "Exercise 1\nTake a look at the characters data set. 1. How many rows and how many columns does the data frame have?\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse str().\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nstr(characters)\n\n'data.frame':   889 obs. of  7 variables:\n $ id        : chr  \"F2\" \"F1\" \"F5\" \"F4\" ...\n $ name      : chr  \"Monica Geller\" \"Rachel Green\" \"Chandler Bing\" \"Joey Tribbiani\" ...\n $ uni_id    : chr  \"F\" \"F\" \"F\" \"F\" ...\n $ uni_name  : chr  \"Friends\" \"Friends\" \"Friends\" \"Friends\" ...\n $ notability: num  79.7 76.7 74.4 74.3 72.6 51.6 86.5 84.2 82.6 65.6 ...\n $ link      : chr  \"https://openpsychometrics.org/tests/characters/stats/F/2\" \"https://openpsychometrics.org/tests/characters/stats/F/1\" \"https://openpsychometrics.org/tests/characters/stats/F/5\" \"https://openpsychometrics.org/tests/characters/stats/F/4\" ...\n $ image_link: chr  \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/2.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/1.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/5.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/4.jpg\" ...\n\n\nThe data frame has 889 rows and 7 columns.\n\n\n\n\nWhat show are the first characters in the data frame from?\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse head().\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nhead(characters)\n\n  id           name uni_id uni_name notability\n1 F2  Monica Geller      F  Friends       79.7\n2 F1   Rachel Green      F  Friends       76.7\n3 F5  Chandler Bing      F  Friends       74.4\n4 F4 Joey Tribbiani      F  Friends       74.3\n5 F3  Phoebe Buffay      F  Friends       72.6\n6 F6    Ross Geller      F  Friends       51.6\n                                                      link\n1 https://openpsychometrics.org/tests/characters/stats/F/2\n2 https://openpsychometrics.org/tests/characters/stats/F/1\n3 https://openpsychometrics.org/tests/characters/stats/F/5\n4 https://openpsychometrics.org/tests/characters/stats/F/4\n5 https://openpsychometrics.org/tests/characters/stats/F/3\n6 https://openpsychometrics.org/tests/characters/stats/F/6\n                                                                  image_link\n1 https://openpsychometrics.org/tests/characters/test-resources/pics/F/2.jpg\n2 https://openpsychometrics.org/tests/characters/test-resources/pics/F/1.jpg\n3 https://openpsychometrics.org/tests/characters/test-resources/pics/F/5.jpg\n4 https://openpsychometrics.org/tests/characters/test-resources/pics/F/4.jpg\n5 https://openpsychometrics.org/tests/characters/test-resources/pics/F/3.jpg\n6 https://openpsychometrics.org/tests/characters/test-resources/pics/F/6.jpg\n\n\n\n\n\nThey are from Friends."
  },
  {
    "objectID": "qmd/format/format.html",
    "href": "qmd/format/format.html",
    "title": "Wide and Long Format",
    "section": "",
    "text": "In this chapter, we will look at a simpler data set that makes it a bit easier to explain reshaping between the wide and long data format, as our relatively complex athletes data set.\nLet’s define our own data set:\nlibrary(tidyverse) # Only if you haven't loaded it yet. Will use later.\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ninhabitants_wide &lt;- data.frame(\n  country = c(\"China\", \"India\", \"USA\"),\n  inhabitants_2021 = c(1425893465, 1407563842, NA),\n  inhabitants_2022 = c(1425857720, 1420939232, 338903174)\n)"
  },
  {
    "objectID": "qmd/format/format.html#wide-format",
    "href": "qmd/format/format.html#wide-format",
    "title": "Wide and Long Format",
    "section": "Wide Format",
    "text": "Wide Format\nIn the wide format, we have only one row per unit of analysis. In this example, each country has it’s own row:\n\nhead(inhabitants_wide)\n\n  country inhabitants_2021 inhabitants_2022\n1   China       1425893465       1425857720\n2   India       1407563842       1420939232\n3     USA               NA        338903174\n\n\nHowever, the variable inhabitants is stretched over multiple rows. In many cases it makes sense to reshape the data, so the inhabitants are all put into one column:"
  },
  {
    "objectID": "qmd/format/format.html#long-format",
    "href": "qmd/format/format.html#long-format",
    "title": "Wide and Long Format",
    "section": "Long Format",
    "text": "Long Format\nThis is what happens in the Long data Format does, where each unit of analysis is spread over multiple rows."
  },
  {
    "objectID": "qmd/format/format.html#reshaping-from-wide-to-long-format",
    "href": "qmd/format/format.html#reshaping-from-wide-to-long-format",
    "title": "Wide and Long Format",
    "section": "Reshaping from Wide to Long Format",
    "text": "Reshaping from Wide to Long Format\nTo get from Wide Format to Long Format we can use the pivot_longer() function from the tidyverse:\n\n\ninhabitants_long &lt;- inhabitants_wide %&gt;%\n  pivot_longer(\n    cols = c(\"inhabitants_2022\", \"inhabitants_2021\"),\n    names_to = \"year\",\n    values_to = \"inhabitants\"\n  )\n\nhead(inhabitants_long)\n\n# A tibble: 6 × 3\n  country year             inhabitants\n  &lt;chr&gt;   &lt;chr&gt;                  &lt;dbl&gt;\n1 China   inhabitants_2022  1425857720\n2 China   inhabitants_2021  1425893465\n3 India   inhabitants_2022  1420939232\n4 India   inhabitants_2021  1407563842\n5 USA     inhabitants_2022   338903174\n6 USA     inhabitants_2021          NA"
  },
  {
    "objectID": "qmd/format/format.html#reshaping-from-long-to-wide-format",
    "href": "qmd/format/format.html#reshaping-from-long-to-wide-format",
    "title": "Wide and Long Format",
    "section": "Reshaping from Long to Wide Format",
    "text": "Reshaping from Long to Wide Format\nIn other cases it might happen, that multiple variables are put into the same column, togehter with an identifier column:\n\ninhabitants_long_2\n\n  country         variable      value\n1   China             area    9597000\n2   China inhabitants_2022 1425857720\n3   India             area    3287000\n4   India inhabitants_2022 1420939232\n5     USA             area    9834000\n6     USA inhabitants_2022  338903174\n\n\nIn that case it can make sense to spread the the distinct variables into two columns:\n\ninhabitants_wide_2 &lt;- inhabitants_long_2 %&gt;%\n  pivot_wider(\n    id_cols = \"country\",\n    names_from = \"variable\",\n    values_from = \"value\"\n  )\n\ninhabitants_wide_2\n\n# A tibble: 3 × 3\n  country    area inhabitants_2022\n  &lt;chr&gt;     &lt;dbl&gt;            &lt;dbl&gt;\n1 China   9597000       1425857720\n2 India   3287000       1420939232\n3 USA     9834000        338903174"
  },
  {
    "objectID": "qmd/merging/merging_exercise.html",
    "href": "qmd/merging/merging_exercise.html",
    "title": "Merging: Exercise",
    "section": "",
    "text": "Previous code\n\n\n\n\n\n\nlibrary(tidyverse)\n\n## Load the data\ncharacters &lt;- readRDS(file = here::here(\"raw_data\", \"characters.rds\"))\npsych_stats &lt;- read.csv(\n  file = here::here(\"raw_data\", \"psych_stats.csv\"),\n  sep = \";\"\n)\n\n## Take a look at the data sets\nstr(characters)\n\n'data.frame':   889 obs. of  7 variables:\n $ id        : chr  \"F2\" \"F1\" \"F5\" \"F4\" ...\n $ name      : chr  \"Monica Geller\" \"Rachel Green\" \"Chandler Bing\" \"Joey Tribbiani\" ...\n $ uni_id    : chr  \"F\" \"F\" \"F\" \"F\" ...\n $ uni_name  : chr  \"Friends\" \"Friends\" \"Friends\" \"Friends\" ...\n $ notability: num  79.7 76.7 74.4 74.3 72.6 51.6 86.5 84.2 82.6 65.6 ...\n $ link      : chr  \"https://openpsychometrics.org/tests/characters/stats/F/2\" \"https://openpsychometrics.org/tests/characters/stats/F/1\" \"https://openpsychometrics.org/tests/characters/stats/F/5\" \"https://openpsychometrics.org/tests/characters/stats/F/4\" ...\n $ image_link: chr  \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/2.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/1.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/5.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/4.jpg\" ...\n\nstr(psych_stats)\n\n'data.frame':   889 obs. of  365 variables:\n $ char_id                                     : chr  \"F2\" \"F1\" \"F5\" \"F4\" ...\n $ messy_neat                                  : num  95.7 30.2 45.3 13 20.9 ...\n $ disorganized_self.disciplined               : num  95.2 25.9 42.4 11 20.9 75.6 10.4 31.9 39.6 31.1 ...\n $ diligent_lazy                               : num  6.1 51.8 52.2 78.1 45.2 ...\n $ on.time_tardy                               : num  6.2 77.9 57.1 84.1 74 20.6 85.7 68.3 73.6 58.2 ...\n $ competitive_cooperative                     : num  6.4 28.9 42.8 44.2 55.3 ...\n $ scheduled_spontaneous                       : num  6.6 72.3 54.9 91.3 94.9 ...\n $ ADHD_OCD                                    : num  92.9 31.8 26.7 10.4 12.8 70.1 35.5 30.1 51.8 39.2 ...\n $ chaotic_orderly                             : num  92.2 27 38.2 12.6 11.2 68.8 6.8 20.6 23.4 28.8 ...\n $ motivated_unmotivated                       : num  7.8 31.8 52.3 45.6 24.7 31.5 80.9 30.5 40.8 50.7 ...\n $ bossy_meek                                  : num  7.9 30.6 64.8 60.8 40.1 ...\n $ persistent_quitter                          : num  7.9 35.8 43.9 33.8 21.3 ...\n $ overachiever_underachiever                  : num  8.2 43.8 55.8 68.8 51.3 23.2 67.7 36.7 44.1 44.4 ...\n $ muddy_washed                                : num  91 80.2 58.7 42.7 48.1 64.6 27.6 62.4 70.1 69.2 ...\n $ beautiful_ugly                              : num  9.2 5.3 26.2 11 11.4 ...\n $ slacker_workaholic                          : num  90.8 45.9 53.4 17.6 32 81.5 23.8 30.1 33.2 34.6 ...\n $ driven_unambitious                          : num  9.5 30.3 49.8 49.4 43.4 22.7 58.5 34.1 32 47.4 ...\n $ outlaw_sheriff                              : num  90.3 39.3 46.7 23.8 16.1 85.4 21.4 22.7 27.3 30.1 ...\n $ precise_vague                               : num  9.9 64.7 53.2 78 78.1 25.4 68.4 60.1 47.3 61.7 ...\n $ bad.cook_good.cook                          : num  90 11.1 28.2 31.2 29.4 35.9 27.3 46.2 43.8 52.8 ...\n $ manicured_scruffy                           : num  10.6 7.7 45.6 47.6 62.5 20.5 81.3 37.3 20.3 20.9 ...\n $ lenient_strict                              : num  89.3 34.2 28.8 11 15.4 76.7 15.2 24.2 38.9 21.5 ...\n $ relaxed_tense                               : num  89 58.8 66.4 10.4 16.9 88.9 69.9 64.2 54.5 64.8 ...\n $ demanding_unchallenging                     : num  11 23.9 58.3 66.3 57.1 28.5 35.9 37.8 16.8 60.3 ...\n $ drop.out_valedictorian                      : num  88.9 32.5 47 14.9 22.1 87.7 12.5 29.6 36.5 51.2 ...\n $ go.getter_slugabed                          : num  11.7 31.3 52.6 48.1 27.6 41.8 62.6 33.9 27.3 51.1 ...\n $ competent_incompetent                       : num  11.9 47.1 37.1 77.2 53.6 37.8 51.9 41.1 35.2 56.1 ...\n $ aloof_obsessed                              : num  88.1 62.3 52.3 35.1 33.2 80.8 75.1 54.9 70.7 61.9 ...\n $ flexible_rigid                              : num  87.8 41.8 45.9 17.3 13.9 83.7 45.9 27.4 55 32.1 ...\n $ active_slothful                             : num  12.2 33.1 61.1 56.7 31.4 48.8 73.9 19.8 29.2 35.5 ...\n $ loose_tight                                 : num  87.4 43.2 44.3 14 15.3 82.5 28.1 26 44.8 43.6 ...\n $ pointed_random                              : num  12.8 49.9 67.1 86.2 87.4 36.7 65.4 53.1 36.9 56.2 ...\n $ fresh_stinky                                : num  12.9 14.6 31.9 44.3 39.2 44.3 64.4 30.2 18.2 24.6 ...\n $ dominant_submissive                         : num  13.6 41.6 73.7 40.2 30.9 69.5 43.5 52.6 36.9 77.9 ...\n $ anxious_calm                                : num  13.7 28.8 20 66.1 58 11.9 12 32.1 37.1 29.8 ...\n $ clean_perverted                             : num  13.7 42.5 56.8 77.5 59.4 44 53.1 51.2 61.9 50.6 ...\n $ neutral_opinionated                         : num  86.3 74.6 67.2 43.4 76.6 84.2 67.3 77.9 82.5 43.9 ...\n $ always.down_picky                           : num  85.9 72.6 49.8 27.1 35.2 71.9 23.6 36.2 71.8 36.2 ...\n $ hurried_leisurely                           : num  14.6 55.1 55.9 85.9 81 22.1 48.6 45.6 49 39.3 ...\n $ attractive_repulsive                        : num  14.7 9.4 28.5 15.7 18.2 ...\n $ devoted_unfaithful                          : num  14.8 29.1 22.6 41.5 19.6 47.5 34.1 55.7 42.7 48.2 ...\n $ helpless_resourceful                        : num  85 41.4 56.6 37.9 70.6 52.4 41.4 51.5 36.2 29.8 ...\n $ deliberate_spontaneous                      : num  15.1 71.7 56.5 89.1 92.9 20.9 78.6 88.3 64 60.9 ...\n $ plays.hard_works.hard                       : num  84.7 41.3 46.5 13.7 26 81.2 28.2 30 19.9 26.4 ...\n $ imaginative_practical                       : num  84.7 37.9 54.6 17 5.4 ...\n $ frenzied_sleepy                             : num  15.5 29.9 34.7 55.6 30 31.1 59.4 25.2 19 46 ...\n $ queer_straight                              : num  84.3 84.1 65.4 84.3 45.4 77.9 10.2 4.8 73.4 64.1 ...\n $ assertive_passive                           : num  15.8 40.4 66.3 44.3 39.3 60.9 45.1 45.8 23.4 63.3 ...\n $ fast.talking_slow.talking                   : num  15.9 20.8 18.3 42.2 21.7 49.6 69.5 34.3 32.5 44.5 ...\n $ astonishing_methodical                      : num  83.8 28 49.9 19.2 17.4 83 31.2 27.4 36 32.7 ...\n $ hoarder_unprepared                          : num  16.2 70 63.5 82 54.9 35.5 60.3 64.5 48.3 67.8 ...\n $ consistent_variable                         : num  16.6 60.2 46.3 63.1 79.3 39.5 72 65.3 69.7 62.3 ...\n $ involved_remote                             : num  16.7 26.3 42.7 30.2 36.7 36.6 62.2 39.3 26.4 38.7 ...\n $ backdoor_official                           : num  83.3 51.9 47.4 24.4 20.4 76.4 29.1 29.3 53.5 36.7 ...\n $ captain_first.mate                          : num  16.7 52.7 73.5 74.2 57.9 68.4 55.9 51 19 73.6 ...\n $ refined_rugged                              : num  17.3 18.9 48.4 74.4 69.9 24.4 81.6 48 31.4 40.7 ...\n $ accommodating_stubborn                      : num  82.7 77.2 48.2 43.9 48.3 78.5 78.1 69 85.9 41.5 ...\n $ barbaric_civilized                          : num  82.6 76.5 66.6 32.9 39.9 77 33.4 44.4 36.7 55.5 ...\n $ alpha_beta                                  : num  17.7 37.9 73.9 33.6 41.9 78.2 44.3 37.4 17.5 66.6 ...\n $ loyal_traitorous                            : num  17.8 32.3 20 15.3 14.5 40.3 29.2 43.1 47.2 33.2 ...\n $ trash_treasure                              : num  82 80.1 82.2 78.4 83.2 47.8 64.5 62.2 68.2 78.4 ...\n $ fast_slow                                   : num  18.1 43.7 38.1 69 55.3 60.4 57.8 29.4 30 54.5 ...\n $ perceptive_unobservant                      : num  18.3 59.5 41.5 80 41.1 48.6 21.6 33.3 28 49 ...\n $ goof.off_studious                           : num  81.4 33.2 20.7 7.4 16.6 ...\n $ feminist_sexist                             : num  18.6 23.3 43.9 62 10.5 ...\n $ desperate_high.standards                    : num  81.1 69.2 30.7 36.8 56.7 29.2 33.7 32.5 61.7 25.8 ...\n $ impatient_patient                           : num  18.9 21.9 34 25.7 39.1 25.8 23.8 35.1 18 57.2 ...\n $ preppy_punk.rock                            : num  18.9 16.4 41.5 49.5 73.2 14.4 87.7 74.4 26.4 18.2 ...\n $ naive_paranoid                              : num  80.7 35.5 66.6 22 39.7 71.6 69.6 45.6 50.7 32.1 ...\n $ important_irrelevant                        : num  19.3 22.3 24.6 24.7 26.4 47.4 12.5 14.8 16.4 33.4 ...\n $ apprentice_master                           : num  80.6 42.3 44.9 36.3 61.5 60.8 48 48 73 31.5 ...\n $ healthy_sickly                              : num  19.6 17.8 39.1 26.9 22.6 37 88.9 65.7 56.7 45.5 ...\n $ morning.lark_night.owl                      : num  19.6 69.9 58.3 80.4 61.9 23.2 90.6 81.9 90.1 78.3 ...\n $ alert_oblivious                             : num  19.6 70.7 55.5 87.6 78.9 57.1 54.7 48.9 38.3 67.4 ...\n $ f....the.police_tattle.tale                 : num  80 57.5 56.7 34.4 13.7 ...\n $ experimental_reliable                       : num  79.7 37.8 62 35 22.2 61.7 28 26.5 30.4 39.8 ...\n $ loud_quiet                                  : num  20.4 20.8 25 10.6 15.3 39.5 71.9 42.7 13.2 55.2 ...\n $ high.IQ_low.IQ                              : num  20.5 56.7 28.8 82.6 50.6 19.3 30.9 26.1 47.7 55.6 ...\n $ oppressed_privileged                        : num  79.2 85.4 67.2 66.5 42.1 84.3 22.4 19.6 59.9 63.4 ...\n $ animalistic_human                           : num  79.2 75.6 73.7 43.8 42.1 69.3 70.4 55.9 64.4 73.2 ...\n $ still_twitchy                               : num  79.2 68.6 79.9 76.9 83.6 81.9 77.9 67.4 60.1 58.4 ...\n $ thick_thin                                  : num  78.8 79.6 52.8 35.2 69.2 60.6 73.3 81.4 66.1 48.8 ...\n $ repetitive_varied                           : num  21.3 44.5 40.9 43.4 74.1 18.4 40.1 68.4 47.3 42.1 ...\n $ rational_whimsical                          : num  21.7 72.3 54.4 86.8 93 27.4 67 78.7 69.6 70.9 ...\n $ egalitarian_racist                          : num  21.7 27.8 24.7 24.3 10.7 ...\n $ disreputable_prestigious                    : num  78.2 66.2 47 32.5 36.7 68.2 21.2 42.5 65.2 45.8 ...\n $ ignorant_knowledgeable                      : num  78.2 37.7 66.9 22.2 59.9 68.5 60.8 68.1 44.2 42.6 ...\n $ hard.work_natural.talent                    : num  21.9 47.5 41.8 69.8 71.2 29.2 55.8 67.5 65.8 57.3 ...\n $ androgynous_gendered                        : num  78.1 89.4 68.5 82.5 60.1 78.1 32.6 43.4 88.3 87.9 ...\n $ dispassionate_romantic                      : num  77.9 80.5 64.7 69.6 74.9 67.2 61.5 64.8 59.1 82.3 ...\n $ eloquent_unpolished                         : num  22.1 32.1 56.1 79.8 69 33.7 76.3 45.2 35 42.9 ...\n $ permanent_transient                         : num  22.2 56.1 39 59.6 71.1 31.9 68.5 79.7 57.2 70.6 ...\n $ intense_lighthearted                        : num  22.2 50.8 73.8 79.8 64.2 28.2 22.4 34.7 18.2 44.3 ...\n $ mischievous_well.behaved                    : num  77.8 34.2 30.6 15.8 20.3 71.4 13.3 19.4 17.6 38.2 ...\n $ adventurous_stick.in.the.mud                : num  77.7 37.4 59.7 14.4 8 ...\n $ obedient_rebellious                         : num  22.3 69.2 42.9 72.9 86.2 16.5 92.3 87.1 84.2 38.1 ...\n $ authoritarian_democratic                    : num  22.4 55.2 70 72.1 75.4 41.6 68 67.4 21.8 68.9 ...\n $ city.slicker_country.bumpkin                : num  22.7 9 22.4 18.4 42.6 18.8 26.5 20.2 16.8 24 ...\n $ traditional_unorthodox                      : num  22.8 52.8 54.9 67.2 90 23.1 85.7 90.2 74.5 62.6 ...\n  [list output truncated]\nNow we have gotten to know our characters data set a bit more. However, the personality ratings are not included yet. For that, we need to load the psych_stats data set as well, which contains the ratings for all characters. Now we want to combine both data frames into one, so all information belonging together can be found in the same data frame."
  },
  {
    "objectID": "qmd/merging/merging_exercise.html#exercise-1",
    "href": "qmd/merging/merging_exercise.html#exercise-1",
    "title": "Merging: Exercise",
    "section": "Exercise 1",
    "text": "Exercise 1\nMerge the characters data frame and the psych_stats data frame on a common column.\n\n\n\n\n\n\nHint\n\n\n\n\n\nIdentify the common columns. Are they named the same in both data frames? Look at the documentation of ?merge to see, how you can merge data frames that don’t have identically named columns.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nFirst, let`s take a look at both data sets again:\n\nstr(characters)\n\n'data.frame':   889 obs. of  7 variables:\n $ id        : chr  \"F2\" \"F1\" \"F5\" \"F4\" ...\n $ name      : chr  \"Monica Geller\" \"Rachel Green\" \"Chandler Bing\" \"Joey Tribbiani\" ...\n $ uni_id    : chr  \"F\" \"F\" \"F\" \"F\" ...\n $ uni_name  : chr  \"Friends\" \"Friends\" \"Friends\" \"Friends\" ...\n $ notability: num  79.7 76.7 74.4 74.3 72.6 51.6 86.5 84.2 82.6 65.6 ...\n $ link      : chr  \"https://openpsychometrics.org/tests/characters/stats/F/2\" \"https://openpsychometrics.org/tests/characters/stats/F/1\" \"https://openpsychometrics.org/tests/characters/stats/F/5\" \"https://openpsychometrics.org/tests/characters/stats/F/4\" ...\n $ image_link: chr  \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/2.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/1.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/5.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/4.jpg\" ...\n\nstr(psych_stats)\n\n'data.frame':   889 obs. of  365 variables:\n $ char_id                                     : chr  \"F2\" \"F1\" \"F5\" \"F4\" ...\n $ messy_neat                                  : num  95.7 30.2 45.3 13 20.9 ...\n $ disorganized_self.disciplined               : num  95.2 25.9 42.4 11 20.9 75.6 10.4 31.9 39.6 31.1 ...\n $ diligent_lazy                               : num  6.1 51.8 52.2 78.1 45.2 ...\n $ on.time_tardy                               : num  6.2 77.9 57.1 84.1 74 20.6 85.7 68.3 73.6 58.2 ...\n $ competitive_cooperative                     : num  6.4 28.9 42.8 44.2 55.3 ...\n $ scheduled_spontaneous                       : num  6.6 72.3 54.9 91.3 94.9 ...\n $ ADHD_OCD                                    : num  92.9 31.8 26.7 10.4 12.8 70.1 35.5 30.1 51.8 39.2 ...\n $ chaotic_orderly                             : num  92.2 27 38.2 12.6 11.2 68.8 6.8 20.6 23.4 28.8 ...\n $ motivated_unmotivated                       : num  7.8 31.8 52.3 45.6 24.7 31.5 80.9 30.5 40.8 50.7 ...\n $ bossy_meek                                  : num  7.9 30.6 64.8 60.8 40.1 ...\n $ persistent_quitter                          : num  7.9 35.8 43.9 33.8 21.3 ...\n $ overachiever_underachiever                  : num  8.2 43.8 55.8 68.8 51.3 23.2 67.7 36.7 44.1 44.4 ...\n $ muddy_washed                                : num  91 80.2 58.7 42.7 48.1 64.6 27.6 62.4 70.1 69.2 ...\n $ beautiful_ugly                              : num  9.2 5.3 26.2 11 11.4 ...\n $ slacker_workaholic                          : num  90.8 45.9 53.4 17.6 32 81.5 23.8 30.1 33.2 34.6 ...\n $ driven_unambitious                          : num  9.5 30.3 49.8 49.4 43.4 22.7 58.5 34.1 32 47.4 ...\n $ outlaw_sheriff                              : num  90.3 39.3 46.7 23.8 16.1 85.4 21.4 22.7 27.3 30.1 ...\n $ precise_vague                               : num  9.9 64.7 53.2 78 78.1 25.4 68.4 60.1 47.3 61.7 ...\n $ bad.cook_good.cook                          : num  90 11.1 28.2 31.2 29.4 35.9 27.3 46.2 43.8 52.8 ...\n $ manicured_scruffy                           : num  10.6 7.7 45.6 47.6 62.5 20.5 81.3 37.3 20.3 20.9 ...\n $ lenient_strict                              : num  89.3 34.2 28.8 11 15.4 76.7 15.2 24.2 38.9 21.5 ...\n $ relaxed_tense                               : num  89 58.8 66.4 10.4 16.9 88.9 69.9 64.2 54.5 64.8 ...\n $ demanding_unchallenging                     : num  11 23.9 58.3 66.3 57.1 28.5 35.9 37.8 16.8 60.3 ...\n $ drop.out_valedictorian                      : num  88.9 32.5 47 14.9 22.1 87.7 12.5 29.6 36.5 51.2 ...\n $ go.getter_slugabed                          : num  11.7 31.3 52.6 48.1 27.6 41.8 62.6 33.9 27.3 51.1 ...\n $ competent_incompetent                       : num  11.9 47.1 37.1 77.2 53.6 37.8 51.9 41.1 35.2 56.1 ...\n $ aloof_obsessed                              : num  88.1 62.3 52.3 35.1 33.2 80.8 75.1 54.9 70.7 61.9 ...\n $ flexible_rigid                              : num  87.8 41.8 45.9 17.3 13.9 83.7 45.9 27.4 55 32.1 ...\n $ active_slothful                             : num  12.2 33.1 61.1 56.7 31.4 48.8 73.9 19.8 29.2 35.5 ...\n $ loose_tight                                 : num  87.4 43.2 44.3 14 15.3 82.5 28.1 26 44.8 43.6 ...\n $ pointed_random                              : num  12.8 49.9 67.1 86.2 87.4 36.7 65.4 53.1 36.9 56.2 ...\n $ fresh_stinky                                : num  12.9 14.6 31.9 44.3 39.2 44.3 64.4 30.2 18.2 24.6 ...\n $ dominant_submissive                         : num  13.6 41.6 73.7 40.2 30.9 69.5 43.5 52.6 36.9 77.9 ...\n $ anxious_calm                                : num  13.7 28.8 20 66.1 58 11.9 12 32.1 37.1 29.8 ...\n $ clean_perverted                             : num  13.7 42.5 56.8 77.5 59.4 44 53.1 51.2 61.9 50.6 ...\n $ neutral_opinionated                         : num  86.3 74.6 67.2 43.4 76.6 84.2 67.3 77.9 82.5 43.9 ...\n $ always.down_picky                           : num  85.9 72.6 49.8 27.1 35.2 71.9 23.6 36.2 71.8 36.2 ...\n $ hurried_leisurely                           : num  14.6 55.1 55.9 85.9 81 22.1 48.6 45.6 49 39.3 ...\n $ attractive_repulsive                        : num  14.7 9.4 28.5 15.7 18.2 ...\n $ devoted_unfaithful                          : num  14.8 29.1 22.6 41.5 19.6 47.5 34.1 55.7 42.7 48.2 ...\n $ helpless_resourceful                        : num  85 41.4 56.6 37.9 70.6 52.4 41.4 51.5 36.2 29.8 ...\n $ deliberate_spontaneous                      : num  15.1 71.7 56.5 89.1 92.9 20.9 78.6 88.3 64 60.9 ...\n $ plays.hard_works.hard                       : num  84.7 41.3 46.5 13.7 26 81.2 28.2 30 19.9 26.4 ...\n $ imaginative_practical                       : num  84.7 37.9 54.6 17 5.4 ...\n $ frenzied_sleepy                             : num  15.5 29.9 34.7 55.6 30 31.1 59.4 25.2 19 46 ...\n $ queer_straight                              : num  84.3 84.1 65.4 84.3 45.4 77.9 10.2 4.8 73.4 64.1 ...\n $ assertive_passive                           : num  15.8 40.4 66.3 44.3 39.3 60.9 45.1 45.8 23.4 63.3 ...\n $ fast.talking_slow.talking                   : num  15.9 20.8 18.3 42.2 21.7 49.6 69.5 34.3 32.5 44.5 ...\n $ astonishing_methodical                      : num  83.8 28 49.9 19.2 17.4 83 31.2 27.4 36 32.7 ...\n $ hoarder_unprepared                          : num  16.2 70 63.5 82 54.9 35.5 60.3 64.5 48.3 67.8 ...\n $ consistent_variable                         : num  16.6 60.2 46.3 63.1 79.3 39.5 72 65.3 69.7 62.3 ...\n $ involved_remote                             : num  16.7 26.3 42.7 30.2 36.7 36.6 62.2 39.3 26.4 38.7 ...\n $ backdoor_official                           : num  83.3 51.9 47.4 24.4 20.4 76.4 29.1 29.3 53.5 36.7 ...\n $ captain_first.mate                          : num  16.7 52.7 73.5 74.2 57.9 68.4 55.9 51 19 73.6 ...\n $ refined_rugged                              : num  17.3 18.9 48.4 74.4 69.9 24.4 81.6 48 31.4 40.7 ...\n $ accommodating_stubborn                      : num  82.7 77.2 48.2 43.9 48.3 78.5 78.1 69 85.9 41.5 ...\n $ barbaric_civilized                          : num  82.6 76.5 66.6 32.9 39.9 77 33.4 44.4 36.7 55.5 ...\n $ alpha_beta                                  : num  17.7 37.9 73.9 33.6 41.9 78.2 44.3 37.4 17.5 66.6 ...\n $ loyal_traitorous                            : num  17.8 32.3 20 15.3 14.5 40.3 29.2 43.1 47.2 33.2 ...\n $ trash_treasure                              : num  82 80.1 82.2 78.4 83.2 47.8 64.5 62.2 68.2 78.4 ...\n $ fast_slow                                   : num  18.1 43.7 38.1 69 55.3 60.4 57.8 29.4 30 54.5 ...\n $ perceptive_unobservant                      : num  18.3 59.5 41.5 80 41.1 48.6 21.6 33.3 28 49 ...\n $ goof.off_studious                           : num  81.4 33.2 20.7 7.4 16.6 ...\n $ feminist_sexist                             : num  18.6 23.3 43.9 62 10.5 ...\n $ desperate_high.standards                    : num  81.1 69.2 30.7 36.8 56.7 29.2 33.7 32.5 61.7 25.8 ...\n $ impatient_patient                           : num  18.9 21.9 34 25.7 39.1 25.8 23.8 35.1 18 57.2 ...\n $ preppy_punk.rock                            : num  18.9 16.4 41.5 49.5 73.2 14.4 87.7 74.4 26.4 18.2 ...\n $ naive_paranoid                              : num  80.7 35.5 66.6 22 39.7 71.6 69.6 45.6 50.7 32.1 ...\n $ important_irrelevant                        : num  19.3 22.3 24.6 24.7 26.4 47.4 12.5 14.8 16.4 33.4 ...\n $ apprentice_master                           : num  80.6 42.3 44.9 36.3 61.5 60.8 48 48 73 31.5 ...\n $ healthy_sickly                              : num  19.6 17.8 39.1 26.9 22.6 37 88.9 65.7 56.7 45.5 ...\n $ morning.lark_night.owl                      : num  19.6 69.9 58.3 80.4 61.9 23.2 90.6 81.9 90.1 78.3 ...\n $ alert_oblivious                             : num  19.6 70.7 55.5 87.6 78.9 57.1 54.7 48.9 38.3 67.4 ...\n $ f....the.police_tattle.tale                 : num  80 57.5 56.7 34.4 13.7 ...\n $ experimental_reliable                       : num  79.7 37.8 62 35 22.2 61.7 28 26.5 30.4 39.8 ...\n $ loud_quiet                                  : num  20.4 20.8 25 10.6 15.3 39.5 71.9 42.7 13.2 55.2 ...\n $ high.IQ_low.IQ                              : num  20.5 56.7 28.8 82.6 50.6 19.3 30.9 26.1 47.7 55.6 ...\n $ oppressed_privileged                        : num  79.2 85.4 67.2 66.5 42.1 84.3 22.4 19.6 59.9 63.4 ...\n $ animalistic_human                           : num  79.2 75.6 73.7 43.8 42.1 69.3 70.4 55.9 64.4 73.2 ...\n $ still_twitchy                               : num  79.2 68.6 79.9 76.9 83.6 81.9 77.9 67.4 60.1 58.4 ...\n $ thick_thin                                  : num  78.8 79.6 52.8 35.2 69.2 60.6 73.3 81.4 66.1 48.8 ...\n $ repetitive_varied                           : num  21.3 44.5 40.9 43.4 74.1 18.4 40.1 68.4 47.3 42.1 ...\n $ rational_whimsical                          : num  21.7 72.3 54.4 86.8 93 27.4 67 78.7 69.6 70.9 ...\n $ egalitarian_racist                          : num  21.7 27.8 24.7 24.3 10.7 ...\n $ disreputable_prestigious                    : num  78.2 66.2 47 32.5 36.7 68.2 21.2 42.5 65.2 45.8 ...\n $ ignorant_knowledgeable                      : num  78.2 37.7 66.9 22.2 59.9 68.5 60.8 68.1 44.2 42.6 ...\n $ hard.work_natural.talent                    : num  21.9 47.5 41.8 69.8 71.2 29.2 55.8 67.5 65.8 57.3 ...\n $ androgynous_gendered                        : num  78.1 89.4 68.5 82.5 60.1 78.1 32.6 43.4 88.3 87.9 ...\n $ dispassionate_romantic                      : num  77.9 80.5 64.7 69.6 74.9 67.2 61.5 64.8 59.1 82.3 ...\n $ eloquent_unpolished                         : num  22.1 32.1 56.1 79.8 69 33.7 76.3 45.2 35 42.9 ...\n $ permanent_transient                         : num  22.2 56.1 39 59.6 71.1 31.9 68.5 79.7 57.2 70.6 ...\n $ intense_lighthearted                        : num  22.2 50.8 73.8 79.8 64.2 28.2 22.4 34.7 18.2 44.3 ...\n $ mischievous_well.behaved                    : num  77.8 34.2 30.6 15.8 20.3 71.4 13.3 19.4 17.6 38.2 ...\n $ adventurous_stick.in.the.mud                : num  77.7 37.4 59.7 14.4 8 ...\n $ obedient_rebellious                         : num  22.3 69.2 42.9 72.9 86.2 16.5 92.3 87.1 84.2 38.1 ...\n $ authoritarian_democratic                    : num  22.4 55.2 70 72.1 75.4 41.6 68 67.4 21.8 68.9 ...\n $ city.slicker_country.bumpkin                : num  22.7 9 22.4 18.4 42.6 18.8 26.5 20.2 16.8 24 ...\n $ traditional_unorthodox                      : num  22.8 52.8 54.9 67.2 90 23.1 85.7 90.2 74.5 62.6 ...\n  [list output truncated]\n\n\nIt seems like both data frames have a column containing an ID for the character. We can use that column for merging:\n\ncharacters_stats &lt;- merge(\n  x = characters,\n  y = psych_stats,\n  by.x = \"id\", \n  by.y = \"char_id\"\n)\n\nstr(characters_stats)\n\n'data.frame':   889 obs. of  371 variables:\n $ id                                          : chr  \"AD1\" \"AD10\" \"AD2\" \"AD3\" ...\n $ name                                        : chr  \"Michael Bluth\" \"Lucille Bluth\" \"Lindsay Bluth Funke\" \"George Oscar 'Gob' Bluth\" ...\n $ uni_id                                      : chr  \"AD\" \"AD\" \"AD\" \"AD\" ...\n $ uni_name                                    : chr  \"Arrested Development\" \"Arrested Development\" \"Arrested Development\" \"Arrested Development\" ...\n $ notability                                  : num  76.9 72 49 38.3 56.7 61.5 43.2 36.7 64.4 34.3 ...\n $ link                                        : chr  \"https://openpsychometrics.org/tests/characters/stats/AD/1\" \"https://openpsychometrics.org/tests/characters/stats/AD/10\" \"https://openpsychometrics.org/tests/characters/stats/AD/2\" \"https://openpsychometrics.org/tests/characters/stats/AD/3\" ...\n $ image_link                                  : chr  \"https://openpsychometrics.org/tests/characters/test-resources/pics/AD/1.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/AD/10.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/AD/2.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/AD/3.jpg\" ...\n $ messy_neat                                  : num  68.6 74.5 24.7 22.9 80.2 24.4 54.8 35.9 25.1 15.6 ...\n $ disorganized_self.disciplined               : num  73.3 59.3 11.9 11 67.3 27.7 25.4 20.8 26.5 20.7 ...\n $ diligent_lazy                               : num  10.8 46.9 87.1 79.1 23.5 67.2 44.7 45.8 47.5 72.1 ...\n $ on.time_tardy                               : num  22.2 68.1 88.9 87.7 21.4 78.4 40 58.8 57.8 86.6 ...\n $ competitive_cooperative                     : num  45.1 7.1 13.2 7.1 84.1 ...\n $ scheduled_spontaneous                       : num  16.2 39.2 85 87 19.6 84.3 46 71.7 69.8 75.8 ...\n $ ADHD_OCD                                    : num  86.3 74.5 31.4 19.8 74.3 15.5 51.3 49.5 35.3 20.5 ...\n $ chaotic_orderly                             : num  74.7 29.3 12.5 7.9 64.2 ...\n $ motivated_unmotivated                       : num  15.4 26.9 72.8 57.2 39.1 48.4 66.3 32 34.6 64 ...\n $ bossy_meek                                  : num  36.2 4.8 18.8 30.8 91.7 10 91.1 83.2 12.2 58.4 ...\n $ persistent_quitter                          : num  17.8 22.4 69.3 51.1 42.9 37.9 66.3 30.7 32.4 47.1 ...\n $ overachiever_underachiever                  : num  18.9 34.2 84.4 75.8 47.8 70.6 83.4 69.5 38.1 72.9 ...\n $ muddy_washed                                : num  80.9 81.5 70.2 45.7 80.8 39.8 57.5 44.2 38.9 14.7 ...\n $ beautiful_ugly                              : num  30.8 43 14.6 43.5 47.7 22.8 59.4 61.1 73.6 75.5 ...\n $ slacker_workaholic                          : num  90.3 28 7.8 11.4 65.4 30.9 21.8 32.3 61.4 18.3 ...\n $ driven_unambitious                          : num  19.1 25.3 63.6 41.5 42.7 38.7 71.1 39 21.7 63.7 ...\n $ outlaw_sheriff                              : num  78 39.6 20.3 18.7 81.3 13.2 55.8 36.7 12.4 15.5 ...\n $ precise_vague                               : num  27.6 49.2 69 77.4 57 60.1 73.2 71.2 62.1 81.9 ...\n $ bad.cook_good.cook                          : num  55.3 7.1 7.7 9.2 46.9 ...\n $ manicured_scruffy                           : num  38 5.1 8.5 30.6 32 ...\n $ lenient_strict                              : num  75.2 81 18.1 27.3 37.2 25 38.3 18.3 62.2 30.7 ...\n $ relaxed_tense                               : num  90.1 72.6 61.4 56.5 83 29.7 89 68.7 82.8 42 ...\n $ demanding_unchallenging                     : num  33.4 4.2 10.1 22.5 92 25.4 58 59.2 13 39.4 ...\n $ drop.out_valedictorian                      : num  80.7 58.4 12.7 13.9 73.3 27 37 34.4 45.3 19.5 ...\n $ go.getter_slugabed                          : num  24.6 44.1 64.2 54.4 49.7 32.7 69.4 54.8 40.1 71.5 ...\n $ competent_incompetent                       : num  25 47.3 81.5 89.7 53.2 29.1 87.9 89.3 67.4 72.3 ...\n $ aloof_obsessed                              : num  64.9 52.6 60.3 62.1 67.2 42.6 59.6 64.7 57.1 46.7 ...\n $ flexible_rigid                              : num  73.9 83.9 52.2 54.5 52.2 23.1 72.8 33 72.4 32.5 ...\n $ active_slothful                             : num  21 59.2 64.6 54.6 52.2 53.5 66.8 59.2 50.6 79.7 ...\n $ loose_tight                                 : num  80.6 79 32.4 35 80.4 23.4 73 39.9 41.1 18.7 ...\n $ pointed_random                              : num  15.6 21.8 48.8 86.1 56.8 62.7 83.1 79.5 52.2 77.6 ...\n $ fresh_stinky                                : num  28.5 39.7 29.8 61.6 41.6 38.5 60.9 71.9 76.8 86.3 ...\n $ dominant_submissive                         : num  53.8 6.9 17.5 42.1 94.4 ...\n $ anxious_calm                                : num  19.7 41.5 33 26.7 10.1 69.4 5.3 19.1 22.6 34.9 ...\n $ clean_perverted                             : num  19.4 72.6 72.9 86.3 53.2 74.4 48.8 61.7 85.9 82.7 ...\n $ neutral_opinionated                         : num  74.3 97.3 85.7 83.3 18 89.1 29.4 61.3 91.5 63.1 ...\n $ always.down_picky                           : num  72.3 95.4 81.3 48.6 47.8 37.1 65.8 57.3 66.9 51 ...\n $ hurried_leisurely                           : num  16.7 64.7 68.9 59.6 26.9 81.5 46.6 66.7 48.9 73.2 ...\n $ attractive_repulsive                        : num  24.1 58.1 17.6 62.5 48.7 20.9 75.3 80.3 74.5 81.5 ...\n $ devoted_unfaithful                          : num  21 72.8 72.4 81 12.5 62.2 14.1 22.5 78.3 48.2 ...\n $ helpless_resourceful                        : num  70.5 69.8 29.9 36.1 32.6 ...\n $ deliberate_spontaneous                      : num  17.6 28.8 78.9 84.1 22 76.1 46.4 79.1 41.9 80.6 ...\n $ plays.hard_works.hard                       : num  88.4 18 9.8 11.5 79.3 25.9 27.5 30.1 32.6 21.7 ...\n $ imaginative_practical                       : num  86.4 59.1 21.1 12.8 62.8 25.9 21.1 11.3 38.1 23.9 ...\n $ frenzied_sleepy                             : num  21 24.2 20.6 16.3 49.1 44.6 24.5 25.7 17.3 54.7 ...\n $ queer_straight                              : num  87.9 85.6 66.8 46.5 57.9 42.1 38.4 14.8 76.2 57.3 ...\n $ assertive_passive                           : num  43.2 15 27.4 41.9 92.1 19.2 88 82.5 17.8 64.1 ...\n $ fast.talking_slow.talking                   : num  39.9 34.7 21 20 45.4 23.8 59.4 46.8 38.1 70.7 ...\n $ astonishing_methodical                      : num  83.8 56.6 22 23.6 65.2 45.1 39.5 34.7 52.8 39.4 ...\n $ hoarder_unprepared                          : num  42.4 36.8 58.7 77.3 60.3 57 75.7 67.3 44.1 63.8 ...\n $ consistent_variable                         : num  23.2 46.7 78.5 71.1 36.9 62.9 70.9 56.9 66.5 75 ...\n $ involved_remote                             : num  18.9 56.5 53.2 49.9 58.8 54.1 68.9 40.3 51.9 73.7 ...\n $ backdoor_official                           : num  76.9 37.8 23 14.4 54.8 21.6 28.9 17.9 22.6 14 ...\n $ captain_first.mate                          : num  36.4 16.7 45.1 71.1 91.2 19 88.9 86.4 18 66.2 ...\n $ refined_rugged                              : num  32.7 11.5 36.5 51.3 28.3 66.7 42.1 31.8 63.6 83 ...\n $ accommodating_stubborn                      : num  60.7 96.1 83.5 90.6 5.9 ...\n $ barbaric_civilized                          : num  87.8 56.9 50.7 24.4 81.7 46.4 57.2 50.1 26.4 33.5 ...\n $ alpha_beta                                  : num  63.2 6.4 25.2 50.3 88.2 ...\n $ loyal_traitorous                            : num  22.7 86.5 79.5 75.9 15.6 65.8 18.9 30.3 82.3 69.4 ...\n $ trash_treasure                              : num  69.6 60.3 48 37.3 81.7 65.1 66.9 55.4 29.7 31.2 ...\n $ fast_slow                                   : num  37.1 34.7 50.7 58.6 71 28.3 87.7 78.5 45.5 75.2 ...\n $ perceptive_unobservant                      : num  43.4 45.3 82.6 83.6 58.3 24.5 72.6 78.5 46 63.9 ...\n $ goof.off_studious                           : num  82.2 65.4 15.5 10.3 66.5 21.7 34.9 29.9 41.4 21.3 ...\n $ feminist_sexist                             : num  37.5 69.3 43.1 86.3 23.4 17.1 36.1 35.3 86.3 65.5 ...\n $ desperate_high.standards                    : num  45.7 84.4 41.8 22.8 23.1 60.3 14.2 12.6 25.3 15.7 ...\n $ impatient_patient                           : num  55.4 7.4 11.5 10.7 79.6 ...\n $ preppy_punk.rock                            : num  13.6 9.8 31.5 26.6 13.8 81.8 16.6 28.3 48.3 77.1 ...\n $ naive_paranoid                              : num  70 74 33.9 60.3 33.1 60 31.7 31.5 79.1 64.4 ...\n $ important_irrelevant                        : num  22.1 27 51 61.7 42.3 37.5 56.8 63.3 34.6 65.7 ...\n $ apprentice_master                           : num  66.8 89.7 47 36.1 12.3 74.7 11.7 18.8 84.2 53.5 ...\n $ healthy_sickly                              : num  23.8 57.5 43.7 47.1 51.9 25.3 77.1 69.5 59.8 73.5 ...\n $ morning.lark_night.owl                      : num  22.5 57.8 78.9 80.9 22.3 81.5 32.9 35.4 55 69.3 ...\n $ alert_oblivious                             : num  36.6 50.3 84.1 84.5 78.3 35.5 90.6 93.5 56.4 72.7 ...\n $ f....the.police_tattle.tale                 : num  78.2 35.3 34.7 52.2 80.9 10.7 80.9 71.8 26.8 17.5 ...\n $ experimental_reliable                       : num  76 24 12.5 10 71.6 18.8 29.5 12.8 17.7 14.6 ...\n $ loud_quiet                                  : num  57.7 8.7 14.9 8.2 88.1 25.2 64 26.2 14.7 44.5 ...\n $ high.IQ_low.IQ                              : num  24.6 31.8 72.3 80.4 28.7 29.3 79.3 65.4 47.5 57.6 ...\n $ oppressed_privileged                        : num  74.1 98.8 90.2 93.5 75 75.1 71.3 68.2 92.5 60.8 ...\n $ animalistic_human                           : num  86.9 33.7 47.1 30.5 83.1 58.6 39.9 44.7 32.7 28.1 ...\n $ still_twitchy                               : num  64.2 51.5 80.8 79.9 77.6 62.9 91.3 89 78.9 75.3 ...\n $ thick_thin                                  : num  58.3 69.1 77.7 61.6 80.1 48.9 58.1 52.3 32.3 37.6 ...\n $ repetitive_varied                           : num  23.9 35.8 42.5 52.2 26.7 74.4 30.8 44.2 39.8 52.7 ...\n $ rational_whimsical                          : num  15.4 58.4 86.5 87.3 51.7 65.4 83.3 90.3 66.1 79.2 ...\n $ egalitarian_racist                          : num  22.3 85.6 56.3 65.8 18.5 22.1 38.7 36.6 71.8 62.2 ...\n $ disreputable_prestigious                    : num  61 63.4 36.1 20.7 56.7 29.1 28.8 19.5 20.1 17.2 ...\n $ ignorant_knowledgeable                      : num  73.3 26.4 14.3 9.5 43.2 60.9 17.4 17.4 34.5 31.5 ...\n $ hard.work_natural.talent                    : num  19.3 76.2 77.4 63.3 30.1 71.2 56.5 55.1 54.2 62.5 ...\n $ androgynous_gendered                        : num  83.4 90 87.1 72.4 60.6 56.6 48.4 23.9 81.3 57.2 ...\n $ dispassionate_romantic                      : num  58.3 20.4 47.3 48.3 80.1 37.3 68 83.3 50.2 73.3 ...\n $ eloquent_unpolished                         : num  33.2 23.8 43.3 73.3 60.7 58.5 75.7 69 64.4 83.1 ...\n $ permanent_transient                         : num  30.9 37.4 79.6 76.7 41.8 65.1 51.2 69.7 66.5 77.5 ...\n $ intense_lighthearted                        : num  31.5 12.5 36 23 76.9 36.8 59.6 50.9 11.8 40.6 ...\n  [list output truncated]\n\n\nWorked like a charm!"
  },
  {
    "objectID": "qmd/setup/setup.html",
    "href": "qmd/setup/setup.html",
    "title": "Setup",
    "section": "",
    "text": "Please go to this website and download and install R and RStudio. While R is is a language and environment for statistical computing and graphics, RStudio is the most used integrated development environment for R, facilitating working with it.\n\n\n\n\n\n\nOpen if you want to use R in your browser instead of installing it\n\n\n\n\n\nIn case you don’t use a notebook where you can install R and RStudio, or you don’t want to, you can use the posit Cloud service. It can be run in you browser, and provides the same functions and interface as if you were working with your own RStudio installation. And it’s free as well!\n\nGo to posit Cloud.\nClick on Sign Up to create an account (it’s free) and login.\nOn the upper right, click on New Project. This will create a new RStudio project, which you can use to follow this workshop the same way as if you had installed R on your notebook.\n\n\n\n\n\n\n\nWarning\n\n\n\n\n\nKeep in mind that the free posit Cloud account only gives you 25 computing hours per month, but this should be more than enough for this workshop. Take a look here for the subscription plans."
  },
  {
    "objectID": "qmd/setup/setup.html#installation",
    "href": "qmd/setup/setup.html#installation",
    "title": "Setup",
    "section": "",
    "text": "Please go to this website and download and install R and RStudio. While R is is a language and environment for statistical computing and graphics, RStudio is the most used integrated development environment for R, facilitating working with it.\n\n\n\n\n\n\nOpen if you want to use R in your browser instead of installing it\n\n\n\n\n\nIn case you don’t use a notebook where you can install R and RStudio, or you don’t want to, you can use the posit Cloud service. It can be run in you browser, and provides the same functions and interface as if you were working with your own RStudio installation. And it’s free as well!\n\nGo to posit Cloud.\nClick on Sign Up to create an account (it’s free) and login.\nOn the upper right, click on New Project. This will create a new RStudio project, which you can use to follow this workshop the same way as if you had installed R on your notebook.\n\n\n\n\n\n\n\nWarning\n\n\n\n\n\nKeep in mind that the free posit Cloud account only gives you 25 computing hours per month, but this should be more than enough for this workshop. Take a look here for the subscription plans."
  },
  {
    "objectID": "qmd/setup/setup.html#structure-of-the-rstudio-interface",
    "href": "qmd/setup/setup.html#structure-of-the-rstudio-interface",
    "title": "Setup",
    "section": "Structure of the RStudio interface",
    "text": "Structure of the RStudio interface\nWhen you open RStudio it will look something like this:\n\nThe window can be split into 4 parts:\n\n\n1) Script pane\nThe script pane is used to edit scripts. Scripts are the files you store your code in. You can execute a line of code by pressing ctrl + enter (on windows) or command + return (on macOS). To execute multiple lines of code at once, mark them before you press the keys. Try it yourself! Write:\n\n# Our first line of code:\nprint(\"Hello World!\")\n\n[1] \"Hello World!\"\n\n\ninto your script and execute it. It should output “Hello World!” in your console.\nBy the way: Code lines that are preceded by a # are commented out, and will not be evaluated.\n\n\n2) Console\nYou can also work directly in the console. Type into your console and then just press enter:\n\n# Sum two values\n10 + 5\n\n[1] 15\n\n\nJust beware that the code you write here will not be saved, so it is more usefull for trying out things or for code you don’t need to save in a script.\n\n\n3) Workspace\nIn the Environment tab you get an overview over the objects currently loaded into your R session. You can also look at your command history and some more things we don’t need for now.\n\n\n4) Plots, Files, Help …\nPlots you build in your R session get output in the Plot tab. If you call the help function the documentation opens in the Help tab. The Files tab let’s you mange the files in your working directory."
  },
  {
    "objectID": "qmd/getting_started/the_big_picture.html",
    "href": "qmd/getting_started/the_big_picture.html",
    "title": "The Big Picture",
    "section": "",
    "text": "Now that we have completed our set up, let’s dive right into programming with R. In this chapter, we will go through a “mini-project” with very basic data, which follows a possible workflow when working with data in R. We will install and load packages, load data, perform some operations on this data, calculate some summary statistics and plot them. In later chapters we will go into a little more detail for each topic, so don’t worry if you don’t understand something quite yet, it will be covered again. The goal of this chapter is to simply give you an idea of what is possible in R, before dealing with the specifics."
  },
  {
    "objectID": "qmd/getting_started/the_big_picture.html#packages",
    "href": "qmd/getting_started/the_big_picture.html#packages",
    "title": "The Big Picture",
    "section": "Packages",
    "text": "Packages\nPackages are extensions to the base R you get by default. Let’s install a package collection, that makes it easier to work with data in R:\n\ninstall.packages(\"tidyverse\")\n\nThe tidyverse is a collection of packages following a common philosophy, and facilitating many aspects of coding in R. We will use functions from base R and from the tidyverse. However, as I personally find them a bit more intuitive in many cases, we will use tidyverse functions a lot in the current chapter, so you can quickly get an insight into what is possible with R.\n\n\n# tidyverse code will be marked like this.\n\n\nJust by installing the packages, we can’t use them. We also have to load them into our R session:\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors"
  },
  {
    "objectID": "qmd/getting_started/the_big_picture.html#load-data",
    "href": "qmd/getting_started/the_big_picture.html#load-data",
    "title": "The Big Picture",
    "section": "Load Data",
    "text": "Load Data\nData is loaded into R so you can work with it. For this chapter, we are going to use the data set babynames, which we can find on the tidytuesday site. I have already tweaked the data set a bit, so download it from here to follow along. Right-click on the respective data set found under this link, select ‘save as’ and then choose a folder on your notebook where to save it. We have talked about where that optimally should be in Workflow: Exercises. Our goal is to look at the most common name in every year and make a nice plot out of it.\nSo, after downloading it and saving it in the folder raw_data within my project directory, I can load the data set into R with:\n\nbabynames &lt;- read.csv(\"./raw_data/babynames.csv\")\n\nThis will load the data into R and assigning it the name babynames by using the &lt;-. You can see the data popping up in your Environment pane on the upper right. Note that the file path might differ on your device, depending on where you saved your data."
  },
  {
    "objectID": "qmd/getting_started/the_big_picture.html#take-a-look",
    "href": "qmd/getting_started/the_big_picture.html#take-a-look",
    "title": "The Big Picture",
    "section": "Take a look",
    "text": "Take a look\nNow that we have our data loaded safely into R, we can get an overview with a multitude of commands. One of the most important ones might be head(), which will give us the first few rows of the data:\n\nhead(babynames)\n\n  year sex      name ID\n1 1880   F      Mary  1\n2 1880   F      Anna  2\n3 1880   F      Emma  3\n4   NA   F Elizabeth  4\n5 1880   F    Minnie  5\n6 1880   F  Margaret  6\n\n\nEspecially for bigger data sets, it might be more feasible to only look at the structure and not the whole data set:\n\nstr(babynames)\n\n'data.frame':   1924665 obs. of  4 variables:\n $ year: int  1880 1880 1880 NA 1880 1880 1880 1880 1880 1880 ...\n $ sex : chr  \"F\" \"F\" \"F\" \"F\" ...\n $ name: chr  \"Mary\" \"Anna\" \"Emma\" \"Elizabeth\" ...\n $ ID  : int  1 2 3 4 5 6 7 8 9 10 ...\n\n\nOn the left we can see the columns of this data frame, named year, sex, names, and ID. On the right we see the first values in each column, for example 1880, 1880, 1880, NA etc … in the year-column.\nSo, what we can infer from the data and its online description is that it contains the most common names for boys and girls in the USA for each year since 1880."
  },
  {
    "objectID": "qmd/getting_started/the_big_picture.html#merging",
    "href": "qmd/getting_started/the_big_picture.html#merging",
    "title": "The Big Picture",
    "section": "Merging",
    "text": "Merging\nSadly the data is not complete. If we had the number of people born with a specific name for every year, we could find out which name was the most common each year. However, the number of people is missing from our data (ok, i split it up for illustrative purposes). So let’s download it and load it into R:\n\nbabynames_n &lt;- read.csv(\"./raw_data/babynames_n.csv\")\n\nNow we can merge it with our other data set by the ID column:\n\nbabynames_merged &lt;- merge(babynames, \n                          babynames_n, \n                          by = \"ID\")\n\nhead(babynames_merged)\n\n  ID year sex      name    n       prop\n1  1 1880   F      Mary 7065 0.07238359\n2  2 1880   F      Anna 2604 0.02667896\n3  3 1880   F      Emma 2003 0.02052149\n4  4   NA   F Elizabeth 1939 0.01986579\n5  5 1880   F    Minnie 1746 0.01788843\n6  6 1880   F  Margaret 1578 0.01616720\n\n\nGreat, now we can see the number of people born with that name in each year since 1880, and the propability that they get this specific name, calculated from the total of births in this year! But hold on! The column years seems to include missing values (NA's). It is always a good idea to at least think about the missing values before doing any analyses, so let’s do just that:"
  },
  {
    "objectID": "qmd/getting_started/the_big_picture.html#missings",
    "href": "qmd/getting_started/the_big_picture.html#missings",
    "title": "The Big Picture",
    "section": "Missings",
    "text": "Missings\nThere are multiple ways to deal with missing values. For reasons of simplicity, we will just remove any rows that contain NA's. We can achieve that very easily using the function na.omit():\n\nbabynames_merged &lt;- na.omit(babynames_merged)\nhead(babynames_merged)\n\n  ID year sex     name    n       prop\n1  1 1880   F     Mary 7065 0.07238359\n2  2 1880   F     Anna 2604 0.02667896\n3  3 1880   F     Emma 2003 0.02052149\n5  5 1880   F   Minnie 1746 0.01788843\n6  6 1880   F Margaret 1578 0.01616720\n7  7 1880   F      Ida 1472 0.01508119"
  },
  {
    "objectID": "qmd/getting_started/the_big_picture.html#subsetting-data",
    "href": "qmd/getting_started/the_big_picture.html#subsetting-data",
    "title": "The Big Picture",
    "section": "Subsetting data",
    "text": "Subsetting data\nOne very important part of working with data in R is the subsetting of data. This means we select specific values from a data set. Let’s suppose we want to only look at the female names in this data set:\n\n\nbabynames_F &lt;- babynames_merged %&gt;%\n  filter(sex == \"F\")\n\n\nWondering what the %&gt;% means? That’s a pipe operator, which is used, mainly in the tidyverse, to connect multiple function calls. This can make code a lot more readable. In our case, we start with the babynames_merged data frame and then perform an operation on it, in this case filtering specific values."
  },
  {
    "objectID": "qmd/getting_started/the_big_picture.html#adding-a-new-column",
    "href": "qmd/getting_started/the_big_picture.html#adding-a-new-column",
    "title": "The Big Picture",
    "section": "Adding a new column",
    "text": "Adding a new column\nNow, we want to plot the percentages of each name, instead of the probability, because it looks a bit more intuitive. So, let’s build a new column named percentage, which is just the prop column multiplied by 100:\n\nbabynames_F$percentage &lt;- babynames_F$prop * 100\nhead(babynames_F)\n\n  ID year sex     name    n       prop percentage\n1  1 1880   F     Mary 7065 0.07238359   7.238359\n2  2 1880   F     Anna 2604 0.02667896   2.667896\n3  3 1880   F     Emma 2003 0.02052149   2.052149\n4  5 1880   F   Minnie 1746 0.01788843   1.788843\n5  6 1880   F Margaret 1578 0.01616720   1.616720\n6  7 1880   F      Ida 1472 0.01508119   1.508119"
  },
  {
    "objectID": "qmd/getting_started/the_big_picture.html#selecting-columns",
    "href": "qmd/getting_started/the_big_picture.html#selecting-columns",
    "title": "The Big Picture",
    "section": "Selecting columns",
    "text": "Selecting columns\nNow we can trim down our data set a bit more and [select] only the columns we are actually going to need:\n\n\nbabynames_F &lt;- babynames_F %&gt;%\n  select(year, name, percentage)\nhead(babynames_F)\n\n  year     name percentage\n1 1880     Mary   7.238359\n2 1880     Anna   2.667896\n3 1880     Emma   2.052149\n4 1880   Minnie   1.788843\n5 1880 Margaret   1.616720\n6 1880      Ida   1.508119"
  },
  {
    "objectID": "qmd/getting_started/the_big_picture.html#some-additional-summary-statistics",
    "href": "qmd/getting_started/the_big_picture.html#some-additional-summary-statistics",
    "title": "The Big Picture",
    "section": "Some additional summary statistics",
    "text": "Some additional summary statistics\nNow, the next part can show you how easy it can be to deal with data in R. First, let’s group our data according to year:\n\n\nbabynames_F_grouped &lt;- group_by(babynames_F, year)\n\n\nAny operations we now perform are performed by year, and not on the whole data set at once. In our case, we want to find the most common name each year, which is the name with the maximum percentage:\n\n\nbabynames_F_max &lt;- slice(babynames_F_grouped, which.max(percentage))\n\nhead(babynames_F_max)\n\n# A tibble: 6 × 3\n# Groups:   year [6]\n   year name  percentage\n  &lt;int&gt; &lt;chr&gt;      &lt;dbl&gt;\n1  1880 Mary        7.24\n2  1881 Mary        7.00\n3  1882 Mary        7.04\n4  1883 Mary        6.67\n5  1884 Mary        6.70\n6  1885 Mary        6.43\n\n\n\nThe which.max(percentage) command finds the maximum percentage per year. slice() will extract the respective rows, so we have only the row contatining the most common name per year in the end.\nAt the moment we only want to get an idea what R can do, so don’t hold up if the functions are not that clear to you right now, hopefully that will change throughout this tutorial."
  },
  {
    "objectID": "qmd/getting_started/the_big_picture.html#plot-the-data",
    "href": "qmd/getting_started/the_big_picture.html#plot-the-data",
    "title": "The Big Picture",
    "section": "Plot the data",
    "text": "Plot the data\nWe will use the package ggplot2 (which is also part of the tidyverse) for plotting our data. It should be mentioned that Base R also has some powerful plotting functions, however, ggplot2 makes it very easy to build complex and beautiful plots.\nA ggplot is constructed from multiple layers, that can be laid over each other using the + operator.\nWe start with the function ggplot(), where we define our data and the x and y axes.\n\n\np &lt;- ggplot(\n  data = babynames_F_max,\n  aes(\n    x = year,\n    y = percentage)\n  )\n\nWe can also define different colours for different groups. For example, if we want the bars to get filled with a colour corresponding to the name they are representing, we can do that:\n\np &lt;- ggplot(\n  data = babynames_F_max,\n  aes(\n    x = year,\n    y = percentage,\n    fill = name\n  )\n)\n\nNow that we have defined our aesthetics, we can add a geom-layer. This will make use of the data we have defined in ggplot() and plot some bars for us:\n\np &lt;- p +\n  geom_col()\np\n\n\n\n\nLet’s give the axes some more informative names and a title to the plot:\n\np &lt;- p +\n  ggtitle(\"Most common female name in the United States of America by year\") +\n  xlab(\"Birthyear\") +\n  ylab(\"Percentage of children given that name relative to total births\")\np\n\n\n\n\nFinally, to style the plot a bit, let’s add a predefined theme and a color palette:\n\np +\n  theme_bw() + # Theme\n  scale_fill_brewer(palette = \"Spectral\") # Color palette\n\n\n\n\n\nWe would have many more options to style this plot further (for example we could sort the names in the Legend by order of appearance), but let’s keep it at that for now."
  },
  {
    "objectID": "qmd/getting_started/the_big_picture.html#conclusion",
    "href": "qmd/getting_started/the_big_picture.html#conclusion",
    "title": "The Big Picture",
    "section": "Conclusion",
    "text": "Conclusion\nIn this tutorial we have learned that R is a flexible tool for editing and plotting data. Of course, we barely scratched the surface. Therefore, we want to dive a bit deeper into each step. Either follow the course, or navigate to the chapters you are most interested in. But first, take a look at the new data set you will be working with throughout the exercises."
  },
  {
    "objectID": "qmd/basics/tidyverse.html",
    "href": "qmd/basics/tidyverse.html",
    "title": "Tidyverse",
    "section": "",
    "text": "Throughout this workshop you will come into contact with some functions from the very popular package collection tidyverse. The tidyverse is composed of multiple packages, all following a common philosophy, and facilitating many aspects of coding in R, for example data wrangling and plotting. It is not really necessary to learn the tidyverse syntax in order to understand R and become proficient in it. However, I find it easier to understand in many cases, which probably makes it easier to get started with. Therefore, I will provide the syntax from the respective tidyverse package along with the Base R syntax in many cases. In the end, it is a question of preference what you want to learn. Most code will probably be composed from base R functions and tidyverse functions.\nWe will mainly use the tidyverse packages dpylr and ggplot2."
  },
  {
    "objectID": "qmd/basics/tidyverse.html#the-pipe-operator",
    "href": "qmd/basics/tidyverse.html#the-pipe-operator",
    "title": "Tidyverse",
    "section": "The pipe operator",
    "text": "The pipe operator\ntidyverse code is often written using the pipe operator %&gt;% (read as ‘then do’), which makes it easy to connect multiple function calls:\nIn base R, one could write:\n\nsum(seq(from = 1, to = mean(c(45:100), na.rm = TRUE), by = 0.1))\n\n[1] 26313\n\n\nWhich, in the tidyverse, would be written:\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nc(45:100) %&gt;%\n  mean(na.rm = TRUE) %&gt;%\n  seq(from = 1, to = ., by = 0.1) %&gt;%\n  sum\n\n[1] 26313\n\n\n\nMuch nicer to read, right?\nSome notes on this syntax:\n\nIf we don’t have any additional arguments we want to put into the function, we can just write the function name without any brackets, like we do at the end with sum.\nThe pipe operator will give the result of the last function as input into the next function. That’s why we don’t have to specify the vector within the mean() function.\nIf we want to clearly state which of the function arguments should receive the input, we can write a ., which can be read as output of the previous function call. That’s what we do in the seq() function. It calculates a sequence from 1 to the mean of c(45:100)."
  },
  {
    "objectID": "qmd/basics/basics_exercise.html",
    "href": "qmd/basics/basics_exercise.html",
    "title": "Basic operations: Exercises",
    "section": "",
    "text": "What does the function seq do? “,\n\nRepeats a value multiple times.\nBuilds a sequence of values.\nLoads a SQL data base.\nIt’s part of another package and therefore not loaded in R.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the help function ?.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nRepeats a value multiple times.\nBuilds a sequence of values.\nLoads a SQL data base.\nIt’s part of another package and therefore not loaded in R."
  },
  {
    "objectID": "qmd/basics/basics_exercise.html#exercise-1",
    "href": "qmd/basics/basics_exercise.html#exercise-1",
    "title": "Basic operations: Exercises",
    "section": "",
    "text": "What does the function seq do? “,\n\nRepeats a value multiple times.\nBuilds a sequence of values.\nLoads a SQL data base.\nIt’s part of another package and therefore not loaded in R.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the help function ?.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nRepeats a value multiple times.\nBuilds a sequence of values.\nLoads a SQL data base.\nIt’s part of another package and therefore not loaded in R."
  },
  {
    "objectID": "qmd/basics/basics_exercise.html#exercise-2",
    "href": "qmd/basics/basics_exercise.html#exercise-2",
    "title": "Basic operations: Exercises",
    "section": "Exercise 2",
    "text": "Exercise 2\nWhy does the following code not work? Correct it so it does.\n\nc(1, 2, 3, 4, 5)\nmean(num_vec)\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nDoes the object num_vec actually exist?\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe object num_vec hasn’t been assigned yet. So let’s do that:\n\nnum_vec &lt;- c(1, 2, 3, 4, 5)\nmean(num_vec)\n\n[1] 3"
  },
  {
    "objectID": "qmd/basics/basics_exercise.html#exercise-3",
    "href": "qmd/basics/basics_exercise.html#exercise-3",
    "title": "Basic operations: Exercises",
    "section": "Exercise 3",
    "text": "Exercise 3\nBuild the following vector with as little code as possible:\n\nvec_1 &lt;- c(1, 2, 3, 4, 5, 5.1, 5.2, 5.3, 5.4, 5.5, 2, 2, 2, 2, 2, 2, 2, 2)\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse seq() and rep(). You can also build consecutive sequences using :.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nvec_1 &lt;- c(1:5, seq(from = 5, to = 5.5, by = 0.1), rep(2, 8))"
  },
  {
    "objectID": "qmd/basics/basics_exercise.html#exercise-4",
    "href": "qmd/basics/basics_exercise.html#exercise-4",
    "title": "Basic operations: Exercises",
    "section": "Exercise 4",
    "text": "Exercise 4\nFind all of the elements in the vector that are either equal to 1000, or lie between than sqrt(11) and log(1.001).\n\nvec_num &lt;- c(sqrt(100)^3, exp(-6), 22.02/3 * sqrt(4^2) * 0.25, -120987/(47621 * 1.3 ^ 4 ))\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou need to combine three logical statements. Go at it step by step: first find all elements in vec_num that are equal to 1000, and then add a comparison for the rest of the statement behind an | (or).\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nvec_num == 1000 | (vec_num &lt; sqrt(11) & vec_num &gt; log(1.001))\n\n[1]  TRUE  TRUE FALSE FALSE"
  }
]